{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 19:59:17.368631: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-15 19:59:19.641213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/gilbreth/cuda-toolkit/cuda-11.2.0/extras/CUPTI/lib64:/apps/gilbreth/cuda-toolkit/cuda-11.2.0/lib64:/apps/spack/gilbreth/apps/intel-mpi/2017.1.132-intel-17.0.1-p7yx74h/compilers_and_libraries_2017.1.132/linux/mpi/intel64/lib:/apps/spack/gilbreth/apps/intel-mpi/2017.1.132-intel-17.0.1-p7yx74h/compilers_and_libraries_2017.1.132/linux/mpi/mic/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/itac/2017.1.024/intel64/slib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mpi/intel64/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mpi/mic/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/ipp/lib/intel64:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mkl/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/tbb/lib/intel64/gcc4.7:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/debugger_2017/iga/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/debugger_2017/libipt/intel64/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/daal/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/lib:/usr/lib64\n",
      "2024-04-15 19:59:19.642218: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/gilbreth/cuda-toolkit/cuda-11.2.0/extras/CUPTI/lib64:/apps/gilbreth/cuda-toolkit/cuda-11.2.0/lib64:/apps/spack/gilbreth/apps/intel-mpi/2017.1.132-intel-17.0.1-p7yx74h/compilers_and_libraries_2017.1.132/linux/mpi/intel64/lib:/apps/spack/gilbreth/apps/intel-mpi/2017.1.132-intel-17.0.1-p7yx74h/compilers_and_libraries_2017.1.132/linux/mpi/mic/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/itac/2017.1.024/intel64/slib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mpi/intel64/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mpi/mic/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/ipp/lib/intel64:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mkl/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/tbb/lib/intel64/gcc4.7:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/debugger_2017/iga/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/debugger_2017/libipt/intel64/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/daal/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/lib:/usr/lib64\n",
      "2024-04-15 19:59:19.642232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from auditory_cortex.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default normalizer file...\n",
      "Creating normalizer object from: modified_bins_normalizer.csv\n",
      "Reading existing dataframe.\n",
      "Model on device: cuda\n"
     ]
    }
   ],
   "source": [
    "model_name = 'speech2text'\n",
    "dataloader = DataLoader()\n",
    "model = dataloader.get_DNN_obj(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### architecture..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speech2TextForConditionalGeneration(\n",
       "  (model): Speech2TextModel(\n",
       "    (encoder): Speech2TextEncoder(\n",
       "      (conv): Conv1dSubsampler(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "          (1): Conv1d(512, 2048, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        )\n",
       "      )\n",
       "      (embed_positions): Speech2TextSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x Speech2TextEncoderLayer(\n",
       "          (self_attn): Speech2TextAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): Speech2TextDecoder(\n",
       "      (embed_tokens): Embedding(10000, 1024, padding_idx=1)\n",
       "      (embed_positions): Speech2TextSinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x Speech2TextDecoderLayer(\n",
       "          (self_attn): Speech2TextAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): Speech2TextAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=10000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.get_model_architecture\n",
    "dict([*model.extractor.model.named_modules()])['']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech2Text...!\n",
      "Note that the layer-0 corresponds to kernel size and stride of spectrogram\n",
      "Calculating receptive fields for all layers...\n",
      "Layer 0, RF:   400 samples, 25.00 ms, sampling_rate: 100Hz, sampling_time: 10.000ms\n",
      "Layer 1, RF:  1040 samples, 65.00 ms, sampling_rate: 50Hz, sampling_time: 20.000ms\n",
      "Layer 2, RF:  2320 samples, 145.00 ms, sampling_rate: 25Hz, sampling_time: 40.000ms\n"
     ]
    }
   ],
   "source": [
    "from auditory_cortex.utils import get_receptive_fields\n",
    "\n",
    "print(\"Speech2Text...!\")\n",
    "print(f\"Note that the layer-0 corresponds to kernel size and stride of spectrogram\")\n",
    "# spectrogram with:\n",
    "#  - window length 25 ms (400 samples)\n",
    "#  - window stride 10 ms (160 samples)\n",
    "kernels = [400, 5, 5]\n",
    "strides = [160, 2, 2]\n",
    "# the last entries are kernel size and strides of the 'convolution position encoding'\n",
    "\n",
    "get_receptive_fields(kernels, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### changing the architecture.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_auto_class',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_create_repo',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_decoder_start_token_id',\n",
       " '_get_feat_extract_output_lengths',\n",
       " '_get_feature_vector_attention_mask',\n",
       " '_get_files_timestamps',\n",
       " '_get_logits_processor',\n",
       " '_get_logits_warper',\n",
       " '_get_name',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_model_inputs',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_save_to_state_dict',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " 'add_memory_hooks',\n",
       " 'add_module',\n",
       " 'adjust_logits_during_generation',\n",
       " 'apply',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'beam_sample',\n",
       " 'beam_search',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'constrained_beam_search',\n",
       " 'contrastive_search',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'enable_input_require_grads',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_buffer',\n",
       " 'get_decoder',\n",
       " 'get_encoder',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'greedy_search',\n",
       " 'group_beam_search',\n",
       " 'half',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_loaded_in_8bit',\n",
       " 'is_parallelizable',\n",
       " 'lm_head',\n",
       " 'load_state_dict',\n",
       " 'main_input_name',\n",
       " 'model',\n",
       " 'modules',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'sample',\n",
       " 'save_pretrained',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'set_output_embeddings',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model.extractor.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Speech2TextConfig {\n",
       "  \"_name_or_path\": \"facebook/s2t-large-librispeech-asr\",\n",
       "  \"activation_dropout\": 0.2,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"architectures\": [\n",
       "    \"Speech2TextForConditionalGeneration\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.2,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"conv_channels\": 1024,\n",
       "  \"conv_kernel_sizes\": [\n",
       "    5,\n",
       "    5\n",
       "  ],\n",
       "  \"d_model\": 1024,\n",
       "  \"decoder_attention_heads\": 16,\n",
       "  \"decoder_ffn_dim\": 4096,\n",
       "  \"decoder_layerdrop\": 0.0,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"dropout\": 0.2,\n",
       "  \"early_stopping\": true,\n",
       "  \"encoder_attention_heads\": 16,\n",
       "  \"encoder_ffn_dim\": 4096,\n",
       "  \"encoder_layerdrop\": 0.0,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_channels\": 1,\n",
       "  \"input_feat_per_channel\": 80,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"max_length\": 200,\n",
       "  \"max_source_positions\": 6000,\n",
       "  \"max_target_positions\": 1024,\n",
       "  \"model_type\": \"speech_to_text\",\n",
       "  \"num_beams\": 5,\n",
       "  \"num_conv_layers\": 2,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"scale_embedding\": true,\n",
       "  \"transformers_version\": \"4.28.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 10000\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.extractor.model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
