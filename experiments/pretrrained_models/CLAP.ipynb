{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmedb/projects/Wav2Letter/deepspeech.pytorch/deepspeech_pytorch/loader/data_loader.py:17: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default normalizer file...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from auditory_cortex.dataloader import DataLoader\n",
    "\n",
    "from transformers import ClapModel, ClapProcessor\n",
    "\n",
    "dataloader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading raw features from /scratch/gilbreth/ahmedb/cache/CLAP/CLAP_raw_features.pkl\n"
     ]
    }
   ],
   "source": [
    "model_name = \"CLAP\"\n",
    "bin_width = 50\n",
    "features = dataloader.get_raw_DNN_features(model_name=model_name)\n",
    "\n",
    "# features = dataloader.get_resampled_DNN_features(model_name=model_name, bin_width=bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 128])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 0\n",
    "sent = 12\n",
    "features[layer][sent].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 1\n",
    "sent = 12\n",
    "features[layer][sent].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 4\n",
    "sent = 12\n",
    "features[layer][sent].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1024])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = 7\n",
    "sent = 12\n",
    "features[layer][sent].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud = dataloader.get_stim_aud(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.369625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.metadata.stim_duration(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = ClapModel.from_pretrained(\"laion/larger_clap_general\").to(0)\n",
    "processor = ClapProcessor.from_pretrained(\"laion/larger_clap_general\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent duration: 1.369625 sec\n",
      "Input features: torch.Size([1, 1, 1001, 64]) \n"
     ]
    }
   ],
   "source": [
    "sent=12\n",
    "aud = dataloader.get_stim_aud(sent)\n",
    "aud = resample(aud, aud.size*3)\n",
    "inputs = processor(audios=aud, sampling_rate=48000, return_tensors=\"pt\").to(0)\n",
    "# \n",
    "\n",
    "print(f\"Sent duration: {dataloader.metadata.stim_duration(sent)} sec\")\n",
    "print(f\"Input features: {inputs.input_features.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent duration: 1.7599999999999998 sec\n",
      "Input features: torch.Size([1, 1, 1001, 64]) \n"
     ]
    }
   ],
   "source": [
    "sent=18\n",
    "aud = dataloader.get_stim_aud(sent)\n",
    "aud = resample(aud, aud.size*3)\n",
    "\n",
    "\n",
    "inputs = processor(audios=aud, sampling_rate=48000, return_tensors=\"pt\").to(0)\n",
    "# \n",
    "\n",
    "print(f\"Sent duration: {dataloader.metadata.stim_duration(sent)} sec\")\n",
    "print(f\"Input features: {inputs.input_features.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1001, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_features.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x2acfdfc9e130>,\n",
       " <AxesSubplot:xlabel='time (ms)', ylabel='mel filters'>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from auditory_cortex.utils import SyntheticInputUtils\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "SyntheticInputUtils.plot_spect(inputs.input_features.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAA0CAYAAACD6+9oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0xklEQVR4nO29aaxlSXLf98vlLHd7W73auqp6qocznFX0iBxwgWmCtmyJpAjpiyVQHwzaliDAkgzJ/mCTIGxY/kTJ/iAZNiwSkgxKsLiYFi2C0MIFtEBYMJchOcNZOT1bL1Ndy1vvdpbMDH+IvPe9190z3T0z/arougE8vHPPPedk/E9GRkRGROY1IsKGNrShDW3o6SP7uBnY0IY2tKENPR7aGIANbWhDG3pKaWMANrShDW3oKaWNAdjQhja0oaeUNgZgQxva0IaeUvKX2VhpKqkZXWaTG9rQhjb0VclYi6T0uNn4qjTl6JGIXP1GP/dSDUBtRnwHf+Iym9zQhja0oa9KbrJFPD193Gx8VfpV+fkvvR3PfVMGwBjzRWAKRCCIyIeNMXvAzwJ3gS8Cf15Ejr7qc3yBG26BNWBy9MlZTFEgTQuSoCgxziIhQAh6nTVgnV6fIhijxzHpdwBJ9J6UMGWpz0oCZYHxCnO95iEJtC2pbTHe6/Uxrr83q+e73OZ5vvoe6XqMs5i61jZXvEg6e/6KVljPP6Np9LuqwhiD9D3EqNc5q+0meWOsoNheD+vq+hiRtkO6DlOW+v3rYS28PuM8n+fvq8qvDetiqXjKQrG2nX5/HmuMIKJYX70uJUakD2DtRaxVhXH268daVXqu6/W+ulJ57PszfF8NK5xhez2sK3oLWI1zeu2q3fwuX4N12SAhYKtKzyW5iNWaM1nKfALQttpOXYH3Os6+GtbVODj/jGVzEWvTXBjTF7Bap7L8tWINQbHGeBFrjCoXbtXuV8E6qPX7tQzHNU4zGcN0+tr+eArorcwA/l0ReXTu848AvyYiP26M+ZH8+b/+ag/od0pe+XMfQKzBJCEMDc2+EMaJ6qGjOoJ+DItv6rAzT3lsCUMh1gnxghGDXViKmSEVQirBJPDz/LkAsZAKwfZ5sBtIXhAHbmlwnV6DQHVk6Cd6TXUANgix0nOxEkw0YPR/KoVYguvALQwmQbcrlEcGsVAd6zONCGIMGDBJ1lj7iaHZE+IoUd93VMfQ7sDyuQ574immljg4hzUZ3NziF9p2KjLWmSHWiid5EPf6WP3CYAJgwQRDeQLdtj6jfqS8xdrQbek9JmWswRAHQvLgWn1nAP2WUB4rrvI4N7fCujrOWLttQ7snxEoY3LeUJ7C8Bu3tDndY4JcQBpDqhLiMdWbxS0OsBPFgYsY6lHWfYhTLGmuh3xUzA6LnbGcoptDt6HupDvTyWEO/BcmdYbW9oR8JWLAt+KVBHISRUJxoO+XJa7Gu2kf0nbZXEuKgfmApT2F+S+iv9/iHBTZArIVUC2JVlvzM4pqzfjRBZTiMVAGlKivxjFUsiM9YT806c+cag19AuyO4xlAfKo9xAN0W2t55rBMBOevXVKqcF1ODEShP9P6vhLXdVaxGFGsxg9mzQrjSUzwoMKLPW2MNhmJqsX3GasH2On7CWHlJlf43QWVrhRWjWFPWUMXMYHvotgU/N1THKm9hiOICkDOs3ZZgkr4j10AcCGK0j22AYnqGsT5ObP3MfZBXGamngL6eENCfBb43H/8U8H/zBgZAHPQTAwlMUkUbJgm729H4AiOeWAl37hzw4GRMWwxh3FPUAWuFGA1hVNCbAtsZxAmIClfyKkxpHCBYpDOYZDC9QSoVSFpHP9YBL4WQCkuqBbc0xMqQSkOsVLGYpEoIqwo4DFXIpFelZCKErYhJDgFsVCVkkv4Xn49XWMdC2IrYrZ7Glpjk6CfCO+484svDbbqqhklPUZ1h7YclclBge1X0pIw1D1wZB+gz1mgwwZAGSdu3jpgHhhSJWKmBKaaGMDAYMYQBawVsIojT58daskJVrAiE7YgR9QRXGF+N1UQAVTRhK2LHPUtbgjj67cTdZx/yQrVHe1pgt3qKImKMkJKhr0s4LJQPm7EO1OimKiGjCK3FBMVpkhoQkwzJ6bVGQLYSYaBYyxOIA4MYiIMzhbjCGgaqrEhge0PIxqbfioBb9915zKkAG1U2xKhhjJOIHQaWtsIkS78becedR7zgrhAah5v0FD5jjZa+KpEjr/xaAavvOZVCqgQZRkzjIMoZ1kHCBIMUhjBKmGjoJwm3tMRasEH7VSyEIaoIo8qfeNSRqgQbVIbDSMdMHCfEWmxAAXGGOXmwIWN1qmjTVsAUiaUpMWIJ+z13bh/wIlcgWPxWR+lVkaZo6cqK4ljHiBh9ThyKOmy1IIMzrCtHJg0SpjekwhDGSWVhKNhOx6JrM1aXsXI21sSrAU+l5HGj18RBfr+lxbVkQwcIxMU5Y/eU0Zs1AAL8sjFGgJ8QkZ8ErovIvfz9K8D117vRGPOXgb8MUGzt6mCL6P8W3MISKq/W3wAG9gczjhYD+s6QFp7egHWCJJ2liUU98kHCNtnDGCSkTuodlUmte28xYTXI9PqVNyNFIo71O9c4xIHt1DtaDQRQj9n0huRQw+GACEYMFKpsjEDy6lmQhdykjDFoe7Y1uIUllg5cVswW9uo59/2EuMLKGVZlQIg1SCUYAzacw2qAIiFY6LPByu8wDhI45WGFVb/Ls5MIrkFnOaumWkilKhFxkFzuKwCfCEM1NOrpn8MaOTOYZKxzS/SK1Ygamt1qwUt2F1pLmvusqFh772JQpVAItgWyQZMqgRWoVFkBmC57jE7UuysSRIOUiZg9ZDGq/G0EmjOPej3wq1dhzf1HIYRhwvYZq5xhtSFjDfoqXWuIC6czi4wVJ+xUS150CbMsiM4j9UWsGAi1yqUFiIY0EKSKYPP/YEFW71pnRrEW9ZBRJya6lcHXZ9oIfqnyuMba6qxgpYCT15ksBn1fQ6CxiOUMqz2HNep510Gce2QUwGfDWUa2qgacYGeW4D2pNmdaw0o2wFmgW4tNEIcJSu1XKXPfrZwIK0hxhtUknbmlkix/Wc5CxuouYg2ioi9ODYJtdWYgpRBNArG4JdmJYT3LeBrpzUL/bhF52RhzDfgVY8ynz38pIpKNw2soG4ufBBjcuCMmZUEsoLma1KPwApUAHjGwCCUpZW/WZG+wcazdCKOemBlGUpUI1sNWwBV6fQoWwSI2IZ3DDCLGJ5L1sFJ42aPDZkFzhliqRxcGOksgNy92NcBUskxvoAE3CMTeQm8uYDaRtXCtFExzLSEj9Z4oEmI8GGERSkS4iHXp1jyup8TjnlQ6gnWw1eO8KNbe6vu0BgkOMwgYJ6S513flWGMWJ3m2pN5Tt529fXMR60qxYiG1Btsb3FCxmmRWXXAB60oJpQLaaxGpI6bQEA+ogV+EUr3gbLwkWqS1Z1hdVm6Tnlg6ks9Ys8FMwSBWEJwqi2HQ51HoALevxgoyh1BAv60e8AWsqxRPxipLBeaGgRgKJIclVvguYHUQK2iuBygSpkwolw4MLEOBsRDrlHm30GWs0ZC8qBId98SlJ5UGs9Vh86w29RZxUWUDix1q7HqNtTgz3uIVW/IqL912ntnwOlhzeIW5VS95EEixQLqV5j/DatI5rLX2Kz5jjUaxolitT6QqY+2cYjWCCVbDV4VghkGxBoOd9BgnSJYn8SBR5dIOA5IMSTw4NSBm1feFyqxfmnW/plLW40378wxrMuDQmb4ZBET8mfCusD7ZBUBvK70pAyAiL+f/D4wxvwB8O3DfGHNTRO4ZY24CD97Ms4ycefpGwBSJZ28eslU1fPLhXdzSULuAc9lDEFRJWHTArEI/BqRxqgTrhCsS1kW8T0RnCcaRxCFesGWkLAOtQGq8KmEj0BdQJBIgzq69o7TyTuDMYORj02eBtVDXPfNZAajgkr39lZF7NVbKxDfdeogzic/fexaTXoU1ZawZH31+rgVZ+otYbVpj7VuPJB1ovoz4ItJEg/RWlXAyMPNQJs3fOktaeb6Dc1iDUU87Gcjhs1WsfVD3zKfF2os8j/VCv6Ln3SDyrpsP6JPj5RdvQYLSRYwVqNW7lcZBkR/wOlilUozWJQ2LOUPo/NpQ+DLgfaKJFokG4yMSLcwdDCOpNyTncr8KaRihkNfH2p0Z20HdsZgWF2Y48BUUhYAfBt7zzH2OmgGHL9wAgcJpyIc6Qm+hdes+1mkJiBFYYxWckzOs1hI6l5VeoigjziWWvTpCxkckWMzCYUaRVFvEGc2DFRlrninQG5WpqNMsxSqkMlHXgWauCVM5N+NbKf81zNy35aTjfTfu8+LpNs2X9gEobMRYMIOIdFbfbZ7BiFPnCnK/WvXEnROcjxgDwTpir9fioCwDxkDTWx07PiKtw7QWhoFUWjV2hcpmGsX1rPoC1pUMW50FF1WgX+YiCfsqrE8pvaEBMMaMACsi03z8J4H/HvhF4IeBH8///9mbajFpqyZqwi4uPW10JFFPEwOlC8RoYeUdCpjWrOOwttdpcSyz52Yglo4ojh7WXh7JIHUiBcuyqdeeurQW01tsa0jJq7cTdAC4FsyRQ6xTA9Vnx7w8U+orD6lZlphGGbCdJrggC5R9FdbGEBpHGzwD32M7jct6G0nJQmPX3qZp7dq7U6zmDKsTYuOJwkWsUbGG3tEvC/XAnCBLj+mNxk/FYTsNVSWvIbji2CHmDCvo7GyFdRX/XS5K5SspzlVoaz1rWGFN4JaW0Dj65IhJQ3TiBYtoocVSvWSTDPRuHZqxnSqotMLqhdD4M0W07leQOhI6T7/InrVPirXVeHaaedzCYiMkq0lPG/wal+1yyKk4e7QJGhZazitMpzJmu1dhzeEz8apA3MISh46QbMbKWvGKmItY5+ewtgbbOk1uW0hlIiz9xTDRSjFVib71dH3GWilW21hMhDT1uMaslbZbGkzvc7vaX2LPQh2GjN9b2nmp4TTRAom150/GmliHNO3CEkaOIJaU9D07nxAxpGiQRcYaDfQqd6t+tZ3TWY/V3E1YeJ25rygXXFAI3bJAQh7/dULmihUBmZ3DuioAac9h7VTW0rnCJdca4sjSr7HmEJhoH9peOIu5Pl30ZmYA14FfyCV0HvgnIvIvjTG/DfycMeYvAl8C/vybadAIEDQp129HRtfmvH/3PjvFgk/V78A2htOu1lB1MkgV8cNAUQZCsMTgiCcl4gQ36YlzheCqiHWRsoyM65ZZU7FclCBQDXqsFebHAx1ARULKQLQO6gQLp7HOBGAQI7l9zpKAUQgTjUeb3mKbbEwGST0ec2asIN+bsYYhhJ3I5NqMD+7dwyJ8vrqDeDjpBhijyUkZRIphjy+iYu0z1jLhRoE4U0F3dcDaRFUFRlXH6aKmXarHWg+09HBxOFReioSUkKxDhoF0WuhACYAxRESVn5xhjU6IWwkpEqaz2M5gjA5ces15XOjTFdao1T1hN7B7dcoHdu4xDxX3yptg4eR8vw4jftjhfSIES2g9cVogdcTWUUNYFnwdMDZR1z3DsudkPqBr9D0Mhh0pGZYHOcDtlefYWswwIl2BiSYXzRii0Rj9GqsBI0K/rR7kyvBap9VYybwO1tWsJ6LVYnuB/f0pf2zny7y43OWjxTWMS5y2tYZAkkFGgWKoMhiDpW88Mvea7PUJWWqupBiqtzEadBQ+cjqv6ZoC64R60BGjpTkYaL/6RBon6DLWZYkJq0rhbEVWWFcFCj5jNepkYERDo3WeJWY3f+Xtn8/rhKEgVzqu75/yge17JDF8ye9hrDDrNbSHGBj1lIMeY1Csi0LxjYPOdBoHXrEaK4wGLd4ljqcDQuexPjEYdHSdp+tqbbxIajyC0VnG9BxWo1hNnlmZhI5HJ4SdnIxeqgTYMmoYsc8zody34vL43VQBvZZE5PPAv/U65w/gra/qWnvRAE5wNnG9OuVaeUraCrhFgYih9IF5mdi5OuMdO0cMfUcTPSfdgC/Efcy0IB2UuM5gg6G3ghkKpW+ZLiuW8wqmBbYxLCceN+6pxi3tSa1KtIrE1mFcQkpDGDpsB91OUu+u0bIzyWWV/U6k2GkJj2qKY4sNhmZcrMGIYx0HN6tk8HmsRaJwkevlKUPXEiZRPVSEwkeWVWL/+il3to6oXaCJnqN2yBf7q5iFIzWK1QRDcIIddRQucrqoaealYm0Niy2PH/UUk5Z+Wp1h7ew6ThuGFtNDu6uxeNcayMly8dDvBvykJz6sKU90BtKMzmG157D2nG0osjJ+RaL0kVvVMX3p+NdDrWYpbaQoIl0duXHziJujU0oXaULBYTPkxW4f0zhk7hWrQHBCNW7xNnEyH9DOS5iqdznfchSjnmKro5+VmogsEqm3+r8SwlCVWHtFw4muMRDPYd3vcYOIPKgoTi1ihW545oknBy6c61e0b1d4bRGpfOBmeYI1wu/WgnSOygeKItIMI7duHnFjdIq3iSYU3F+MeeWFPQ3fBMUqVuidMJi0GCOczAZ08xIz9UgiY+1wWx1xobFx63V2a8tIrLSsGnKpZsxYk2JNHsL1DlskzP2KYmpJhdBVZ1hX4a5VAvjVZL0wLHpul0fMxxVfKO8SekftA66IhFHgHc8ccHUww+b81r3pFo9e2sHMPCYYXKf5j+CEwaRBxHA8HdDPS+zUkwzMthzlsMdOelLjNEdoEhL9GmvMVUDtXtQcVaMgJM/W4/VWZzoPKoqZVon1rtDw0Arrql+TvBbsU0KXmv9eedmrJI1dOJbLkoN+xNi166oZZ1WB7N044X1XHmBNokueLnkWfaHT33M10rGUdQxwvqyI0SKdTo9XMd44K4jWQzDYQSA2KpCSPU0bwDcQl4buVg/7kbDwmN4iRWJybcb0cKTKcj1N1xiyCSaXDJ4ZAtuxrkIAMHPHfFlxlOvWTL5vhXX/5gnvu/IKAE0s6JJn3pUaGormLKFcabUJYhRrcJrozl4e0RDmWVnHnLxd6vdpWuhaii5XPDWG8ExHdIm08JqwqyJb+3NOH45VMa2MmFMPjFWCO4eGjIBthFRorNUkYO6ZNRWP+jGVDfkdab9WRc/kVsN7dzU/0OW/eVeoVxpXZZo6jTcukZJiDb1DOouN2XsLVhU/ZKyJOPeYaIinxTrUY3s16PFmSzAgC71GBpHJ3pzp/TG+V6BGUIMWzToMt1KKq+of8bCqpErzgumk4jCMCMnm2YGhsJFB1XFlMufdOw/pk6OJniZ6Fm2ppY9GIOW1G177NQTLPFaEzkEOdQLQZ6x5luaGgXhaZqwlNoc1TESr5663BNG4u4kGxj3jrYbZK2N8MGf5mhXWdK5fz2Fdra2xvaGbeaY7FY/CmF50fEnGOhp07Fw54Z2TA9qkONvgWbQFtrF5DUTGWgpYoe8dIThC5zVPktC8cuvootGwkAVbBuJJqaHQaYHL/QroGL7W0kfNKZloMNsdw2HH4t74rDIONOcTc3n4ORl+mulyC6DM2Z8JGgftG8/zp1e5t9zGLNy6xGtStVQucLM+Ydcv6MVl5XmVV7iiAmy1/lm8ern1oMMaIURLK0YTS1GFzZQpl5lpuVk1bmm7gSbm+hxjX5W3NJbBzpKdffXqduolDxcjZn5AqnTRjXjBjQOxcXkKeSZJqyTp+XI111i6ZcGnjm9QuIhdamLbGmGrbpgULbfrY8aupRXPUT+kj45HsqdTZ6fxzVSArwJV3StWH2kEpLMac3aiid+8LkASFOOOvq91+rxwhIHg8qpiaRzjGwu2rqqXvVU1vDKbYAqdLfilVou4kVaryCrUtSre8XkQ5s+rfMdyUfKJk5vEZHEd9JXgbWJn0LBbLXh2cEhlAq14Droxi77kKGmfIma9HsBXgbruNSfuEm3GChryMV6QlfIAiklHf1xhhgFOC8JQ68aNKNadG1NG1zrlpVrywsmOJscrwS2t9u9Q+zUlMGIvYHWv6le7tCwWFb9/fJt5X+Y8llDayPag4fpwyt3BAYWJLFLJYT/ipK2ZrXIn5+LsRRWoKk3EWCu0YrQoIJccGydIm5OboCHQ00KxNiUh18qbqO9o7/opgyJQuMikbPnS0S6UiVTqortQolVArSOVZi27WtasWFcFDDZo2OhkNuD3ju9wsByulWvpIjvDJTeHpzw31LWiTSp42I15tBjSZKO6njk6oap7yjKvZjdClzJWK1AmnZkHDxGsTci4J80LzCDC1BFGitX2htA7rl4/oXQ6GxsVHZ8/uIKUSXEtdX2LHQRS50iFvtOzWfvKQjx9dKkG4HzSjSz8iGHRF8SkJYaxgtO2pvKBraLhVnVEbXpq23O7tFQ28MnBTS3nKhPJ6IKduuq5sTUFoA2eE5eYCSRT4EaBetDRdY6eknrQ844rhzwfrlLXPc2yRA782QKoQrA2MS5btsoGbxLzomQwalkES4gGtzBYm2CgSVnxGv++8FZXU2urygwxzPtSa/ZFSwSPmgHDome3WnCzPKGyPaUJPFuqlvnD6obWg/uMNcf5r09mACz7gukK67zAj3qquqdtCoIVhqOOm9unfCHuMxi2zE0Nh05XOgtQJpwRtqqGrVK3qBgWPfW4ZRkNfZ62K9ZATAWp0CIgzFfAmo9nXUWfcplqlThYDhkXHbvlkmvFKYWJlCZwqzyiTZ4vVbrXlVg0uW5hPGy5MloAsOgLpr5ilgxp6SlGPWUVaJYlsbNMxkt2hkteiHuMxg3TYOHEavknYCqtntqpl4yLliSGcdWxGHW0werOI8FodcpACH2pq63NGb41f+nsvKBY553mpkyVeLgcMS469ss5+8V0jbWrPMfdgFeqK5qkr8EstQJma9SwN1iQMMy6kpmvmEUDnaUcdxRFZDkvkWjZ2VpQ+cA92WY8bjhdOmTqNYFuwJQJZ4W9wYKxb+mSY1y3LEcFfe5XrFbiWCuEVqvg4jmj9BqsgAhMu4pZU6mR8InD5ZBx2XKtnrLvFaszidvlIfeXWxyVu0ipuSjtV2FnvGS7akgYpm3F1CUWyUBQ58z7xCK/86s7M/roOLRjRqOG05nHLR2p1NJfV0WcTewP5utQ8WTQ0I09fSoJuXJPK8pE120UrJPtsfw6lNofcbpcA5BLD+WcN0DSaokm+LzcXZg2FUdxgDXCLNa0pqCXjolb8k31A7Z3FpzaAa6I9JTQW3ZHS9699RBvIsf9gHt+mySGBbC/O+WZ8QnTvuaL968wrFtmne4BM6w6qqLnuK5wrXqytg7sDBrujI4Z+ZYuea3WEcO9aGmjgeQwYvA+EpMn1IJH45s2e8Suy5UXq8Rnti9d0IEqpWI9WQwobGQ6rFmkkrFrGNmW9wxf4Vd33kPXFlibtOonGq6O57xnS6tuD7sh9/1EZz0Wru+dcmN0yqPlmJcf7TCsOha9Wt2tQYMxwuJRqRVQhSaU90YL7oyOGLhesZpEEsMrwdJHrV5xK6xS6OrgRrffsO1FrCuFkcSQxND2WSk54XRZc7IYMCpaZkNN8G27BUPb8r7RPf711rtIot5tQHm+Np7xrol6lY+6EffdhL739EXi1v4xV+o5r8y3uH+4RV32LPsCY2Bn0NBvefojj2u1ssjXPfvDBXdHh1iTCOKwRkhiuB8cIRqtrBFwPhLQVaWuVayuMRqV6HUNgOSFdqywBkesACucLAacmprdesFiUJLErrG+f3KP35zcxTl9z1E0Nn1rcsKzo0OSWB60Yx64CV3nSZXl2f0jtsslL9U7HByPqXygDR5jhb3RgsWkIk7dGmtZ9+wP59wdHZDEkjBrrA+TJUaD6SzOgM1Y+7Gs73dLs966Idbk8J4mtmKyhKirrQGOFwOmTcW1wZRpterXpWLdusfHxrcoqkCKjojHlInbk2OeGZwQxPHKcsIjN6bvtCT27v4hQ9/xpWKX6WyAM8IiOIwR9sdzpuMBce5wra4SH9QdV4fz9btLOeYTk+UgqsNmksFYwSC6odlIVx6nQp7qMNCl5wBieW4AFYKtIrUPVC5w3wumN3gX1wrEIgxtR2GCzgRMz3v2H3A8UQPx0sk2ITjubh3yzcNX2HMznBEebk34rfo5HjZj3rP1gKvllIfdhAfTMX10Gi4B+uC4uXXK4fYWTD1pGLl745Bv3XuRWVQjEcVwuz5mr1xwdTDjxYkOQucTXevXq11NBJvOYuGxUqxhpEvfXRUpneI9yKWChYu0yZLEUNhAYSKFiYrV9Xzz1Yd0Sctkv3y6RQiOd04OeM/wFbbdHGeE+/02/2/9HEftkA/s3GPXL/hytc2j2Yi29/RB5/Vd8DyzdcpnJmPEOdIk8L6bD3jf1ivMYpWVkeHZwSF75ZwvD7d5YbLL4cnoDGuO5ZI0hyBOE8Gx1DCBYgVfBgZFr8nb1X4uLqpBEEthItYkrBFq27PvT3nn9UeULrIMBa+cTkjJ8K7JI943+jI7TmcBL3V7/GZ1l3lf8S27LzN2LZOi5Wg+oO09MenMqU+WZ3ZP+PzBAPEW2en54M373B0f0CW/zlu/c/iIa9WUFwZ7vDjZ5uR0hHOiWI1o4jeXVorX0GUstXywH+rCpLIMDHxPrA2L3K+lD3RBgdcmEI3RfrU9t8tD7t44YLtcctQOeViPMUZ49+QBd+tH7LgFUQwvdPv8VnWXLjq+dfdFChspbeRkPmDZe/qomismy80rJ7x4UpIKi9lr+dCtl7lWTQni8Dmw/67RQ65VM14Y7vLSeJvT6RBjhJBLRleJX7cw6/2YVntQ9RPFWmSsw6rn2J3164qXoe3oxVGaQG17nq0OePbmIXv1nEfLMQf1kNJH3ju5z+3ykIlr6CeOL7RX+e3yHVgjfGjnJVyegnyqqVj2hY5Z1LG4tn/Kg+kVUmmw+y3ffusFRq4j5dicN5F3Tx5yYzDli8M9Xh5vM5+rYYpBZ9GrbSfcQqMOTytdrgGQnJDrWce1fRnZH8xoYpG3hzA5bpm4Us95Z/WAiVtSEOlxNKlk4lv2ygUfGL3MJ8a3+MzJNbaKhhv+hKv+lB275G7xkNr0fK65xs3yhMJE2uQ1bp4sw7LnlAF1qTHXrStzZmXN1qThXVuPWKYSZ4QuecauZeg6dos514opteuZtyUGtI7a6r4jJkDRZC84kpeun8146qrnSj3XFbFBYwd1xnptMOUd5SNGtsUhRAzzVDEuWvarGd9UP+Tj42f4w5NrbPkl14tjrrkpE9twp9AY8wvtHreqIwBmsdKNGI0wrDqm85pBoVjHV+csZhX7u3PujI7WWJNYtnzD0HXsFzOulVNKG/lYW2Jtol2op6qxV02ar7ZQSCU6m3OA1YVj2+WSk26guYtoGJQ9pY88MzxZYwWIGG27bHhudMDN8pg/GN3mc6f77BQLrvpTbvgTRqbjlj+iMJF73TbPVodEDNvFkBgtrhJK3zNfVFQuaiJ2f0G7LLh59YRnhid0uRg+iWWU+3W/mHGlmFO6wMfbEmtFV7o6yZVXq+0VVPGvZnWrGP540DIpG9ro89oSQ1UESh+5MzjimeLoAtYmFWyXS/7Y9pfZdkt+f3ybF6Z77PoFN/wJN/wxtQncKhTrYRhxqzqiTQU75ZIYLKWPWAON0Uq60kaqK0v6znPn2hF75YI2+XW/jnzL2LWKtZzhTeRTbV6ZHTUctFoj4pqc2zm3kl0ciBF2RksmZcOsL3GNhgLrsqem57nhAbeKI4amJWGJGKZmwE615MM7L+B2Ex89vc29xRZ7fs6N4oSr7pTaBG54HaOLWHK7PGSaarbLhr53VJNAiJbeObxNTKqWwytLUnR80/VHjFxHLxZnBG8iY6dYrxen7PgF1gif6/dJSXNi4gST17K4ForZpgroUmi1sGSV9JLdjmHdUdqIt2m9AlbQipHdcsGem3HHnzCyiV50AH2kvIs1wq3iiKNqxCvlhIHtqG2/Vp4O4UZxwiJV3C4PKE3MikZLTPcGCw7LIbv1kp1yyUldMyh73rd3n9v1EYtUrj22wkR2/VxjuOK5XVd8rt5n2RUMJg3NolSvsGUdW1wNIJO0asTstQyrntJG8J0uyRf1aJxN7JULrrgZd/wptRF6gU4s/6Z6N9eKKXfKA+73W9wrtxk4nQmBvo+SyPXimEY8d4pDANqk5bTDqmO7ajgsRuzVC0oXOK4GbA0aPrh3jxvVKU0q1jgr27PtlpQmMEwFtwYDPlteJQkMxi3LWaX5g2DWWGOtxm+9aGi3Y1hpv458pzXceUbnbWKvmKtSd/M11sY7fr18L9eLU+4Uh9yrdrhfThja7oLyLEzgmeKIiOFOeUAUy0kYkpJhXLXqIRcD9geaIxkPWvbGCz505WWulLPXYN1zc5xJVLbnzqDms8VVrE2kkWE5rYil4KPunKn7B+WFVUb3o7J7LYNC+3VYdCrXomFNbxP7xYwb/pgbbkFhoBeYuhN+vXwfN4tj9vyMl8sdDssRQ9dS246YlWdtem5mI3CnOKCRgvv9FkkMW2VLEMu8Kbk5PGURSibDltHOlA9deYmxa/OsMlJlb3zbLXAmUZjI7eExzxf7Ou6AZV+vvf0V1lTmahujmw/6nY7ah4y152HWHiKG0kX2/Ywb7oTrbonLWK/YOb9evJdnSsXxYrnHaV8ztO0FGR7alpvFMVNXc6c8YBoHvOj3QAw79RJrhD46rg+mHHcDJqOGnUHDt+y+TGUDSQxVnkEPXcvENjiTsCZxazjiS35Xy3BtQbPUnJ2ssD7F9HUZAGPM9wF/Fy3e+vsi8uNveJOceRXGCZO65d3jB1iE36qeg1OPASof2CmWXHMzapOYJ8si11RGLNtuztC07PspV6oFd+sDChNopCAmQxTL0LRsuwUj27JjF8x9RekjW3XD9XrKi8UOO+WSke8YFj2VCwycCuX14pShbc8ZgYBD6MWxW8zZrhpishrSCJaiNfjlWYmgDaokRNMFGKfVPu8Z3ydh+Ih/J6YzOCNUPrBfzLjq5hQI0+RoxBFzLHPoWoZGPZqr1TbPVgc4k+jEEVNNFMuOXXDslkzsktr2HMch3kd26yV71ZyXi212Kw2jjMqOUdGtB8xuOac2qhRHtsWahEOy4VuwVTfMu5KlGCToVsZ+mb19c6YQV9tGOJfYrZe8f3KPaaz5mHsO4BzWKVfs8gLWXhzOyDr/cb045UE94Xap+zk3qaDPlVY7bsFpGjCxSwoT2fNziiJypZ7jbeJBOeZKNWceKkZlx261wNu4xjq0HY70Gqxj3zKpW81HidHdLZe6nfBrsIJuR+ES+4MZH5x8mQf9hM+ad+jAsolB0bPr5+zZBgscJ08vlrmUeJMY2paRbblWTjmsRzxTHL0G6xU/o5GSLduwRbPGenUwYxEKjsoBe6UmjsdVy5V6jiMxtB0T11DZ/jVYLUlDZ3VLHx0pGegtruFsu/QV1lWxhhd8Ebk+mPLByZf5gt/nBbkNaBXQsOjY8zP2XEMCpuewVlbDt0PbcqM6YRkLbhQn61muykbiqj8lBsvENtSmZ8s3+CJwc3BKEsO8K9ivZjTRs1W3XM1G/jzWMoeKi9UKNmDLN4yqjpisYg0qvyQuJLyfRvqaDYAxxgH/C/AfAC8Bv22M+UUR+eRXvdHm3K8DCZZh0fGnt36faar56eG30ZUFg6InJIsj8bleK0N6cXTiSFhCsjSp4DCOVWn5ll4c0zggovcBDK2ef6Xf4aHZYp4qKh/YrRa8b3SPF8a73BocY43w0I8Z+o6Jbxg6HSyNFCxSRaShNoZGSlVUCO8cH/BwPqbvHcYJ/XbCtVbDBH0uF8zGAKsb1F2p5/zZrd/j5bjNPx58B4JfY7UIn+2urbE2oknQkByLWHEYx1S2f12s1iRq09OL48X+CoUJTFNNXQSu1jPeO3qFe4ttbtXHLGPBUTFkXOg0ucr7V6ywAtm4eHpx1LbnnZMDPnL/NiFYjE/0Wwkb7HpXSdvnrTJyF6dkuTk45QcnH+Vz/VV+rvp2KBOVV08N4NPd9ddgjWKYxZpTpx7iyHU0Ur4Ga2niGqsl0YinKgI36ik3qhMeLsc8U51wYEec9vUa6zAXj7epoM+Zv/NYx67h7tYBH71/S5OkRaLbFkrM+vcRbEL3oHGaFE3R8tzogB/c+ii/2zzLL1YfxlXxAtZPdjfW77gXR8yx6pM4ora9znJcxyJV9NnJOY+1TQVf7PfX76sstDy6soFpX/NMdUzCsAgl20XD2LfUtidiWCRNQDujC+FWWLf9kjuTYz7x4IYqxSrSbzlkpnkd3+QZXQGxACKkZHj/5B4/MPkYv+G+mV8vv4Wy1DJTyfmjP2hvEjH0uZ1ONOx6HIdYo4Zp4HpOY43LCwsdaa2w21Tw+TwOkhiqMvBMfcxOsSDJM9wsT5iHii55Jr5l2y8vYJ1JzZ6fMU8VEUubCg2tjaZ89tG+bkVSJbqtnOhe7fW02QriLdO3A8/nlcIYY34G/Y2Ar2gAxEKoyatrtT6/Cdrh81QxGrT0MuLRbIQxwnEY8nx7nUWepxUmYhHaVHAa4Pn2elbIifv9FotUYrMaSpi1UPXisNl736oarBEOw4jrQ/UsrBHGhYYZlrHg+f6aJiptpLSBoVVvuc+eaps8j7oR00Wlm5P1dp0QBQ2JrMpdVz9aokvmKz7d3eA0DahHHc204GA+RMRw0I943rwWay+WozDkeRSrNcLL7S5HbvS6WI9Ez7fi2a2X9MlxEgZcH0zXOZCh7yhsZBYrHnYTrEkUOQxy6EYUWcGusB60Q2bnsbZm7RGHQS6jy97/al+JaVCsB3Gs9erTgqOF1sk+6ie0qbiAFTQuv+rHXhzeRl5or1Db/vWxBsW6SCW7wyXzWLKIJdcH03UIb+g7CpM4DTX3263XYHUmEcXSJlVYh+2IxaLSNSTB6N7xK6zDbOhs/j0GKyqn/ZBPtjc5DGNkEogLz9FigLPCvW6HR2ZCKx6LrJObAPf7LU7igCYVWJP4QnuVar3c+CLWkzjAIkxjze5wyWmo2SmWXB9MmcWK0gZqp2tDDroxX047a6wD13EYLmJtk+egGbFclqTeQp7ZYQEL/SjPYi3rHWNF4Kgf8unuBidxQJxEmnnJcVVTuMRL3RWAC1hXxu5ev8OjMDmH9doFL/081mnUhG2bPLvDJQfdmIHr2K/nTGPNwHUZa+KVdjvL9Wux9ulMho/bAW2TsUajCzoz1m7LsNkK4q3TLeDFc59fAr7jjW5KOX5sREgLz2lT8fHlbWrbM6k6TiIs2wJrheNuQGm3Gbt2rZSiWE5DRWU9bSqyMDsGLnvSudQtYtcemFacqAHok27cddwPmfUVzugmZad9TRJDEIvPscMgljZ6lvbMG1+tcjzpVJnJ7GyHrfUq4D6voPSSk71CmhUcNQM+vryt4YZBS9uNWbYlziUedmMAxr5dG6solnlQr3wZyzXWzvu1Mv9KWNvk6ZJu3HUcFOuhHZEwnPY1NogmLY3oSmsjLGPBLP9U3nmsR23+1Y3p2bbL69XcvcbCdWm9Yo2zgoNmxKeaZwB0/cGjimVbUhSBe802bekZum6NtU+OeSgpbGQeKpaxoBdL8I7K9l8V6zxWxGTpk+OgH7EIJYfdiCCW065mYUuWsbiAtU1+XeXVJb9eqXva1mdY3WuxrraUXv2ASj8rediO+VTzDFEsxaAnHNYs25K67Plyu81OoV4q5BlPKpiHkmM7JGFoo4ZLktg3xHoa6jXPh92IWV9x4Efad31FFz1D362xBpPWCnJ1X7takdznXf9WWF0ujF9hzVtKmwAkQz8vebnZYeyfoUmFbq+89MyXFZNhy0vtLhPfXMC6iCXzUHLQjS9gPY/pK2E97lXu2uRZxoJF0MVl81Ax6yst5vB54dyrsCax6/G7CCWLvtBk9zRvMZ3H6mrsPq1k5Gv8HUxjzH8IfJ+I/KX8+T8CvkNE/tqrrlv/IAzwQeDjXzu73xDaBx694VVvPz0JfDwJPMCTwceTwAM8GXw8CTzAk8HHk8LDSESufqMf/PXMAF4G7pz7fDufu0DnfxDGGPM7IvLhr6PNr5ueBB6eFD6eBB6eFD6eBB6eFD6eBB6eFD6eIB7uvh3Ptm98yVek3wbebYx5zhhTAj+E/kbAhja0oQ1t6I8Afc0zABEJxpi/BvwrtAz0H4rIJ75hnG1oQxva0IbeVvq61gGIyD8H/vlbuOUnv572vkH0JPAATwYfTwIP8GTw8STwAE8GH08CD/Bk8PH/ax6+5iTwhja0oQ1t6I82fT05gA1taEMb2tAfYdoYgA1taEMbelpJRN72P+D7gM8AzwM/8jY8/x8CD4CPnzu3B/wK8Nn8fzefN8D/lHn5GPCt5+754Xz9Z4Effos83AF+HV0J/Qngrz8mPmrgt4CPZj7+Zj7/HPCbub2fBcp8vsqfn8/f3z33rB/N5z8D/KmvoV8c8HvALz0OHoAvAn8A/D7wO4+jP/L9O8DPA58GPgV812XyAbwnv4PV3ynwNx7Tu/gvslx+HPjpLK+XLRd/Pbf/CeBvXJZc8DbrKeDbUHl/Pt9r3pCnt9qBX0OHO+BzwDuBElVM7/8Gt/E9wLe+6sX+bbKxAX4E+Fv5+AeAf5Ff8HcCv3muIz6f/+/m4923wMPNVScBE+APgfc/Bj4MMM7HRR443wn8HPBD+fzfA/6zfPxXgL+Xj38I+Nl8/P7cVxU6QD8HuLfYL/8l8E84MwCXygNqAPZfde5S+yM/46eAv5SPS9QgXDof58bjK8A7HoNs3gK+AAzOycN/fJlywdli1CFaBPOrwLsu413wNusp1PH7znzPvwC+/w3fx1sVoK9B4L4L+FfnPv8o8KNvQzt3X/ViPwPczMc3gc/k458A/sKrrwP+AvAT585fuO5r4OefoRvlPTY+spD/LrpFxyPAv7pP0DLe78rHPl9nXt1P5697k23fBn4N+PeAX8rPvGwevshrDcCl9gewjSo98zj5OHffnwT+n8f0Llbbx+zlfv4l4E9dplwAfw74B+c+/zfAf3VZ74K3SU/l7z597vyF677S32XkAF5vz6Bbl9DudRG5l49fAa6/AT/fMD6NMXeBP45635fOhzHGGWN+H51u/grqIR2LyGqnsfPPXLeXvz8BrnwD+Pg76MBa7X525THwIMAvG2M+krckgcvvj+eAh8D/Zoz5PWPM3zfGjB4DHyv6ITT0wmXzICIvA/8j8AJwD+3nj3C5cvFx4N8xxlwxxgxRT/sOj68/vlHt3srHb4mfpyIJLGoS5TLaMsaMgf8TjS2ePg4+RCSKyIdQL/zbgfe+3W2eJ2PMDwIPROQjl9nu69B3i8i3At8P/FVjzPec//KS+sOj0/7/VUT+ODBHp/qXzQd5xf6fAf6PV393GTwYY3bRHYOfA54BRmh+8NJIRD4F/C3gl4F/ieZE4quuuTR98bjbvQwD8Kb2DHob6L4x5iZA/v/gDfj5uvk0xhSo8v/fReSfPi4+ViQix2hi+ruAHWPMauHf+Weu28vfbwMHXycf/zbwZ4wxXwR+Bg0D/d1L5mHlcSIiD4BfQI3hZffHS8BLIvKb+fPPowbhccjF9wO/KyL38+fL5uHfB74gIg9FpAf+KSorly0X/0BEvk1Evgc4QvN1j2ucfqPafTkfvzV+3moM8a3+oR7Q51Grv0oCf+BtaOcuF2Nr/wMXkyt/Ox//aS4mV34rn99DY7W7+e8LwN5baN8A/wj4O686f9l8XAV28vEA+A3gB1Gv73yi7a/k47/KxUTbz+XjD3Ax0fZ53mISOD/nezlLAl8aD6h3OTl3/G9Qb/NS+yM/4zeA9+Tj/y7z8Dj4+BngP3mMsvkdaOXNMD/7p4D//LJlE7iW/z+LVmbtXNa74G3UU7w2CfwDb8jPWx3QX8sfGmf7QzQW/WNvw/N/Go0p9qjH9RfRWOGvoaVSv3ruJRn0l8w+h5ZMffjcc/5TtITq+fMD5U3y8N3o9O1jnJXb/cBj4ONb0NLLj6Hxzv82n39nFpDn0QFX5fN1/vx8/v6d5571Y5m/z/AmKgq+Aj/fy5kBuDQeclsf5awc9sfy+Uvtj3z/h4DfyX3yf6ED97LlYoR6z9vnzj2Od/E3UaX7ceAfo0r8UmUTNcifzLLxJy7rXfA26yngw/m9fg74n3kTZaCbrSA2tKENbegppaciCbyhDW1oQxt6LW0MwIY2tKENPaW0MQAb2tCGNvSU0sYAbGhDG9rQU0obA7ChDW1oQ08pbQzAhja0oQ09pbQxABva0IY29JTS/wd9Qsjm830uOAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "waveform = inputs.input_features.squeeze().cpu()\n",
    "fig, ax = plt.subplots()\n",
    "cmap='viridis'\n",
    "\n",
    "x_ticks = np.arange(0, waveform.shape[0], 100)\n",
    "data = ax.imshow(waveform.transpose(1,0), cmap=cmap, origin='lower')\n",
    "ax.set_xticks(x_ticks, 10*x_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,   200,   400,   600,   800,  1000,  1200,  1400,  1600,\n",
       "        1800,  2000,  2200,  2400,  2600,  2800,  3000,  3200,  3400,\n",
       "        3600,  3800,  4000,  4200,  4400,  4600,  4800,  5000,  5200,\n",
       "        5400,  5600,  5800,  6000,  6200,  6400,  6600,  6800,  7000,\n",
       "        7200,  7400,  7600,  7800,  8000,  8200,  8400,  8600,  8800,\n",
       "        9000,  9200,  9400,  9600,  9800, 10000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ticks*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_embed = model.get_audio_features(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1001, 64])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': ClapModel(\n",
       "   (text_model): ClapTextModel(\n",
       "     (embeddings): ClapTextEmbeddings(\n",
       "       (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "       (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "       (token_type_embeddings): Embedding(1, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): ClapTextEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0-11): 12 x ClapTextLayer(\n",
       "           (attention): ClapTextAttention(\n",
       "             (self): ClapTextSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): ClapTextSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): ClapTextIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): ClapTextOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (pooler): ClapTextPooler(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (activation): Tanh()\n",
       "     )\n",
       "   )\n",
       "   (text_projection): ClapProjectionLayer(\n",
       "     (linear1): Linear(in_features=768, out_features=512, bias=True)\n",
       "     (activation): ReLU()\n",
       "     (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       "   (audio_model): ClapAudioModel(\n",
       "     (audio_encoder): ClapAudioEncoder(\n",
       "       (patch_embed): ClapAudioPatchEmbed(\n",
       "         (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "         (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "       )\n",
       "       (layers): ModuleList(\n",
       "         (0): ClapAudioStage(\n",
       "           (blocks): ModuleList(\n",
       "             (0-1): 2 x ClapAudioLayer(\n",
       "               (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "               (attention): ClapAudioAttention(\n",
       "                 (self): ClapAudioSelfAttention(\n",
       "                   (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                   (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                   (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                   (dropout): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "                 (output): ClapAudioSelfOutput(\n",
       "                   (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                   (dropout): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (drop_path): Identity()\n",
       "               (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "               (intermediate): ClapAudioIntermediate(\n",
       "                 (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "                 (intermediate_act_fn): GELUActivation()\n",
       "               )\n",
       "               (output): ClapAudioOutput(\n",
       "                 (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (downsample): ClapAudioPatchMerging(\n",
       "             (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "             (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "         (1): ClapAudioStage(\n",
       "           (blocks): ModuleList(\n",
       "             (0-1): 2 x ClapAudioLayer(\n",
       "               (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "               (attention): ClapAudioAttention(\n",
       "                 (self): ClapAudioSelfAttention(\n",
       "                   (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                   (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                   (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                   (dropout): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "                 (output): ClapAudioSelfOutput(\n",
       "                   (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                   (dropout): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (drop_path): Identity()\n",
       "               (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "               (intermediate): ClapAudioIntermediate(\n",
       "                 (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                 (intermediate_act_fn): GELUActivation()\n",
       "               )\n",
       "               (output): ClapAudioOutput(\n",
       "                 (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (downsample): ClapAudioPatchMerging(\n",
       "             (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "             (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "         (2): ClapAudioStage(\n",
       "           (blocks): ModuleList(\n",
       "             (0-11): 12 x ClapAudioLayer(\n",
       "               (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "               (attention): ClapAudioAttention(\n",
       "                 (self): ClapAudioSelfAttention(\n",
       "                   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                   (dropout): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "                 (output): ClapAudioSelfOutput(\n",
       "                   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                   (dropout): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (drop_path): Identity()\n",
       "               (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "               (intermediate): ClapAudioIntermediate(\n",
       "                 (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                 (intermediate_act_fn): GELUActivation()\n",
       "               )\n",
       "               (output): ClapAudioOutput(\n",
       "                 (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "           (downsample): ClapAudioPatchMerging(\n",
       "             (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "             (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "           )\n",
       "         )\n",
       "         (3): ClapAudioStage(\n",
       "           (blocks): ModuleList(\n",
       "             (0-1): 2 x ClapAudioLayer(\n",
       "               (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (attention): ClapAudioAttention(\n",
       "                 (self): ClapAudioSelfAttention(\n",
       "                   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                   (dropout): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "                 (output): ClapAudioSelfOutput(\n",
       "                   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                   (dropout): Dropout(p=0.0, inplace=False)\n",
       "                 )\n",
       "               )\n",
       "               (drop_path): Identity()\n",
       "               (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "               (intermediate): ClapAudioIntermediate(\n",
       "                 (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                 (intermediate_act_fn): GELUActivation()\n",
       "               )\n",
       "               (output): ClapAudioOutput(\n",
       "                 (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                 (dropout): Dropout(p=0.1, inplace=False)\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "       (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "     )\n",
       "   )\n",
       "   (audio_projection): ClapProjectionLayer(\n",
       "     (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "     (activation): ReLU()\n",
       "     (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'text_model': ClapTextModel(\n",
       "   (embeddings): ClapTextEmbeddings(\n",
       "     (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "     (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "     (token_type_embeddings): Embedding(1, 768)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (encoder): ClapTextEncoder(\n",
       "     (layer): ModuleList(\n",
       "       (0-11): 12 x ClapTextLayer(\n",
       "         (attention): ClapTextAttention(\n",
       "           (self): ClapTextSelfAttention(\n",
       "             (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "           (output): ClapTextSelfOutput(\n",
       "             (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (intermediate): ClapTextIntermediate(\n",
       "           (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): ClapTextOutput(\n",
       "           (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (pooler): ClapTextPooler(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (activation): Tanh()\n",
       "   )\n",
       " ),\n",
       " 'text_model.embeddings': ClapTextEmbeddings(\n",
       "   (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "   (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "   (token_type_embeddings): Embedding(1, 768)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.embeddings.word_embeddings': Embedding(50265, 768, padding_idx=1),\n",
       " 'text_model.embeddings.position_embeddings': Embedding(514, 768, padding_idx=1),\n",
       " 'text_model.embeddings.token_type_embeddings': Embedding(1, 768),\n",
       " 'text_model.embeddings.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.embeddings.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder': ClapTextEncoder(\n",
       "   (layer): ModuleList(\n",
       "     (0-11): 12 x ClapTextLayer(\n",
       "       (attention): ClapTextAttention(\n",
       "         (self): ClapTextSelfAttention(\n",
       "           (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "         (output): ClapTextSelfOutput(\n",
       "           (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (intermediate): ClapTextIntermediate(\n",
       "         (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): ClapTextOutput(\n",
       "         (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer': ModuleList(\n",
       "   (0-11): 12 x ClapTextLayer(\n",
       "     (attention): ClapTextAttention(\n",
       "       (self): ClapTextSelfAttention(\n",
       "         (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "       (output): ClapTextSelfOutput(\n",
       "         (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (intermediate): ClapTextIntermediate(\n",
       "       (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): ClapTextOutput(\n",
       "       (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.0': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.0.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.0.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.0.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.0.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.0.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.0.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.0.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.0.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.0.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.0.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.0.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.0.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.0.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.0.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.0.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.0.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.0.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.1': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.1.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.1.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.1.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.1.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.1.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.1.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.1.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.1.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.1.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.1.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.1.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.1.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.1.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.1.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.1.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.1.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.1.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.2': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.2.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.2.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.2.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.2.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.2.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.2.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.2.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.2.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.2.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.2.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.2.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.2.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.2.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.2.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.2.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.2.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.2.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.3': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.3.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.3.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.3.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.3.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.3.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.3.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.3.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.3.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.3.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.3.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.3.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.3.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.3.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.3.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.3.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.3.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.3.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.4': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.4.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.4.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.4.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.4.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.4.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.4.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.4.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.4.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.4.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.4.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.4.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.4.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.4.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.4.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.4.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.4.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.4.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.5': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.5.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.5.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.5.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.5.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.5.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.5.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.5.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.5.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.5.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.5.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.5.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.5.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.5.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.5.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.5.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.5.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.5.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.6': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.6.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.6.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.6.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.6.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.6.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.6.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.6.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.6.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.6.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.6.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.6.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.6.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.6.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.6.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.6.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.6.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.6.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.7': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.7.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.7.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.7.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.7.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.7.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.7.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.7.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.7.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.7.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.7.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.7.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.7.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.7.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.7.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.7.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.7.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.7.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.8': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.8.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.8.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.8.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.8.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.8.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.8.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.8.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.8.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.8.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.8.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.8.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.8.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.8.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.8.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.8.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.8.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.8.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.9': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.9.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.9.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.9.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.9.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.9.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.9.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.9.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.9.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.9.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.9.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.9.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.9.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.9.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.9.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.9.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.9.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.9.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.10': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.10.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.10.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.10.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.10.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.10.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.10.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.10.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.10.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.10.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.10.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.10.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.10.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.10.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.10.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.10.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.10.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.10.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.11': ClapTextLayer(\n",
       "   (attention): ClapTextAttention(\n",
       "     (self): ClapTextSelfAttention(\n",
       "       (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (output): ClapTextSelfOutput(\n",
       "       (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (intermediate): ClapTextIntermediate(\n",
       "     (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapTextOutput(\n",
       "     (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.11.attention': ClapTextAttention(\n",
       "   (self): ClapTextSelfAttention(\n",
       "     (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       "   (output): ClapTextSelfOutput(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'text_model.encoder.layer.11.attention.self': ClapTextSelfAttention(\n",
       "   (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.11.attention.self.query': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.11.attention.self.key': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.11.attention.self.value': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.11.attention.self.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.11.attention.output': ClapTextSelfOutput(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.11.attention.output.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.11.attention.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.11.attention.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.encoder.layer.11.intermediate': ClapTextIntermediate(\n",
       "   (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'text_model.encoder.layer.11.intermediate.dense': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'text_model.encoder.layer.11.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'text_model.encoder.layer.11.output': ClapTextOutput(\n",
       "   (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'text_model.encoder.layer.11.output.dense': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'text_model.encoder.layer.11.output.LayerNorm': LayerNorm((768,), eps=1e-12, elementwise_affine=True),\n",
       " 'text_model.encoder.layer.11.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'text_model.pooler': ClapTextPooler(\n",
       "   (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (activation): Tanh()\n",
       " ),\n",
       " 'text_model.pooler.dense': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'text_model.pooler.activation': Tanh(),\n",
       " 'text_projection': ClapProjectionLayer(\n",
       "   (linear1): Linear(in_features=768, out_features=512, bias=True)\n",
       "   (activation): ReLU()\n",
       "   (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       " ),\n",
       " 'text_projection.linear1': Linear(in_features=768, out_features=512, bias=True),\n",
       " 'text_projection.activation': ReLU(),\n",
       " 'text_projection.linear2': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model': ClapAudioModel(\n",
       "   (audio_encoder): ClapAudioEncoder(\n",
       "     (patch_embed): ClapAudioPatchEmbed(\n",
       "       (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "       (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (layers): ModuleList(\n",
       "       (0): ClapAudioStage(\n",
       "         (blocks): ModuleList(\n",
       "           (0-1): 2 x ClapAudioLayer(\n",
       "             (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "             (attention): ClapAudioAttention(\n",
       "               (self): ClapAudioSelfAttention(\n",
       "                 (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "                 (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "                 (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "                 (dropout): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "               (output): ClapAudioSelfOutput(\n",
       "                 (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "                 (dropout): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): Identity()\n",
       "             (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "             (intermediate): ClapAudioIntermediate(\n",
       "               (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): ClapAudioOutput(\n",
       "               (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (downsample): ClapAudioPatchMerging(\n",
       "           (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "           (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (1): ClapAudioStage(\n",
       "         (blocks): ModuleList(\n",
       "           (0-1): 2 x ClapAudioLayer(\n",
       "             (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "             (attention): ClapAudioAttention(\n",
       "               (self): ClapAudioSelfAttention(\n",
       "                 (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                 (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                 (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                 (dropout): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "               (output): ClapAudioSelfOutput(\n",
       "                 (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                 (dropout): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): Identity()\n",
       "             (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "             (intermediate): ClapAudioIntermediate(\n",
       "               (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): ClapAudioOutput(\n",
       "               (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (downsample): ClapAudioPatchMerging(\n",
       "           (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "           (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (2): ClapAudioStage(\n",
       "         (blocks): ModuleList(\n",
       "           (0-11): 12 x ClapAudioLayer(\n",
       "             (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (attention): ClapAudioAttention(\n",
       "               (self): ClapAudioSelfAttention(\n",
       "                 (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "                 (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "                 (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "                 (dropout): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "               (output): ClapAudioSelfOutput(\n",
       "                 (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "                 (dropout): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): Identity()\n",
       "             (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "             (intermediate): ClapAudioIntermediate(\n",
       "               (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): ClapAudioOutput(\n",
       "               (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (downsample): ClapAudioPatchMerging(\n",
       "           (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "           (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "         )\n",
       "       )\n",
       "       (3): ClapAudioStage(\n",
       "         (blocks): ModuleList(\n",
       "           (0-1): 2 x ClapAudioLayer(\n",
       "             (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (attention): ClapAudioAttention(\n",
       "               (self): ClapAudioSelfAttention(\n",
       "                 (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                 (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                 (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                 (dropout): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "               (output): ClapAudioSelfOutput(\n",
       "                 (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                 (dropout): Dropout(p=0.0, inplace=False)\n",
       "               )\n",
       "             )\n",
       "             (drop_path): Identity()\n",
       "             (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "             (intermediate): ClapAudioIntermediate(\n",
       "               (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "               (intermediate_act_fn): GELUActivation()\n",
       "             )\n",
       "             (output): ClapAudioOutput(\n",
       "               (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder': ClapAudioEncoder(\n",
       "   (patch_embed): ClapAudioPatchEmbed(\n",
       "     (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "     (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (layers): ModuleList(\n",
       "     (0): ClapAudioStage(\n",
       "       (blocks): ModuleList(\n",
       "         (0-1): 2 x ClapAudioLayer(\n",
       "           (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "           (attention): ClapAudioAttention(\n",
       "             (self): ClapAudioSelfAttention(\n",
       "               (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "               (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "               (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "               (dropout): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "             (output): ClapAudioSelfOutput(\n",
       "               (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "               (dropout): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): Identity()\n",
       "           (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "           (intermediate): ClapAudioIntermediate(\n",
       "             (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): ClapAudioOutput(\n",
       "             (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (downsample): ClapAudioPatchMerging(\n",
       "         (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "         (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "     (1): ClapAudioStage(\n",
       "       (blocks): ModuleList(\n",
       "         (0-1): 2 x ClapAudioLayer(\n",
       "           (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "           (attention): ClapAudioAttention(\n",
       "             (self): ClapAudioSelfAttention(\n",
       "               (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "               (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "               (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "               (dropout): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "             (output): ClapAudioSelfOutput(\n",
       "               (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "               (dropout): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): Identity()\n",
       "           (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "           (intermediate): ClapAudioIntermediate(\n",
       "             (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): ClapAudioOutput(\n",
       "             (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (downsample): ClapAudioPatchMerging(\n",
       "         (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "         (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "     (2): ClapAudioStage(\n",
       "       (blocks): ModuleList(\n",
       "         (0-11): 12 x ClapAudioLayer(\n",
       "           (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           (attention): ClapAudioAttention(\n",
       "             (self): ClapAudioSelfAttention(\n",
       "               (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "               (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "               (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "               (dropout): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "             (output): ClapAudioSelfOutput(\n",
       "               (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "               (dropout): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): Identity()\n",
       "           (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "           (intermediate): ClapAudioIntermediate(\n",
       "             (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): ClapAudioOutput(\n",
       "             (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "       (downsample): ClapAudioPatchMerging(\n",
       "         (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "         (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "       )\n",
       "     )\n",
       "     (3): ClapAudioStage(\n",
       "       (blocks): ModuleList(\n",
       "         (0-1): 2 x ClapAudioLayer(\n",
       "           (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (attention): ClapAudioAttention(\n",
       "             (self): ClapAudioSelfAttention(\n",
       "               (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (dropout): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "             (output): ClapAudioSelfOutput(\n",
       "               (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "               (dropout): Dropout(p=0.0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (drop_path): Identity()\n",
       "           (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "           (intermediate): ClapAudioIntermediate(\n",
       "             (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): ClapAudioOutput(\n",
       "             (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (batch_norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "   (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       " ),\n",
       " 'audio_model.audio_encoder.patch_embed': ClapAudioPatchEmbed(\n",
       "   (proj): Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "   (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " 'audio_model.audio_encoder.patch_embed.proj': Conv2d(1, 128, kernel_size=(4, 4), stride=(4, 4)),\n",
       " 'audio_model.audio_encoder.patch_embed.norm': LayerNorm((128,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers': ModuleList(\n",
       "   (0): ClapAudioStage(\n",
       "     (blocks): ModuleList(\n",
       "       (0-1): 2 x ClapAudioLayer(\n",
       "         (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "         (attention): ClapAudioAttention(\n",
       "           (self): ClapAudioSelfAttention(\n",
       "             (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "             (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "             (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (output): ClapAudioSelfOutput(\n",
       "             (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): Identity()\n",
       "         (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "         (intermediate): ClapAudioIntermediate(\n",
       "           (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): ClapAudioOutput(\n",
       "           (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (downsample): ClapAudioPatchMerging(\n",
       "       (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "       (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       "   (1): ClapAudioStage(\n",
       "     (blocks): ModuleList(\n",
       "       (0-1): 2 x ClapAudioLayer(\n",
       "         (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (attention): ClapAudioAttention(\n",
       "           (self): ClapAudioSelfAttention(\n",
       "             (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "             (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "             (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (output): ClapAudioSelfOutput(\n",
       "             (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): Identity()\n",
       "         (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "         (intermediate): ClapAudioIntermediate(\n",
       "           (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): ClapAudioOutput(\n",
       "           (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (downsample): ClapAudioPatchMerging(\n",
       "       (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "       (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       "   (2): ClapAudioStage(\n",
       "     (blocks): ModuleList(\n",
       "       (0-11): 12 x ClapAudioLayer(\n",
       "         (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "         (attention): ClapAudioAttention(\n",
       "           (self): ClapAudioSelfAttention(\n",
       "             (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (output): ClapAudioSelfOutput(\n",
       "             (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): Identity()\n",
       "         (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "         (intermediate): ClapAudioIntermediate(\n",
       "           (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): ClapAudioOutput(\n",
       "           (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (downsample): ClapAudioPatchMerging(\n",
       "       (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "       (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "   )\n",
       "   (3): ClapAudioStage(\n",
       "     (blocks): ModuleList(\n",
       "       (0-1): 2 x ClapAudioLayer(\n",
       "         (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         (attention): ClapAudioAttention(\n",
       "           (self): ClapAudioSelfAttention(\n",
       "             (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (output): ClapAudioSelfOutput(\n",
       "             (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "             (dropout): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (drop_path): Identity()\n",
       "         (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "         (intermediate): ClapAudioIntermediate(\n",
       "           (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "           (intermediate_act_fn): GELUActivation()\n",
       "         )\n",
       "         (output): ClapAudioOutput(\n",
       "           (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "           (dropout): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0': ClapAudioStage(\n",
       "   (blocks): ModuleList(\n",
       "     (0-1): 2 x ClapAudioLayer(\n",
       "       (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "       (attention): ClapAudioAttention(\n",
       "         (self): ClapAudioSelfAttention(\n",
       "           (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "           (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "           (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "         (output): ClapAudioSelfOutput(\n",
       "           (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "       (intermediate): ClapAudioIntermediate(\n",
       "         (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): ClapAudioOutput(\n",
       "         (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (downsample): ClapAudioPatchMerging(\n",
       "     (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "     (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks': ModuleList(\n",
       "   (0-1): 2 x ClapAudioLayer(\n",
       "     (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "     (attention): ClapAudioAttention(\n",
       "       (self): ClapAudioSelfAttention(\n",
       "         (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "         (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "         (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (output): ClapAudioSelfOutput(\n",
       "         (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): Identity()\n",
       "     (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "     (intermediate): ClapAudioIntermediate(\n",
       "       (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): ClapAudioOutput(\n",
       "       (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "       (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "       (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.layernorm_before': LayerNorm((128,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention.self.query': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention.self.key': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention.self.value': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention.output.dense': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.layernorm_after': LayerNorm((128,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.intermediate.dense': Linear(in_features=128, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.output.dense': Linear(in_features=512, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.0.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "       (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "       (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.layernorm_before': LayerNorm((128,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention.self.query': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention.self.key': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention.self.value': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention.output.dense': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.layernorm_after': LayerNorm((128,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.intermediate.dense': Linear(in_features=128, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.output.dense': Linear(in_features=512, out_features=128, bias=True),\n",
       " 'audio_model.audio_encoder.layers.0.blocks.1.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.0.downsample': ClapAudioPatchMerging(\n",
       "   (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "   (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.0.downsample.reduction': Linear(in_features=512, out_features=256, bias=False),\n",
       " 'audio_model.audio_encoder.layers.0.downsample.norm': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.1': ClapAudioStage(\n",
       "   (blocks): ModuleList(\n",
       "     (0-1): 2 x ClapAudioLayer(\n",
       "       (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "       (attention): ClapAudioAttention(\n",
       "         (self): ClapAudioSelfAttention(\n",
       "           (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "         (output): ClapAudioSelfOutput(\n",
       "           (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "       (intermediate): ClapAudioIntermediate(\n",
       "         (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): ClapAudioOutput(\n",
       "         (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (downsample): ClapAudioPatchMerging(\n",
       "     (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "     (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks': ModuleList(\n",
       "   (0-1): 2 x ClapAudioLayer(\n",
       "     (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "     (attention): ClapAudioAttention(\n",
       "       (self): ClapAudioSelfAttention(\n",
       "         (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "         (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "         (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (output): ClapAudioSelfOutput(\n",
       "         (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): Identity()\n",
       "     (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "     (intermediate): ClapAudioIntermediate(\n",
       "       (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): ClapAudioOutput(\n",
       "       (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.layernorm_before': LayerNorm((256,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention.self.query': Linear(in_features=256, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention.self.key': Linear(in_features=256, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention.self.value': Linear(in_features=256, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention.output.dense': Linear(in_features=256, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.layernorm_after': LayerNorm((256,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.intermediate.dense': Linear(in_features=256, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.output.dense': Linear(in_features=1024, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.0.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.layernorm_before': LayerNorm((256,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention.self.query': Linear(in_features=256, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention.self.key': Linear(in_features=256, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention.self.value': Linear(in_features=256, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention.output.dense': Linear(in_features=256, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.layernorm_after': LayerNorm((256,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.intermediate.dense': Linear(in_features=256, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.output.dense': Linear(in_features=1024, out_features=256, bias=True),\n",
       " 'audio_model.audio_encoder.layers.1.blocks.1.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.1.downsample': ClapAudioPatchMerging(\n",
       "   (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "   (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.1.downsample.reduction': Linear(in_features=1024, out_features=512, bias=False),\n",
       " 'audio_model.audio_encoder.layers.1.downsample.norm': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2': ClapAudioStage(\n",
       "   (blocks): ModuleList(\n",
       "     (0-11): 12 x ClapAudioLayer(\n",
       "       (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "       (attention): ClapAudioAttention(\n",
       "         (self): ClapAudioSelfAttention(\n",
       "           (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "           (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "           (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "         (output): ClapAudioSelfOutput(\n",
       "           (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "       (intermediate): ClapAudioIntermediate(\n",
       "         (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): ClapAudioOutput(\n",
       "         (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (downsample): ClapAudioPatchMerging(\n",
       "     (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "     (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks': ModuleList(\n",
       "   (0-11): 12 x ClapAudioLayer(\n",
       "     (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "     (attention): ClapAudioAttention(\n",
       "       (self): ClapAudioSelfAttention(\n",
       "         (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "         (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "         (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (output): ClapAudioSelfOutput(\n",
       "         (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): Identity()\n",
       "     (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "     (intermediate): ClapAudioIntermediate(\n",
       "       (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): ClapAudioOutput(\n",
       "       (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.0.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.1.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.2.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.3.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.4.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.5.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.6.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.7.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.8.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.9.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.10.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.layernorm_before': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention.self.query': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention.self.key': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention.self.value': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention.output.dense': Linear(in_features=512, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.layernorm_after': LayerNorm((512,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.intermediate.dense': Linear(in_features=512, out_features=2048, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.output.dense': Linear(in_features=2048, out_features=512, bias=True),\n",
       " 'audio_model.audio_encoder.layers.2.blocks.11.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.2.downsample': ClapAudioPatchMerging(\n",
       "   (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "   (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.2.downsample.reduction': Linear(in_features=2048, out_features=1024, bias=False),\n",
       " 'audio_model.audio_encoder.layers.2.downsample.norm': LayerNorm((2048,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.3': ClapAudioStage(\n",
       "   (blocks): ModuleList(\n",
       "     (0-1): 2 x ClapAudioLayer(\n",
       "       (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "       (attention): ClapAudioAttention(\n",
       "         (self): ClapAudioSelfAttention(\n",
       "           (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "         (output): ClapAudioSelfOutput(\n",
       "           (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "           (dropout): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (drop_path): Identity()\n",
       "       (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "       (intermediate): ClapAudioIntermediate(\n",
       "         (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "         (intermediate_act_fn): GELUActivation()\n",
       "       )\n",
       "       (output): ClapAudioOutput(\n",
       "         (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "         (dropout): Dropout(p=0.1, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks': ModuleList(\n",
       "   (0-1): 2 x ClapAudioLayer(\n",
       "     (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     (attention): ClapAudioAttention(\n",
       "       (self): ClapAudioSelfAttention(\n",
       "         (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "         (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "         (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "       (output): ClapAudioSelfOutput(\n",
       "         (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "         (dropout): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (drop_path): Identity()\n",
       "     (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "     (intermediate): ClapAudioIntermediate(\n",
       "       (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "       (intermediate_act_fn): GELUActivation()\n",
       "     )\n",
       "     (output): ClapAudioOutput(\n",
       "       (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "       (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "       (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.layernorm_before': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention.self.query': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention.self.key': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention.self.value': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention.output.dense': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.layernorm_after': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.intermediate.dense': Linear(in_features=1024, out_features=4096, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.output.dense': Linear(in_features=4096, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.0.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1': ClapAudioLayer(\n",
       "   (layernorm_before): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "   (attention): ClapAudioAttention(\n",
       "     (self): ClapAudioSelfAttention(\n",
       "       (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "       (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "       (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "     (output): ClapAudioSelfOutput(\n",
       "       (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "       (dropout): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (drop_path): Identity()\n",
       "   (layernorm_after): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "   (intermediate): ClapAudioIntermediate(\n",
       "     (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "     (intermediate_act_fn): GELUActivation()\n",
       "   )\n",
       "   (output): ClapAudioOutput(\n",
       "     (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.layernorm_before': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention': ClapAudioAttention(\n",
       "   (self): ClapAudioSelfAttention(\n",
       "     (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       "   (output): ClapAudioSelfOutput(\n",
       "     (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "     (dropout): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention.self': ClapAudioSelfAttention(\n",
       "   (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention.self.query': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention.self.key': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention.self.value': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention.self.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention.output': ClapAudioSelfOutput(\n",
       "   (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "   (dropout): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention.output.dense': Linear(in_features=1024, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.attention.output.dropout': Dropout(p=0.0, inplace=False),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.drop_path': Identity(),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.layernorm_after': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.intermediate': ClapAudioIntermediate(\n",
       "   (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "   (intermediate_act_fn): GELUActivation()\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.intermediate.dense': Linear(in_features=1024, out_features=4096, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.intermediate.intermediate_act_fn': GELUActivation(),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.output': ClapAudioOutput(\n",
       "   (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.output.dense': Linear(in_features=4096, out_features=1024, bias=True),\n",
       " 'audio_model.audio_encoder.layers.3.blocks.1.output.dropout': Dropout(p=0.1, inplace=False),\n",
       " 'audio_model.audio_encoder.batch_norm': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " 'audio_model.audio_encoder.norm': LayerNorm((1024,), eps=1e-05, elementwise_affine=True),\n",
       " 'audio_model.audio_encoder.avgpool': AdaptiveAvgPool1d(output_size=1),\n",
       " 'audio_projection': ClapProjectionLayer(\n",
       "   (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "   (activation): ReLU()\n",
       "   (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       " ),\n",
       " 'audio_projection.linear1': Linear(in_features=1024, out_features=512, bias=True),\n",
       " 'audio_projection.activation': ReLU(),\n",
       " 'audio_projection.linear2': Linear(in_features=512, out_features=512, bias=True)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([*model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClapAudioLayer(\n",
       "  (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (attention): ClapAudioAttention(\n",
       "    (self): ClapAudioSelfAttention(\n",
       "      (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (output): ClapAudioSelfOutput(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (drop_path): Identity()\n",
       "  (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (intermediate): ClapAudioIntermediate(\n",
       "    (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): ClapAudioOutput(\n",
       "    (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([*model.named_modules()])['audio_model.audio_encoder.layers.0.blocks.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import ClapModel, ClapProcessor\n",
    "\n",
    "librispeech_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "audio_sample = librispeech_dummy[0]\n",
    "\n",
    "\n",
    "\n",
    "inputs = processor(audios=audio_sample[\"audio\"][\"array\"], return_tensors=\"pt\").to(0)\n",
    "audio_embed = model.get_audio_features(**inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex.computational_models.pretrained_models import CLAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = CLAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_layers = model.get_model_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio_model.audio_encoder.layers.0.blocks.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClapAudioLayer(\n",
       "  (layernorm_before): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (attention): ClapAudioAttention(\n",
       "    (self): ClapAudioSelfAttention(\n",
       "      (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (output): ClapAudioSelfOutput(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (drop_path): Identity()\n",
       "  (layernorm_after): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (intermediate): ClapAudioIntermediate(\n",
       "    (dense): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): ClapAudioOutput(\n",
       "    (dense): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = next(iter(model_layers))\n",
    "print(k)\n",
    "model_layers[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't instantiate abstract class AbstractBaseClass with abstract methods abstract_attribute\n",
      "This is an abstract attribute\n",
      "This is an implementation of the abstract method.\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod, abstractproperty\n",
    "\n",
    "class AbstractBaseClass(ABC):\n",
    "    # @abstractmethod\n",
    "    # def abstract_method(self):\n",
    "    #     pass\n",
    "    \n",
    "    @abstractproperty\n",
    "    def abstract_attribute(self):\n",
    "        pass\n",
    "\n",
    "class ConcreteClass(AbstractBaseClass):\n",
    "    def __init__(self, value):\n",
    "        self._abstract_attribute = value\n",
    "    \n",
    "    def abstract_method(self):\n",
    "        print(\"This is an implementation of the abstract method.\")\n",
    "    \n",
    "    @property\n",
    "    def abstract_attribute(self):\n",
    "        return self._abstract_attribute\n",
    "\n",
    "    @abstract_attribute.setter\n",
    "    def abstract_attribute(self, value):\n",
    "        self._abstract_attribute = value\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    abstract_instance = AbstractBaseClass()\n",
    "except TypeError as e:\n",
    "    print(e)\n",
    "\n",
    "concrete_instance = ConcreteClass(\"This is an abstract attribute\")\n",
    "print(concrete_instance.abstract_attribute)\n",
    "concrete_instance.abstract_method()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wav2vec2.feature_extractor.conv_layers.0.layer_norm',\n",
       " 'wav2vec2.feature_extractor.conv_layers.1.activation',\n",
       " 'wav2vec2.feature_extractor.conv_layers.2.activation',\n",
       " 'wav2vec2.feature_extractor.conv_layers.3.activation',\n",
       " 'wav2vec2.feature_extractor.conv_layers.4.activation',\n",
       " 'wav2vec2.feature_extractor.conv_layers.5.activation',\n",
       " 'wav2vec2.feature_projection.layer_norm',\n",
       " 'wav2vec2.encoder.pos_conv_embed.activation',\n",
       " 'wav2vec2.encoder.layer_norm',\n",
       " 'wav2vec2.encoder.layers.0.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.1.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.2.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.3.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.4.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.5.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.6.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.7.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.8.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.9.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.10.final_layer_norm',\n",
       " 'wav2vec2.encoder.layers.11.final_layer_norm']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
