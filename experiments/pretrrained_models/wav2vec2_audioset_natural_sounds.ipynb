{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-10 18:21:19.100103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-10 18:21:20.110429: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/gilbreth/cuda-toolkit/cuda-11.2.0/extras/CUPTI/lib64:/apps/gilbreth/cuda-toolkit/cuda-11.2.0/lib64:/apps/spack/gilbreth/apps/intel-mpi/2017.1.132-intel-17.0.1-p7yx74h/compilers_and_libraries_2017.1.132/linux/mpi/intel64/lib:/apps/spack/gilbreth/apps/intel-mpi/2017.1.132-intel-17.0.1-p7yx74h/compilers_and_libraries_2017.1.132/linux/mpi/mic/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/itac/2017.1.024/intel64/slib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mpi/intel64/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mpi/mic/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/ipp/lib/intel64:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mkl/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/tbb/lib/intel64/gcc4.7:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/debugger_2017/iga/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/debugger_2017/libipt/intel64/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/daal/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/lib:/usr/lib64\n",
      "2024-07-10 18:21:20.110729: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /apps/gilbreth/cuda-toolkit/cuda-11.2.0/extras/CUPTI/lib64:/apps/gilbreth/cuda-toolkit/cuda-11.2.0/lib64:/apps/spack/gilbreth/apps/intel-mpi/2017.1.132-intel-17.0.1-p7yx74h/compilers_and_libraries_2017.1.132/linux/mpi/intel64/lib:/apps/spack/gilbreth/apps/intel-mpi/2017.1.132-intel-17.0.1-p7yx74h/compilers_and_libraries_2017.1.132/linux/mpi/mic/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/itac/2017.1.024/intel64/slib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mpi/intel64/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mpi/mic/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/ipp/lib/intel64:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/mkl/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/tbb/lib/intel64/gcc4.7:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/debugger_2017/iga/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/debugger_2017/libipt/intel64/lib:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/daal/lib/intel64_lin:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/compilers_and_libraries_2017.1.132/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/apps/spack/gilbreth/apps/intel-parallel-studio/cluster.2017.1-intel-17.0.1-2off4ih/lib:/usr/lib64\n",
      "2024-07-10 18:21:20.110741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from auditory_cortex.plotters.plotter_utils import PlotterUtils\n",
    "from auditory_cortex.plotters.correlation_plotter import RegPlotter\n",
    "from auditory_cortex.analyses import Correlations\n",
    "from auditory_cortex.models import Regression\n",
    "from auditory_cortex.neural_data.neural_meta_data import NeuralMetaData\n",
    "from auditory_cortex.dataloader import DataLoader\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2vec...!\n",
      "Calculating receptive fields for all layers...\n",
      "Layer 0, RF:    10 samples, 0.62 ms, sampling_rate: 3200Hz, sampling_time: 0.312ms\n",
      "Layer 1, RF:    20 samples, 1.25 ms, sampling_rate: 1600Hz, sampling_time: 0.625ms\n",
      "Layer 2, RF:    40 samples, 2.50 ms, sampling_rate: 800Hz, sampling_time: 1.250ms\n",
      "Layer 3, RF:    80 samples, 5.00 ms, sampling_rate: 400Hz, sampling_time: 2.500ms\n",
      "Layer 4, RF:   160 samples, 10.00 ms, sampling_rate: 200Hz, sampling_time: 5.000ms\n",
      "Layer 5, RF:   240 samples, 15.00 ms, sampling_rate: 100Hz, sampling_time: 10.000ms\n",
      "Layer 6, RF:   400 samples, 25.00 ms, sampling_rate: 50Hz, sampling_time: 20.000ms\n"
     ]
    }
   ],
   "source": [
    "from auditory_cortex.utils import get_receptive_fields\n",
    "print(\"Wav2vec...!\")\n",
    "kernels = [10,3,3,3,3,2,2]\n",
    "strides = [5,2,2,2,2,2,2]\n",
    "# the last entries are kernel size and strides of the 'convolution position encoding'\n",
    "\n",
    "get_receptive_fields(kernels, strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2vec...!\n",
      "Calculating receptive fields for all layers...\n",
      "Layer 0, RF:    20 samples, 0.42 ms, sampling_rate: 4800Hz, sampling_time: 0.208ms\n",
      "Layer 1, RF:    60 samples, 1.25 ms, sampling_rate: 1600Hz, sampling_time: 0.625ms\n",
      "Layer 2, RF:   120 samples, 2.50 ms, sampling_rate: 800Hz, sampling_time: 1.250ms\n",
      "Layer 3, RF:   240 samples, 5.00 ms, sampling_rate: 400Hz, sampling_time: 2.500ms\n",
      "Layer 4, RF:   480 samples, 10.00 ms, sampling_rate: 200Hz, sampling_time: 5.000ms\n",
      "Layer 5, RF:   720 samples, 15.00 ms, sampling_rate: 100Hz, sampling_time: 10.000ms\n",
      "Layer 6, RF:  1200 samples, 25.00 ms, sampling_rate: 50Hz, sampling_time: 20.000ms\n"
     ]
    }
   ],
   "source": [
    "from auditory_cortex.utils import get_receptive_fields\n",
    "print(\"Wav2vec...!\")\n",
    "kernels = [20, 5, 3, 3, 3, 2, 2]\n",
    "strides = [10, 3, 2, 2, 2, 2, 2]\n",
    "# the last entries are kernel size and strides of the 'convolution position encoding'\n",
    "\n",
    "get_receptive_fields(kernels, strides, fs=48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
