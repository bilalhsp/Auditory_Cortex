{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47b40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import auditory_cortex.helpers as helpers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "508b3708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression object...\n",
      "Creating regression obj for: 'speech2text'\n"
     ]
    }
   ],
   "source": [
    "obj = helpers.get_regression_obj(model = 'speech2text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf698fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bdf5e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ANN features at bin-width: 20\n",
      "It takes 33.59 sec to load features...!\n",
      "# of iterations requested: 5, \n",
      "# of lambda samples per iteration: 20\n",
      "Itr: 1:\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "Out of memory allocating 2,137,153,536 bytes (allocated so far: 9,608,093,696 bytes).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/ahmedb/projects/Wav2Letter/Auditory_Cortex/experiments/pretrrained_models/wav2vec2.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgilbreth-e4/home/ahmedb/projects/Wav2Letter/Auditory_Cortex/experiments/pretrrained_models/wav2vec2.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m N_sents \u001b[39m=\u001b[39m \u001b[39m499\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgilbreth-e4/home/ahmedb/projects/Wav2Letter/Auditory_Cortex/experiments/pretrrained_models/wav2vec2.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m use_cpu \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgilbreth-e4/home/ahmedb/projects/Wav2Letter/Auditory_Cortex/experiments/pretrrained_models/wav2vec2.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m corr_dict \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49mcross_validated_regression(bin_width\u001b[39m=\u001b[39;49mbin_width, delay\u001b[39m=\u001b[39;49mdelay, N\u001b[39m=\u001b[39;49miterations,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgilbreth-e4/home/ahmedb/projects/Wav2Letter/Auditory_Cortex/experiments/pretrrained_models/wav2vec2.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                             k\u001b[39m=\u001b[39;49mk_folds_validation, N_sents\u001b[39m=\u001b[39;49mN_sents,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgilbreth-e4/home/ahmedb/projects/Wav2Letter/Auditory_Cortex/experiments/pretrrained_models/wav2vec2.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                             load_features\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, numpy\u001b[39m=\u001b[39;49muse_cpu)\n",
      "File \u001b[0;32m~/projects/Wav2Letter/Auditory_Cortex/auditory_cortex/regression.py:477\u001b[0m, in \u001b[0;36mtransformer_regression.cross_validated_regression\u001b[0;34m(self, bin_width, delay, k, num_lmbdas, N, N_sents, load_features, return_dict, numpy, sents)\u001b[0m\n\u001b[1;32m    475\u001b[0m     lmbda_loss \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mzeros(((\u001b[39mlen\u001b[39m(lmbdas),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_channels,\u001b[39m12\u001b[39m)))\n\u001b[1;32m    476\u001b[0m     start_lmbda \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 477\u001b[0m     lmbda_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_fold_CV(mapping_set\u001b[39m=\u001b[39;49mmapping_set, lmbdas\u001b[39m=\u001b[39;49mlmbdas, k\u001b[39m=\u001b[39;49mk)\n\u001b[1;32m    479\u001b[0m \u001b[39m#     for i,l in enumerate(lmbdas):\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[39m#         start_lmbda = time.time()\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[39m#         # loss = 0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \n\u001b[1;32m    509\u001b[0m \u001b[39m# #             print(f\"Takes {(end_lmbda-start_lmbda):.2f} sec, loss: {lmbda_loss[i].sum():.2f}\")\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     end_lmbda \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/projects/Wav2Letter/Auditory_Cortex/auditory_cortex/regression.py:596\u001b[0m, in \u001b[0;36mtransformer_regression.k_fold_CV\u001b[0;34m(self, mapping_set, lmbdas, k, use_cpu)\u001b[0m\n\u001b[1;32m    593\u001b[0m train_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munroll_spikes(sents\u001b[39m=\u001b[39mtrain_set, numpy\u001b[39m=\u001b[39muse_cpu)\n\u001b[1;32m    594\u001b[0m val_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munroll_spikes(sents\u001b[39m=\u001b[39mval_set, numpy\u001b[39m=\u001b[39muse_cpu)\n\u001b[0;32m--> 596\u001b[0m Beta \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mreg(train_x, train_y, lmbda)\n\u001b[1;32m    597\u001b[0m val_pred \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mpredict(val_x, Beta)\n\u001b[1;32m    598\u001b[0m \u001b[39m# to be defined...\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/Wav2Letter/Auditory_Cortex/auditory_cortex/utils.py:285\u001b[0m, in \u001b[0;36mreg\u001b[0;34m(X, y, lmbda)\u001b[0m\n\u001b[1;32m    283\u001b[0m X_T \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mtranspose((\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[1;32m    284\u001b[0m a \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mmatmul(X_T, X) \u001b[39m+\u001b[39m m\u001b[39m*\u001b[39mlmbda\u001b[39m*\u001b[39mI\n\u001b[0;32m--> 285\u001b[0m b \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39;49mmatmul(X_T, y)\n\u001b[1;32m    286\u001b[0m B \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39msolve(a,b)\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m B\u001b[39m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/cupy/_core/_gufuncs.py:684\u001b[0m, in \u001b[0;36m_GUFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m numpy\u001b[39m.\u001b[39mcan_cast(ret_dtype, outs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype, casting\u001b[39m=\u001b[39mcasting):\n\u001b[1;32m    682\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCannot cast out dtype from \u001b[39m\u001b[39m{\u001b[39;00mouts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    683\u001b[0m                         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00mret_dtype\u001b[39m}\u001b[39;00m\u001b[39m with rule \u001b[39m\u001b[39m{\u001b[39;00mcasting\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 684\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_func_to_inputs(\n\u001b[1;32m    685\u001b[0m     func, \u001b[39m0\u001b[39;49m, dimsizess, loop_output_dims, args, outs)\n\u001b[1;32m    687\u001b[0m \u001b[39m# This code credit goes to Dask\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[39m# https://github.com/dask/dask/blob/61b578f5a3ad88cbc6a8b9a73ce08c551bd969fa/dask/array/gufunc.py#L462-L503\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[39m# Treat direct output\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/cupy/_core/_gufuncs.py:399\u001b[0m, in \u001b[0;36m_GUFunc._apply_func_to_inputs\u001b[0;34m(self, func, dim, sizes, dims, args, outs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_supports_out \u001b[39mand\u001b[39;00m outs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     outs \u001b[39m=\u001b[39m outs[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(outs) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m outs\n\u001b[0;32m--> 399\u001b[0m     func(\u001b[39m*\u001b[39;49margs, out\u001b[39m=\u001b[39;49mouts)\n\u001b[1;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     fouts \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32mcupy/_core/_routines_linalg.pyx:705\u001b[0m, in \u001b[0;36mcupy._core._routines_linalg.matmul\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/_routines_linalg.pyx:786\u001b[0m, in \u001b[0;36mcupy._core._routines_linalg.matmul\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/core.pyx:2592\u001b[0m, in \u001b[0;36mcupy._core.core.ascontiguousarray\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/_core/core.pyx:171\u001b[0m, in \u001b[0;36mcupy._core.core.ndarray.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/cuda/memory.pyx:698\u001b[0m, in \u001b[0;36mcupy.cuda.memory.alloc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/cuda/memory.pyx:1375\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/cuda/memory.pyx:1396\u001b[0m, in \u001b[0;36mcupy.cuda.memory.MemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/cuda/memory.pyx:1076\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool.malloc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/cuda/memory.pyx:1097\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._malloc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mcupy/cuda/memory.pyx:1335\u001b[0m, in \u001b[0;36mcupy.cuda.memory.SingleDeviceMemoryPool._try_malloc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Out of memory allocating 2,137,153,536 bytes (allocated so far: 9,608,093,696 bytes)."
     ]
    }
   ],
   "source": [
    "return_dict = True\n",
    "bin_width = 20\n",
    "delay = 0\n",
    "iterations = 5\n",
    "k_folds_validation = 5\n",
    "N_sents = 499\n",
    "use_cpu = False\n",
    "\n",
    "corr_dict = obj.cross_validated_regression(bin_width=bin_width, delay=delay, N=iterations,\n",
    "                            k=k_folds_validation, N_sents=N_sents,\n",
    "                            load_features=True, return_dict=True, numpy=use_cpu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1934625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import auditory_cortex.utils as utils\n",
    "file_path = os.path.join(results_dir, )\n",
    "\n",
    "df = utils.write_to_disk(corr_dict, file_path, normalizer=norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e9a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "770fad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filename = f\"{obj.model_name}_corr_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee381b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations'\n",
    "filename = f\"{obj.model_name}_corr_results.csv\"\n",
    "file_path = os.path.join(results_dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffc28e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations/wav2vec2_corr_results.csv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3429e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ANN features at bin-width: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/transformers/generation_utils.py:1202: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 200 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feats = obj.load_features(sents=[12], load_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d479e0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([[ 0.16819455,  0.69381636,  0.28788525, ..., -3.3358583 ,\n",
       "         -4.178803  , -0.5019975 ],\n",
       "        [-0.11124772,  0.6130596 , -0.49511066, ..., -2.0150714 ,\n",
       "         -2.5038526 , -0.96484333],\n",
       "        [-0.2722688 ,  0.2475733 ,  0.15211618, ..., -2.3396673 ,\n",
       "         -2.4300506 , -0.50456697],\n",
       "        ...,\n",
       "        [ 0.45082942,  0.3039547 , -0.2075296 , ..., -2.5851283 ,\n",
       "         -2.555898  , -0.81837034],\n",
       "        [ 0.02958308,  0.37156802, -0.10901204, ..., -1.634827  ,\n",
       "         -2.4446187 , -0.8291217 ],\n",
       "        [ 1.042978  , -0.01557597,  0.52629215, ..., -1.4462613 ,\n",
       "         -3.0540671 ,  2.7378144 ]], dtype=float32),\n",
       " 1: array([[ 0.27751157, -0.1509359 , -0.12881841, ..., -2.5938241 ,\n",
       "         -1.6793032 , -1.5345055 ],\n",
       "        [ 0.06617635,  0.8833876 ,  0.4438695 , ..., -3.0727577 ,\n",
       "         -2.1466753 , -2.1508334 ],\n",
       "        [ 0.07393002,  1.406701  ,  0.7334309 , ..., -2.559809  ,\n",
       "         -2.8810081 , -2.4060237 ],\n",
       "        ...,\n",
       "        [ 0.24015139,  0.17763099, -0.3071067 , ..., -2.9918067 ,\n",
       "         -2.8703794 , -3.8569994 ],\n",
       "        [ 1.2297276 , -0.3202534 , -0.6326007 , ..., -2.0464475 ,\n",
       "         -2.3690603 , -2.3920832 ],\n",
       "        [ 1.0004257 , -0.49629617, -0.5485724 , ..., -1.8652375 ,\n",
       "         -1.8488303 , -1.3679034 ]], dtype=float32),\n",
       " 2: array([[-3.6478379 , -6.377675  , -1.3796629 , ...,  1.8417443 ,\n",
       "         -0.9594655 ,  2.6465967 ],\n",
       "        [-3.3854842 , -4.8388925 , -1.1524003 , ...,  1.2473706 ,\n",
       "         -0.48719928,  1.9177833 ],\n",
       "        [-1.8735292 , -3.0336864 , -0.8679242 , ...,  0.6914263 ,\n",
       "         -0.15194537, -0.17742097],\n",
       "        ...,\n",
       "        [ 0.95973724, -1.4404141 ,  0.85369533, ...,  0.34439552,\n",
       "          1.1174929 , -1.1620996 ],\n",
       "        [ 0.2999942 , -2.9131966 ,  0.58988804, ...,  1.2920103 ,\n",
       "          0.34778827, -0.78709984],\n",
       "        [-1.8744049 , -5.52918   , -0.5816831 , ...,  1.9610262 ,\n",
       "         -0.60943216,  1.1124724 ]], dtype=float32),\n",
       " 3: array([[-2.005989  , -2.3749626 , -1.8484403 , ...,  1.6920351 ,\n",
       "         -0.12134933,  1.6630754 ],\n",
       "        [-1.8527985 , -2.4228785 , -1.6904532 , ...,  1.617783  ,\n",
       "         -0.31416458,  1.3737938 ],\n",
       "        [-1.4089454 , -2.3158643 , -1.1491473 , ...,  1.3202039 ,\n",
       "         -0.03483623,  0.6066991 ],\n",
       "        ...,\n",
       "        [-1.1491979 , -0.35461113,  0.6453443 , ...,  0.7813925 ,\n",
       "          1.1848605 , -0.22697808],\n",
       "        [-1.6698282 , -1.3810298 ,  0.4061892 , ...,  1.5414265 ,\n",
       "          0.9574465 ,  0.27422708],\n",
       "        [-1.9300753 , -2.1860747 , -0.87713504, ...,  1.8139622 ,\n",
       "          0.4803582 ,  1.1706861 ]], dtype=float32),\n",
       " 4: array([[-0.4787756 ,  0.08477952,  1.0937874 , ...,  1.2970986 ,\n",
       "         -0.7605015 ,  0.98418903],\n",
       "        [-0.7269446 , -0.64217174,  0.3303487 , ...,  1.0301582 ,\n",
       "         -0.26988003,  0.70604485],\n",
       "        [-1.0361787 , -1.4858857 , -0.6311362 , ..., -0.338811  ,\n",
       "          0.6659913 , -0.1630496 ],\n",
       "        ...,\n",
       "        [-1.2781658 , -0.65444154, -0.4123253 , ...,  1.383499  ,\n",
       "          2.0337677 , -0.6943377 ],\n",
       "        [-1.4628414 , -0.6550436 ,  0.3495501 , ...,  1.5584627 ,\n",
       "          1.5141832 ,  0.13391747],\n",
       "        [-0.85071737, -0.1402927 ,  1.149594  , ...,  1.3215259 ,\n",
       "          0.16634335,  0.76592773]], dtype=float32),\n",
       " 5: array([[-0.29525825,  2.938486  ,  0.4448387 , ..., -1.3866683 ,\n",
       "          0.20781069, -0.4346433 ],\n",
       "        [-0.4681924 ,  2.6855798 , -0.20668335, ..., -1.9867102 ,\n",
       "          0.7444785 ,  0.3725182 ],\n",
       "        [-1.062729  ,  0.15567683,  0.0462389 , ..., -1.8464066 ,\n",
       "          0.7716821 ,  0.21373339],\n",
       "        ...,\n",
       "        [-0.7496237 , -1.0930247 ,  0.84155196, ..., -0.19052617,\n",
       "          3.444827  , -1.5653485 ],\n",
       "        [-1.146774  , -1.6039952 ,  0.8559651 , ...,  0.61009353,\n",
       "          3.0217202 , -1.6082686 ],\n",
       "        [-0.7985322 ,  0.438021  ,  0.934345  , ...,  0.02650654,\n",
       "          1.1438543 , -1.3003879 ]], dtype=float32),\n",
       " 6: array([[-2.718923  ,  2.025248  ,  0.799743  , ..., -1.4923013 ,\n",
       "          0.70170695, -0.50702983],\n",
       "        [-2.4311066 ,  2.7506924 ,  1.0694617 , ..., -3.9778538 ,\n",
       "          0.48389158, -0.17823942],\n",
       "        [-1.769039  ,  0.9407271 ,  0.3986822 , ..., -2.7678888 ,\n",
       "          0.62394875,  0.13018338],\n",
       "        ...,\n",
       "        [ 0.60429764, -1.2082901 ,  3.463966  , ...,  3.238135  ,\n",
       "          3.2894845 , -2.638729  ],\n",
       "        [-0.7761214 , -3.2287428 ,  2.2712655 , ...,  5.6059613 ,\n",
       "          3.5949879 , -1.2612902 ],\n",
       "        [-2.1677659 , -1.3404806 ,  0.99215364, ...,  3.4170017 ,\n",
       "          2.1513164 , -0.5960678 ]], dtype=float32),\n",
       " 7: array([[-0.7846317 ,  4.138459  ,  0.19337498, ...,  0.39842224,\n",
       "         -0.3890353 ,  2.1065667 ],\n",
       "        [-1.2043835 ,  6.1970973 , -0.50348985, ..., -0.9426151 ,\n",
       "         -1.2578487 ,  1.8920661 ],\n",
       "        [-1.3327334 ,  3.49024   , -0.24549606, ..., -1.4249703 ,\n",
       "         -0.39281332,  1.1355553 ],\n",
       "        ...,\n",
       "        [-0.5956136 , -1.9828994 ,  4.1457314 , ...,  3.4064062 ,\n",
       "          7.6004434 , -2.2182128 ],\n",
       "        [-1.1890208 , -4.219519  ,  5.3387623 , ...,  4.2291164 ,\n",
       "          7.1734586 , -1.2156554 ],\n",
       "        [-0.9133505 , -1.26247   ,  2.9830642 , ...,  2.6513767 ,\n",
       "          3.3070061 ,  0.8372903 ]], dtype=float32),\n",
       " 8: array([[-2.9141603 ,  0.6136834 ,  0.2300861 , ...,  1.499661  ,\n",
       "         -0.6685301 ,  2.082819  ],\n",
       "        [-4.043555  ,  0.8343441 , -0.49079952, ...,  0.3600009 ,\n",
       "         -1.2491343 ,  2.6130552 ],\n",
       "        [-4.09155   ,  0.5956769 ,  0.01160068, ..., -0.39907727,\n",
       "          0.2508098 ,  1.0391595 ],\n",
       "        ...,\n",
       "        [-0.6527215 , -6.7112083 ,  2.5080338 , ...,  7.2112446 ,\n",
       "          8.134529  , -1.3015454 ],\n",
       "        [ 0.21567178, -5.01913   ,  2.8106742 , ...,  6.0384755 ,\n",
       "          7.5052624 , -0.8491914 ],\n",
       "        [-0.9066101 , -1.5362977 ,  1.7168555 , ...,  3.5432754 ,\n",
       "          3.2650511 ,  0.39548066]], dtype=float32),\n",
       " 9: array([[-4.348097  ,  1.5893986 , -2.3489053 , ..., -0.13156763,\n",
       "         -0.40844   ,  0.9537436 ],\n",
       "        [-4.623128  ,  1.518532  , -4.2788386 , ..., -1.4930578 ,\n",
       "         -0.26664117,  1.3726829 ],\n",
       "        [-3.5395057 ,  1.6324668 , -1.9630826 , ..., -1.2518132 ,\n",
       "         -0.51276684, -0.19061044],\n",
       "        ...,\n",
       "        [-1.9163532 ,  0.69074017,  5.2829556 , ...,  6.5897565 ,\n",
       "         13.525201  ,  2.471844  ],\n",
       "        [-2.2531931 ,  1.45968   ,  4.8344765 , ...,  5.677109  ,\n",
       "          8.6094675 ,  0.624803  ],\n",
       "        [-3.1517327 ,  1.7969786 ,  1.7586578 , ...,  2.7888224 ,\n",
       "          2.461178  ,  0.18703192]], dtype=float32),\n",
       " 10: array([[-4.524088  , -2.4699252 , -1.5545722 , ...,  1.6004353 ,\n",
       "         -0.5867959 ,  2.5942461 ],\n",
       "        [-3.6376467 , -1.6272961 , -2.132068  , ...,  0.7239527 ,\n",
       "         -0.6263737 ,  2.7158577 ],\n",
       "        [-3.7099807 , -0.6784066 , -0.4870054 , ...,  0.19436115,\n",
       "          0.29812673,  2.1174939 ],\n",
       "        ...,\n",
       "        [-8.872567  , -9.127323  ,  6.2945385 , ...,  3.479483  ,\n",
       "         10.610658  , -3.201407  ],\n",
       "        [-8.465688  , -6.5937233 ,  4.682209  , ...,  3.1251938 ,\n",
       "          6.8646126 , -1.8227549 ],\n",
       "        [-6.6983767 , -4.047639  ,  1.4422989 , ...,  2.554907  ,\n",
       "          1.891968  ,  0.80962306]], dtype=float32),\n",
       " 11: array([[-10.362403  ,  -5.142391  ,  -2.9620059 , ...,   7.746425  ,\n",
       "          -0.83542234,   6.5442076 ],\n",
       "        [-11.048375  ,  -6.1996703 ,  -4.2024527 , ...,   7.47868   ,\n",
       "           0.56463546,   8.446208  ],\n",
       "        [ -5.753642  ,  -4.5608573 ,  -2.6205635 , ...,   5.585589  ,\n",
       "           0.53720385,   5.1668887 ],\n",
       "        ...,\n",
       "        [ -1.7339818 ,  -0.9504786 ,  13.301076  , ...,   9.063908  ,\n",
       "           4.79339   ,  -2.6875768 ],\n",
       "        [ -1.9300034 ,  -1.8599924 ,   9.953507  , ...,   7.4343553 ,\n",
       "           2.1221645 ,  -1.4100624 ],\n",
       "        [ -5.626781  ,  -3.389429  ,   2.822447  , ...,   7.0604696 ,\n",
       "          -0.76392055,   2.0491767 ]], dtype=float32)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cd3113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.369625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.dataset.duration(sent=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b4d4d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud = obj.dataset.audio(12)\n",
    "aud = aud.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384e880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aud = obj.dataset.audio(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d96098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0233a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    " from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    " import torch\n",
    " \n",
    " # load model and tokenizer\n",
    " processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    " model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "     \n",
    " # load dummy dataset and read soundfiles\n",
    "#  ds = load_dataset(\"patrickvonplaten/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    " \n",
    " # tokenize\n",
    " input_values = processor(aud, return_tensors=\"pt\", padding=\"longest\").input_values  # Batch size 1\n",
    " \n",
    " # retrieve logits\n",
    " logits = model(input_values).logits\n",
    " \n",
    " # take argmax and decode\n",
    " predicted_ids = torch.argmax(logits, dim=-1)\n",
    " transcription = processor.batch_decode(predicted_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8432f0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAVE YOU GOT ENOUGH BLANKETS']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef256530",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = dict([*model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54f094f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LayerNorm((768,), eps=1e-05, elementwise_affine=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules['wav2vec2.encoder.layers.0.final_layer_norm'] #'wav2vec2.feature_extractor.conv_layers.0.conv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8daf1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My wav2letter Kernel)",
   "language": "python",
   "name": "wav2letter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
