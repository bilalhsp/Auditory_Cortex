{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmedb/projects/Wav2Letter/deepspeech.pytorch/deepspeech_pytorch/loader/data_loader.py:17: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"sox_io\")\n"
     ]
    }
   ],
   "source": [
    "from auditory_cortex.plotters.plotter_utils import PlotterUtils\n",
    "from auditory_cortex.plotters.correlation_plotter import RegPlotter\n",
    "from auditory_cortex.analyses import Correlations\n",
    "from auditory_cortex.models import Regression\n",
    "from auditory_cortex.neural_data.neural_meta_data import NeuralMetaData\n",
    "from auditory_cortex.dataloader import DataLoader\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/pytorch_lightning/utilities/migration/migration.py:203: PossibleUserWarning: You have multiple `ModelCheckpoint` callback states in this checkpoint, but we found state keys that would end up colliding with each other after an upgrade, which means we can't differentiate which of your checkpoint callbacks needs which states. At least one of your `ModelCheckpoint` callbacks will not be able to reload the state.\n",
      "  rank_zero_warn(\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.1.5 to v2.0.8. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../depot/jgmakin/data/auditory_cortex/results/pretrained_weights/deepspeech2/librispeech_pretrained_v3.ckpt`\n",
      "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (WordErrorRate). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ahmedb/.conda/envs/cent7/2020.11-py38/wav2letter/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (CharErrorRate). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_no_full_state`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader()\n",
    "model_name = 'deepspeech2'\n",
    "dnn_obj = dataloader.get_DNN_obj(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = dnn_obj.extractor.model.state_dict()\n",
    "for k,v in state_dict.items():\n",
    "\tstate_dict[k] = v.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from auditory_cortex import cache_dir\n",
    "weights_factor = 1\n",
    "state_dict_path = os.path.join(cache_dir, model_name, 'shuffled', f'shuffled_weights_factor_{weights_factor}.pth')\n",
    "state_dict = dnn_obj.extractor.model.state_dict()\n",
    "# for k,v in state_dict.items():\n",
    "# \tstate_dict[k] = v.cpu().numpy()\n",
    "# torch.save(state_dict, state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = state_dict['conv.seq_module.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(feat.flatten())\n",
    "plt.title(np.linalg.norm(feat))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_param = feat*100\n",
    "plt.hist(scaled_param.flatten())\n",
    "plt.title(np.linalg.norm(scaled_param))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(feat.flatten())\n",
    "plt.title(np.linalg.norm(feat))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader()\n",
    "model_name = 'deepspeech2'\n",
    "dnn_obj = dataloader.get_DNN_obj(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_obj.layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_with_weights = [\n",
    "    'conv.seq_module.0.weight',\n",
    "    'conv.seq_module.3.weight',\n",
    "    'rnns.0.rnn.weight_ih_l0',\n",
    "    # 'rnns.0.rnn.weight_hh_l0',\n",
    "    'rnns.1.rnn.weight_ih_l0',\n",
    "    'rnns.2.rnn.weight_ih_l0',\n",
    "    'rnns.3.rnn.weight_ih_l0',\n",
    "    'rnns.4.rnn.weight_ih_l0',\n",
    "    'fc.0.module.0.weight',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader()\n",
    "model_name = 'deepspeech2'\n",
    "dnn_obj = dataloader.get_DNN_obj(model_name)\n",
    "\n",
    "num_layers = len(layers_with_weights)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=num_layers, figsize=(16,8))\n",
    "\n",
    "i = 0\n",
    "for j, layer_name in enumerate(layers_with_weights):\n",
    "    weights = dnn_obj.extractor.model.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "    norm = np.linalg.norm(weights)\n",
    "\n",
    "    ax = axes[i, j]\n",
    "    ax.hist(weights)\n",
    "    ax.set_title(f\"{norm:.2f}\")\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# reset weights..\n",
    "out = dnn_obj.reset_model_parameters()\n",
    "i = 1\n",
    "for j, layer_name in enumerate(layers_with_weights):\n",
    "    weights = dnn_obj.extractor.model.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "    norm = np.linalg.norm(weights)\n",
    "\n",
    "    ax = axes[i, j]\n",
    "    ax.hist(weights)\n",
    "    ax.set_title(f\"{norm:.2f}\")\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict([*dnn_obj.extractor.model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_weight_initializations(model_name, layer_name):\n",
    "    dataloader = DataLoader()\n",
    "    dnn_obj = dataloader.get_DNN_obj(model_name)\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10,8))\n",
    "\n",
    "    # layer_name = 'conv.seq_module.0.weight'\n",
    "\n",
    "    weights = dnn_obj.extractor.model.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "    norm = np.linalg.norm(weights)\n",
    "\n",
    "    i=0\n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.hist(weights)\n",
    "    ax.set_title(f\"original Norm={norm:.2f}\")\n",
    "\n",
    "    # reset weights..\n",
    "    out = dnn_obj.reset_model_parameters()\n",
    "    weights = dnn_obj.extractor.model.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "    norm = np.linalg.norm(weights)\n",
    "\n",
    "    i=1\n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.hist(weights)\n",
    "    ax.set_title(f\"reset Norm={norm:.2f}\")\n",
    "\n",
    "    # randn weights..\n",
    "    out = dnn_obj.randomly_reinitialize_weights(False)\n",
    "    weights = dnn_obj.extractor.model.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "    norm = np.linalg.norm(weights)\n",
    "\n",
    "    i=2\n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.hist(weights)\n",
    "    ax.set_title(f\"randn Norm={norm:.2f}\")\n",
    "\n",
    "    # rand weights..\n",
    "    out = dnn_obj.randomly_reinitialize_weights(True)\n",
    "    weights = dnn_obj.extractor.model.state_dict()[layer_name].flatten().cpu().numpy()\n",
    "    norm = np.linalg.norm(weights)\n",
    "\n",
    "    i=3\n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.hist(weights)\n",
    "    ax.set_title(f\"rand Norm={norm:.2f}\")\n",
    "\n",
    "    plt.suptitle(layer_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer_name = 'conv.seq_module.0.weight'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer_name = 'conv.seq_module.0.bias'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer_name = 'conv.seq_module.3.weight'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer_name = 'conv.seq_module.3.bias'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whisper_tiny.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader()\n",
    "model_name = 'whisper_tiny'\n",
    "dnn_obj = dataloader.get_DNN_obj(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict([*dnn_obj.extractor.model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader()\n",
    "model_name = 'speech2text'\n",
    "dnn_obj = dataloader.get_DNN_obj(model_name)\n",
    "dict([*dnn_obj.extractor.model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader()\n",
    "model_name = 'deepspeech2'\n",
    "dnn_obj = dataloader.get_DNN_obj(model_name)\n",
    "dict([*dnn_obj.extractor.model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "layer_name = 'model.encoder.conv1.weight'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "layer_name = 'model.encoder.conv2.weight'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "layer_name = 'model.encoder.layers.0.fc1.weight'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wav2letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "layer_name = 'conv1.conv.weight'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "layer_name = 'conv2.conv.weight'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "layer_name = 'conv6.conv.weight'\n",
    "compare_weight_initializations(model_name, layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader()\n",
    "model_name = 'wav2letter_modified'\n",
    "dnn_obj = dataloader.get_DNN_obj(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict([*dnn_obj.extractor.model.named_modules()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_obj.extractor.model.state_dict()['conv1.conv.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
