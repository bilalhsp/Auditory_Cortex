{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf734c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------  set up logging ----------------------\n",
    "import logging\n",
    "from auditory_cortex.utils import set_up_logging\n",
    "set_up_logging('info')\n",
    "\n",
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "\n",
    "from auditory_cortex.plotters import tikzplots\n",
    "from auditory_cortex.analyses import Correlations, STRFCorrelations\n",
    "from auditory_cortex.plotters.correlation_plotter import RegPlotter\n",
    "from auditory_cortex.plotters.plotter_utils import PlotterUtils\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83e15f",
   "metadata": {},
   "source": [
    "### Median correlations for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef57e1b",
   "metadata": {},
   "source": [
    "#### timit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859c8f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:Extracting column: normalized_test_cc\n",
      "INFO:Filtering 'normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: whisper_tiny\n",
      "layer: 0, median: 0.5196238624345509\n",
      "layer: 1, median: 0.5793349635051107\n",
      "layer: 2, median: 0.560012065589323\n",
      "layer: 3, median: 0.5072174775858294\n",
      "layer: 4, median: 0.46440022993088004\n",
      "layer: 5, median: 0.4063860800522521\n",
      "INFO:Extracting column: normalized_test_cc\n",
      "INFO:Filtering 'normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: whisper_base\n",
      "layer: 0, median: 0.5280932295363825\n",
      "layer: 1, median: 0.5720958721000792\n",
      "layer: 2, median: 0.5572772551446759\n",
      "layer: 3, median: 0.5288996030587831\n",
      "layer: 4, median: 0.4845301305037797\n",
      "layer: 5, median: 0.46676533849929974\n",
      "layer: 6, median: 0.4232206829260936\n",
      "layer: 7, median: 0.41125479767360085\n",
      "INFO:Extracting column: normalized_test_cc\n",
      "INFO:Filtering 'normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: wav2vec2\n",
      "layer: 0, median: 0.10251589323498006\n",
      "layer: 1, median: 0.4992233774104463\n",
      "layer: 2, median: 0.5274613499363485\n",
      "layer: 3, median: 0.5306123790185349\n",
      "layer: 4, median: 0.54164969773542\n",
      "layer: 5, median: 0.5391673607425339\n",
      "layer: 6, median: 0.49554988123795524\n",
      "layer: 7, median: 0.5437265851946369\n",
      "layer: 8, median: 0.5142889363932887\n",
      "layer: 9, median: 0.5164797972921049\n",
      "layer: 10, median: 0.4991261051017192\n",
      "layer: 11, median: 0.47797879915923913\n",
      "layer: 12, median: 0.4598058736602011\n",
      "layer: 13, median: 0.42123992550664774\n",
      "layer: 14, median: 0.41376541020505153\n",
      "layer: 15, median: 0.40132851276542003\n",
      "layer: 16, median: 0.3777356509581513\n",
      "layer: 17, median: 0.35701542748971715\n",
      "layer: 18, median: 0.36025362641365316\n",
      "layer: 19, median: 0.3615495962208428\n",
      "layer: 20, median: 0.31220080887080714\n",
      "INFO:Extracting column: normalized_test_cc\n",
      "INFO:Filtering 'normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: wav2letter_modified\n",
      "layer: 0, median: 0.41906786457817613\n",
      "layer: 1, median: 0.4609020279328696\n",
      "layer: 2, median: 0.5005499797113471\n",
      "layer: 3, median: 0.5360977650741912\n",
      "layer: 4, median: 0.5387119330921046\n",
      "layer: 5, median: 0.5169828960311981\n",
      "layer: 6, median: 0.5102823968584309\n",
      "layer: 7, median: 0.49556894687841413\n",
      "layer: 8, median: 0.4824087033370288\n",
      "layer: 9, median: 0.4488043466431273\n",
      "layer: 10, median: 0.40682442120176987\n",
      "layer: 11, median: 0.3733921304333915\n",
      "layer: 12, median: 0.26636975753910624\n",
      "layer: 13, median: 0.2265799418192819\n",
      "INFO:Extracting column: normalized_test_cc\n",
      "INFO:Filtering 'normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: speech2text\n",
      "layer: 0, median: 0.4545911623225123\n",
      "layer: 1, median: 0.5186448810848951\n",
      "layer: 2, median: 0.5331229907112802\n",
      "layer: 3, median: 0.5401546225310232\n",
      "layer: 4, median: 0.5530613477774277\n",
      "layer: 5, median: 0.5610278621730853\n",
      "layer: 6, median: 0.5484575081530526\n",
      "layer: 7, median: 0.5408614512646126\n",
      "layer: 8, median: 0.5174990275856832\n",
      "layer: 9, median: 0.508554992699215\n",
      "layer: 10, median: 0.49803743135225914\n",
      "layer: 11, median: 0.46349922737499727\n",
      "layer: 12, median: 0.4406368877562349\n",
      "layer: 13, median: 0.4215504838711205\n",
      "INFO:Extracting column: normalized_test_cc\n",
      "INFO:Filtering 'normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: deepspeech2\n",
      "layer: 0, median: 0.49551570303346654\n",
      "layer: 1, median: 0.5569568886714523\n",
      "layer: 2, median: 0.5661099948176553\n",
      "layer: 3, median: 0.5202696204861359\n",
      "layer: 4, median: 0.44297706076956583\n",
      "layer: 5, median: 0.3666190074265327\n",
      "layer: 6, median: 0.3295687748868197\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "model_names = [\n",
    "    'whisper_tiny', 'whisper_base', 'wav2vec2',\n",
    "    'wav2letter_modified', 'speech2text', 'deepspeech2',\n",
    "    ]\n",
    "identifier = 'timit_trf_lags300_bw50_naplib_matched'\n",
    "area = 'all'\n",
    "bin_width = 50\n",
    "delay = 0\n",
    "mVocs = True if 'mVocs' in identifier else False\n",
    "normalized=True\n",
    "for model_name in model_names:\n",
    "    corr_obj = Correlations(model_name+'_'+identifier)\n",
    "    data_dist = corr_obj.get_corr_all_layers_for_bin_width(\n",
    "                    neural_area=area, bin_width=bin_width, delay=delay,\n",
    "                    threshold=threshold, normalized=normalized,\n",
    "                    mVocs=mVocs, \n",
    "                )\n",
    "    print(f\"#######################################################\")\n",
    "    print(f\"model: {model_name}\")\n",
    "    for layer_id, dist in data_dist.items():\n",
    "        print(f\"layer: {layer_id}, median: {np.median(dist)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74a070",
   "metadata": {},
   "source": [
    "#### mVocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18e5419a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:Extracting column: mVocs_normalized_test_cc\n",
      "INFO:Filtering 'mVocs_normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: whisper_tiny\n",
      "layer: 0, median: 0.6390401100619133\n",
      "layer: 1, median: 0.6755318734741179\n",
      "layer: 2, median: 0.6507962350541424\n",
      "layer: 3, median: 0.6139949498999512\n",
      "layer: 4, median: 0.6158836390764476\n",
      "layer: 5, median: 0.5971326356247014\n",
      "INFO:Extracting column: mVocs_normalized_test_cc\n",
      "INFO:Filtering 'mVocs_normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: whisper_base\n",
      "layer: 0, median: 0.6402062204832104\n",
      "layer: 1, median: 0.6671388117410714\n",
      "layer: 2, median: 0.6586770431891543\n",
      "layer: 3, median: 0.6511502190869117\n",
      "layer: 4, median: 0.638228035390166\n",
      "layer: 5, median: 0.6304775504643122\n",
      "layer: 6, median: 0.6224308497608303\n",
      "layer: 7, median: 0.6058217705506671\n",
      "INFO:Extracting column: mVocs_normalized_test_cc\n",
      "INFO:Filtering 'mVocs_normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: wav2vec2\n",
      "layer: 0, median: 0.1709064692727296\n",
      "layer: 1, median: 0.5706112828131142\n",
      "layer: 2, median: 0.604934210402109\n",
      "layer: 3, median: 0.6164532341558382\n",
      "layer: 4, median: 0.6303024451708498\n",
      "layer: 5, median: 0.630931048610015\n",
      "layer: 6, median: 0.5470980574266954\n",
      "layer: 7, median: 0.620135277727026\n",
      "layer: 8, median: 0.5766870310900105\n",
      "layer: 9, median: 0.6114987052276148\n",
      "layer: 10, median: 0.5869484454806724\n",
      "layer: 11, median: 0.5805639470369259\n",
      "layer: 12, median: 0.5838073657371878\n",
      "layer: 13, median: 0.5777035739359421\n",
      "layer: 14, median: 0.5354423379586883\n",
      "layer: 15, median: 0.5355854042299019\n",
      "layer: 16, median: 0.4732845453304293\n",
      "layer: 17, median: 0.4733049079529331\n",
      "layer: 18, median: 0.4785424114232796\n",
      "layer: 19, median: 0.4979542063598223\n",
      "layer: 20, median: 0.4526069970203921\n",
      "INFO:Extracting column: mVocs_normalized_test_cc\n",
      "INFO:Filtering 'mVocs_normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: wav2letter_modified\n",
      "layer: 0, median: 0.4568075631479436\n",
      "layer: 1, median: 0.5507663805576861\n",
      "layer: 2, median: 0.6062009257071714\n",
      "layer: 3, median: 0.6308855949533541\n",
      "layer: 4, median: 0.6294420936178792\n",
      "layer: 5, median: 0.6404547374891458\n",
      "layer: 6, median: 0.6570036944393883\n",
      "layer: 7, median: 0.6348447393593075\n",
      "layer: 8, median: 0.632943624685791\n",
      "layer: 9, median: 0.6134862201999172\n",
      "layer: 10, median: 0.6237939680776668\n",
      "layer: 11, median: 0.590003697509332\n",
      "layer: 12, median: 0.5962232634214274\n",
      "layer: 13, median: 0.5742292414176543\n",
      "INFO:Extracting column: mVocs_normalized_test_cc\n",
      "INFO:Filtering 'mVocs_normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: speech2text\n",
      "layer: 0, median: 0.4648382035339754\n",
      "layer: 1, median: 0.4769832349846566\n",
      "layer: 2, median: 0.4884972168753947\n",
      "layer: 3, median: 0.5060112064960609\n",
      "layer: 4, median: 0.5365242248150558\n",
      "layer: 5, median: 0.5535937795460011\n",
      "layer: 6, median: 0.565718345266456\n",
      "layer: 7, median: 0.5659625257339733\n",
      "layer: 8, median: 0.5582101362735385\n",
      "layer: 9, median: 0.5388815746396782\n",
      "layer: 10, median: 0.5453840751059416\n",
      "layer: 11, median: 0.5526216758513659\n",
      "layer: 12, median: 0.5203144744102413\n",
      "layer: 13, median: 0.5060741658818577\n",
      "INFO:Extracting column: mVocs_normalized_test_cc\n",
      "INFO:Filtering 'mVocs_normalizer' using multiple of 0.500 with std dev ...\n",
      "#######################################################\n",
      "model: deepspeech2\n",
      "layer: 0, median: 0.5957611092085607\n",
      "layer: 1, median: 0.6369829411379349\n",
      "layer: 2, median: 0.662030240337136\n",
      "layer: 3, median: 0.604763831210915\n",
      "layer: 4, median: 0.5439973544587067\n",
      "layer: 5, median: 0.4982734705394666\n",
      "layer: 6, median: 0.4709182409318636\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "model_names = [\n",
    "    'whisper_tiny', 'whisper_base', 'wav2vec2',\n",
    "    'wav2letter_modified', 'speech2text', 'deepspeech2',\n",
    "    ]\n",
    "identifier = 'mVocs_trf_lags300_bw50_naplib_matched'\n",
    "area = 'all'\n",
    "mVocs = True if 'mVocs' in identifier else False\n",
    "bin_width = 50\n",
    "delay = 0\n",
    "normalized=True\n",
    "for model_name in model_names:\n",
    "    corr_obj = Correlations(model_name+'_'+identifier)\n",
    "    data_dist = corr_obj.get_corr_all_layers_for_bin_width(\n",
    "                    neural_area=area, bin_width=bin_width, delay=delay,\n",
    "                    threshold=threshold, normalized=normalized,\n",
    "                    mVocs=mVocs, \n",
    "                )\n",
    "    print(f\"#######################################################\")\n",
    "    print(f\"model: {model_name}\")\n",
    "    for layer_id, dist in data_dist.items():\n",
    "        print(f\"layer: {layer_id}, median: {np.median(dist)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc83862",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159aa14",
   "metadata": {},
   "source": [
    "### Tuned & highly-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09dc4a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "from auditory_cortex.neural_data import NormalizerCalculator\n",
    "from auditory_cortex.neural_data import create_neural_metadata, create_neural_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106c07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'ucsf'\n",
    "metadata = create_neural_metadata(dataset_name)\n",
    "sessions = metadata.get_all_available_sessions()\n",
    "norm_obj = NormalizerCalculator(dataset_name)\n",
    "\n",
    "stimuli = ['mVocs', 'timit']\n",
    "stim_wise_tuned_sess_channels = {s:{} for s in stimuli}\n",
    "stim_wise_session_null_dist = {s:{} for s in stimuli}\n",
    "stim_wise_session_norm_dist = {s:{} for s in stimuli}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e05ca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:Getting normalizer dist. for sess-180413, bw-50, mVocs=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:Getting normalizer dist. for sess-180420, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180501, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180502, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180613, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180622, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180627, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180717, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180719, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180720, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180724, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180728, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180730, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180731, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180807, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180808, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180810, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180814, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-190604, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-190605, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-190606, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-190703, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-190726, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-190801, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191113, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191115, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191121, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191125, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191206, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191209, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191210, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191211, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-191219, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-200205, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-200206, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-200207, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-200212, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-200213, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-200219, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-200313, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-200318, bw-50, mVocs=True\n",
      "INFO:Getting normalizer dist. for sess-180413, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180420, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180501, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180502, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180613, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180622, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180627, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180717, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180719, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180720, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180724, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180728, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180730, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180731, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180807, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180808, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180810, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-180814, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-190604, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-190605, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-190606, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-190703, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-190726, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-190801, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191113, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191115, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191121, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191125, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191206, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191209, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191210, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191211, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-191219, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-200205, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-200206, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-200207, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-200212, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-200213, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-200219, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-200313, bw-50, mVocs=False\n",
      "INFO:Getting normalizer dist. for sess-200318, bw-50, mVocs=False\n"
     ]
    }
   ],
   "source": [
    "bin_width = 50\n",
    "p_value = 0.05\n",
    "stim_wise_p_values = {}\n",
    "for mVocs in [True, False]:\n",
    "    stim = 'mVocs' if mVocs else 'timit'\n",
    "    tuned_channels = []\n",
    "    all_p_values = []\n",
    "    highly_tuned_channels = []\n",
    "    all_p_values = []\n",
    "    for session in sessions:\n",
    "        shifted_null = norm_obj.get_normalizer_null_dist_using_random_shifts(\n",
    "            session, bin_width=bin_width, mVocs=mVocs, force_redo=False\n",
    "        )\n",
    "        norm_dist = norm_obj.get_normalizer_for_session(\n",
    "            session, bin_width=bin_width, mVocs=mVocs\n",
    "        ) \n",
    "        stim_wise_session_null_dist[stim][session] = shifted_null\n",
    "        stim_wise_session_norm_dist[stim][session] = norm_dist\n",
    "    \n",
    "        # shifted_null = stim_wise_session_null_dist[stim][session]\n",
    "        # norm_dist = stim_wise_session_norm_dist[stim][session]\n",
    "        tuned_channels = []\n",
    "        for ch in range(shifted_null.shape[1]):\n",
    "            dist1 = norm_dist[:,ch]\n",
    "            dist2 = shifted_null[:,ch]\n",
    "            stat, p = mannwhitneyu(dist1, dist2, alternative='greater')  # dist1 > dist2\n",
    "            all_p_values.append(p)\n",
    "            if p < p_value:\n",
    "                tuned_channels.append(ch)\n",
    "        stim_wise_tuned_sess_channels[stim][session] = tuned_channels\n",
    "    all_p_values = np.array(all_p_values) \n",
    "    stim_wise_p_values[stim] = all_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eccd09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t alpha:     w/o correction      using Holm-bonferroni correction\n",
      "stim: mVocs\n",
      "\t\t0.0500: \t1231\t\t1190\n",
      "\t\t0.0100: \t1215\t\t1178\n",
      "\t\t0.0010: \t1198\t\t1162\n",
      "\t\t0.0001: \t1190\t\t1152\n",
      "stim: timit\n",
      "\t\t0.0500: \t1195\t\t1169\n",
      "\t\t0.0100: \t1186\t\t1166\n",
      "\t\t0.0010: \t1176\t\t1161\n",
      "\t\t0.0001: \t1170\t\t1157\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [0.05, 0.01, 0.001, 0.0001]\n",
    "\n",
    "print(f\"\\t\\t alpha:     w/o correction      using Holm-bonferroni correction\")\n",
    "for stim in stimuli:\n",
    "    print(f\"stim: {stim}\")\n",
    "    all_p_values = stim_wise_p_values[stim]\n",
    "    _, corrected_values, _, _ = multipletests(all_p_values, alpha=p, method='holm')\n",
    "    for alpha in alpha_values:\n",
    "        print(f\"\\t\\t{alpha:.4f}: \", end='\\t')\n",
    "        tuned_channels = np.sum(all_p_values < alpha)\n",
    "        print(f\"{tuned_channels}\", end='\\t\\t')\n",
    "        tuned_with_correction = np.sum(corrected_values < alpha)\n",
    "        print(f\"{tuned_with_correction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774094af",
   "metadata": {},
   "source": [
    "#### number of tuned channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da46cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulus: mVocs\n",
      "Total tuned channels in core: 701\n",
      "Total tuned channels in non-primary: 530\n",
      "Total tuned channels in all areas: 1231\n",
      "Stimulus: timit\n",
      "Total tuned channels in core: 707\n",
      "Total tuned channels in non-primary: 488\n",
      "Total tuned channels in all areas: 1195\n"
     ]
    }
   ],
   "source": [
    "stim_wise_sess_ch_lists = {stim:{} for stim in stimuli}\n",
    "total_tuned = {stim:0 for stim in stimuli}\n",
    "for stim in stimuli:\n",
    "    neural_areas = ['core', 'non-primary']\n",
    "    sessions = metadata.get_all_available_sessions()\n",
    "    stim_wise_sess_ch_lists[stim] = {area:[] for area in neural_areas}\n",
    "    \n",
    "    print(f'Stimulus: {stim}')\n",
    "    for area in neural_areas:\n",
    "        area_sessions = metadata.get_all_sessions(area)\n",
    "        # not all sessions are available..\n",
    "        area_sessions = sessions[np.isin(sessions, area_sessions)]\n",
    "        area_tuned = 0\n",
    "        for sess in area_sessions:\n",
    "            num_channels = len(stim_wise_tuned_sess_channels[stim][sess])\n",
    "            area_tuned += num_channels\n",
    "            if num_channels == 0:\n",
    "                continue\n",
    "            sess_ch_list = [f'{sess}_{ch}' for ch in stim_wise_tuned_sess_channels[stim][sess]]\n",
    "            stim_wise_sess_ch_lists[stim][area].extend(sess_ch_list)\n",
    "        total_tuned[stim] += area_tuned\n",
    "        print(f'Total tuned channels in {area}: {area_tuned}')\n",
    "    print(f'Total tuned channels in all areas: {total_tuned[stim]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57020e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area: core\n",
      "\t Tuned for timit: 707\n",
      "\t Tuned for mVocs: 701\n",
      "\t Tuned for both: 580\n",
      "---\n",
      "Area: non-primary\n",
      "\t Tuned for timit: 488\n",
      "\t Tuned for mVocs: 530\n",
      "\t Tuned for both: 341\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for area in ['core', 'non-primary']:\n",
    "    print(f'Area: {area}')\n",
    "    list_tuned = {}\n",
    "    for stim in ['timit', 'mVocs']:\n",
    "        list_tuned[stim] = stim_wise_sess_ch_lists[stim][area]\n",
    "        print(f\"\\t Tuned for {stim}: {len(list_tuned[stim])}\")\n",
    "    tuned_both = set(list_tuned['mVocs']).intersection(set(list_tuned['timit']))\n",
    "    print(f\"\\t Tuned for both: {len(tuned_both)}\")\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f32db",
   "metadata": {},
   "source": [
    "#### number of highly-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1025f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = 0.5\n",
    "stim_wise_highly_tuned = {stim:{} for stim in stimuli}\n",
    "for stim in stimuli:\n",
    "    for session in sessions:\n",
    "        norm_dist = stim_wise_session_norm_dist[stim][session]\n",
    "        shifted_null = stim_wise_session_null_dist[stim][session]\n",
    "\n",
    "        norm_means = np.mean(norm_dist, axis=0)\n",
    "        null_means = np.mean(shifted_null, axis=0)\n",
    "\n",
    "        null_std = np.std(shifted_null, axis=0)\n",
    "        thresh = null_means + (gap * null_std)\n",
    "        highly_tuned_chs = np.where(norm_means > thresh)[0]\n",
    "        stim_wise_highly_tuned[stim][session] = highly_tuned_chs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c66ca9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap: 0.5\n",
      "Stimulus: timit\n",
      "Total highly tuned channels in core: 300\n",
      "Total highly tuned channels in non-primary: 104\n",
      "Total highly tuned channels in all areas: 404\n",
      "Stimulus: mVocs\n",
      "Total highly tuned channels in core: 315\n",
      "Total highly tuned channels in non-primary: 174\n",
      "Total highly tuned channels in all areas: 489\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gap: {gap}\")\n",
    "stim_wise_sess_ch_lists = {stim:{} for stim in stimuli}\n",
    "total_highly_tuned = {stim:0 for stim in stimuli}\n",
    "for stim in ['timit', 'mVocs']:\n",
    "    neural_areas = ['core', 'non-primary']\n",
    "    sessions = metadata.get_all_available_sessions()\n",
    "    stim_wise_sess_ch_lists[stim] = {area:[] for area in neural_areas}\n",
    "    \n",
    "    print(f'Stimulus: {stim}')\n",
    "    for area in neural_areas:\n",
    "        area_sessions = metadata.get_all_sessions(area)\n",
    "        # not all sessions are available..\n",
    "        area_sessions = sessions[np.isin(sessions, area_sessions)]\n",
    "        area_tuned = 0\n",
    "        for sess in area_sessions:\n",
    "            num_channels = len(stim_wise_highly_tuned[stim][sess])\n",
    "            area_tuned += num_channels\n",
    "            if num_channels == 0:\n",
    "                continue\n",
    "            sess_ch_list = [f'{sess}_{ch}' for ch in stim_wise_highly_tuned[stim][sess]]\n",
    "            stim_wise_sess_ch_lists[stim][area].extend(sess_ch_list)\n",
    "        total_highly_tuned[stim] += area_tuned\n",
    "        print(f'Total highly tuned channels in {area}: {area_tuned}')\n",
    "    print(f'Total highly tuned channels in all areas: {total_highly_tuned[stim]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63efc409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gap: 0.5\n",
      "Area: core\n",
      "\t Highly tuned for timit: 300\n",
      "\t Highly tuned for mVocs: 315\n",
      "\t Highly tuned for both: 246\n",
      "---\n",
      "Area: non-primary\n",
      "\t Highly tuned for timit: 104\n",
      "\t Highly tuned for mVocs: 174\n",
      "\t Highly tuned for both: 78\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gap: {gap}\")\n",
    "for area in ['core', 'non-primary']:\n",
    "    print(f'Area: {area}')\n",
    "    list_tuned = {}\n",
    "    for stim in ['timit', 'mVocs']:\n",
    "        list_tuned[stim] = stim_wise_sess_ch_lists[stim][area]\n",
    "        print(f\"\\t Highly tuned for {stim}: {len(list_tuned[stim])}\")\n",
    "    tuned_both = set(list_tuned['mVocs']).intersection(set(list_tuned['timit']))\n",
    "    print(f\"\\t Highly tuned for both: {len(tuned_both)}\")\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (My wav2letter Kernel)",
   "language": "python",
   "name": "wav2letter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
