{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 64 channels loaded...!\n",
      "Objects created, now loading Transformer layer features...!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akamsali/anaconda3/envs/research_env/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630815121/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from auditory_cortex.Regression import transformer_regression\n",
    "\n",
    "reg = transformer_regression('/depot/jgmakin/data/auditory_cortex/josh_data/data',\"200213\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akamsali/anaconda3/envs/research_env/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630815121/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/auditory_cortex/Regression.py:422: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.cov(y_hat, y)[0,1]/(np.sqrt(np.var(y_hat)*factor))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n",
      "[nan]\n",
      "[nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-37b02e6ba11e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mR2tt\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mr2t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2tt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cc_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mR2t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/auditory_cortex/Regression.py\u001b[0m in \u001b[0;36mget_cc_norm\u001b[0;34m(self, layer, win, channel, delay)\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_sample_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimply_spikes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdef_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_sample_spikes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/auditory_cortex/Regression.py\u001b[0m in \u001b[0;36msimply_spikes\u001b[0;34m(self, sent_s, sent_e, ch, w, delay, offset)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mspikes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msent_e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       spikes[x] = torch.tensor(self.dataset.retrieve_spike_counts(sent=i,win=w,delay=delay,early_spikes=False,model=self.model_name,\n\u001b[0m\u001b[1;32m     52\u001b[0m                                                                   offset=offset)[ch])\n\u001b[1;32m     53\u001b[0m     \u001b[0mspikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspikes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_e\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msent_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/auditory_cortex/Dataset.py\u001b[0m in \u001b[0;36mretrieve_spike_counts\u001b[0;34m(self, sent, trial, win, delay, early_spikes, model, offset)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0ms_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_spike_times\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_spikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearly_spikes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m#return spikes count in each bin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m     output = self.create_bins(s_times, sent=sent, trial=trial, win = win,delay=delay, early_spikes = early_spikes, model=model,\n\u001b[0m\u001b[1;32m    229\u001b[0m                               offset=offset)\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/auditory_cortex/Dataset.py\u001b[0m in \u001b[0;36mcreate_bins\u001b[0;34m(self, s_times, sent, trial, win, delay, early_spikes, model, offset)\u001b[0m\n\u001b[1;32m    206\u001b[0m               \u001b[0mst\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m               \u001b[0men\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mwin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from auditory_cortex.Regression import transformer_regression\n",
    "\n",
    "import json \n",
    "import sys\n",
    "\n",
    "# print(sys.argv)\n",
    "# sub = sys.argv[1]\n",
    "# w = sys.argv[2]\n",
    "\n",
    "# print(\"arg vals\",sub, int(w))\n",
    "sub = '200213'\n",
    "w = 10\n",
    "reg = transformer_regression('/depot/jgmakin/data/auditory_cortex/josh_data/data',sub)\n",
    "\n",
    "# channels = np.arange(0,reg.dataset.num_channels).tolist()\n",
    "num_layers = len(reg.layers)\n",
    "corr_values = {}\n",
    "for ch in range(reg.dataset.num_channels):\n",
    "    R2t =[]  \n",
    "    R2v =[] \n",
    "    R2tt =[]\n",
    "    for l in range(num_layers):\n",
    "        r2t, r2v,r2tt = reg.get_cc_norm(l,int(w),channel=ch, delay=0)\n",
    "        print(r2t)\n",
    "        R2t.append(r2t.item())\n",
    "        R2v.append(r2v.item())\n",
    "        R2tt.append(r2tt.item())\n",
    "        # PCt.append(pct)\n",
    "        # PCv.append(pcv)\n",
    "        # PCtt.append(pctt)\n",
    "    corr_values[ch] =  {\"train\": R2t, \"val\": R2v, \"test\": R2tt}\n",
    "# fig, ax = plt.subplots(1,2, figsize=(14,6), sharey=True)\n",
    "\n",
    "# with open(\"/scratch/gilbreth/akamsali/Research/Makin/outputs/neuron_corr/\"+sub + \"_\" + str(w), 'w') as f:\n",
    "#     json.dump(corr_values, f)\n",
    "\n",
    "with open(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/\"+sub + \"_\" + str(w), 'a') as f:\n",
    "    json.dump(corr_values, f)\n",
    "\n",
    "    \n",
    "# plt.plot(R2t, label='Training')\n",
    "# plt.plot(R2v, label='Val')\n",
    "# plt.plot(R2tt, label='Test')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "# ax[0].plot(R2t, label='Training')\n",
    "# ax[0].plot(R2v, label='Val')\n",
    "# ax[0].plot(R2tt, label='Test')\n",
    "# ax[0].legend()\n",
    "# ax[0].set_title(\"R2\")\n",
    "\n",
    "\n",
    "# ax[1].plot(PCt, label='Training')\n",
    "# ax[1].plot(PCv, label='Val')\n",
    "# ax[1].plot(PCtt, label='Test')\n",
    "# ax[1].legend()\n",
    "# ax[1].set_title(\"PC\")\n",
    "\n",
    "# plt.title(\"200213, bin_width=\"+ str(w))\n",
    "# # plt.savefig(\"/Users/akshita/Documents/Research/Makin/outputs/200213_\" + str(w))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from Dataset import Neural_Data\n",
    "\n",
    "\n",
    "neural_data = Neural_Data('/Users/akshita/Documents/Research/Makin/data',\"200206\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_sents = {}\n",
    "for i in range(499):\n",
    "    data = neural_data.retrieve_spikes_count_for_all_trials(i, w=100)\n",
    "    if data[1].shape[0] > 1:\n",
    "        repeated_sents[i] = data[1].shape\n",
    "print(repeated_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "# print(channel.shape)\n",
    "\n",
    "# sents = [12,13,32,43,56,163,212,218,287,308]\n",
    "sents = [12]\n",
    "# sent_vals = {}\n",
    "# wins = [1,5,10,20,30,40,50,75,100,200]\n",
    "wins = [10]\n",
    "for w in wins:\n",
    "    for sent in sents:\n",
    "        data = neural_data.retrieve_spikes_count_for_all_trials(sent, w=w)\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            channel = data[j]\n",
    "            # print(channel.shape)\n",
    "            cnt = 0\n",
    "            val = []\n",
    "            p_r = []\n",
    "            for shift in [0]:#1, 5, 10]:\n",
    "                for i in range(11):\n",
    "                    cnt+=1.0\n",
    "                    ind = np.arange(0,11,1)\n",
    "                    b_ind = ind[i]\n",
    "                    a_ind = np.delete(ind, i)\n",
    "                    # print(a_ind, b_ind)\n",
    "                    a = np.mean(channel[a_ind, :], axis=0)\n",
    "                    b = channel[b_ind,:]\n",
    "                    b = np.roll(b, shift)\n",
    "                    \n",
    "                    res = stats.linregress(a, b)\n",
    "                    pearson_r = stats.pearsonr(a, b)\n",
    "                    val.append(res.rvalue**2)\n",
    "                    p_r.append(pearson_r[0]**2)\n",
    "\n",
    "                with open(\"/home/amy/Documents/Research/Makin/outputs/good_sessions/linreg_cs_win_\" + str(w)+ \"_\"+ str(sent) +\"_\" + str(shift)+\".csv\", 'a') as f:\n",
    "                    writer=csv.writer(f)\n",
    "                    row = val \n",
    "                    writer.writerow(row)\n",
    "                    f.close()\n",
    "    print(\"done: \", w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(0,11,1)\n",
    "b_ind = ind[i]\n",
    "a_ind = np.delete(ind, i)\n",
    "print(a_ind, b_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fig, ax = plt.subplots(4, len(wins),sharey=True,figsize=(5,6))\n",
    "\n",
    "for i, shift in enumerate([0, 1, 5, 10]):\n",
    "    for j, w in enumerate(wins):\n",
    "        for sent in sents:\n",
    "        # plt.figure()\n",
    "            d = pd.read_csv(\"/home/amy/Documents/Research/Makin/outputs/good_sessions/linreg_cs_win_\" + str(w)+ \"_\"+ str(sent) +\"_\" + str(shift)+ \".csv\", header=None)\n",
    "            d.columns = [\"channels\", \"reg_r2\", \"pearson_r2\"]\n",
    "\n",
    "            avg_r2 = d['reg_r2'].to_numpy()\n",
    "            pearson_r2 = d['pearson_r2'].to_numpy()\n",
    "            # print(avg_r2.shape, pearson_r2.shape)\n",
    "\n",
    "            # channels = d['channels'].to_numpy()\n",
    "            # plt.figure()\n",
    "            # ax[i, j].plot(channels, avg_r2, label=str(sent))\n",
    "            ax[i].plot(avg_r2-pearson_r2, label=str(sent))\n",
    "            ax[0].set_title(f\"Win={w}\")\n",
    "            ax[i].set_ylabel(f\"Shift={shift}\")\n",
    "            plt.ylim(-1.25, 0.8)\n",
    "        # plt.xlabel(\"channels\")\n",
    "    # plt.title(f\"Win = {w}\" , fontsize=16)plt.legend()\n",
    "        # plt.savefig(\"/home/amy/Documents/Research/Makin/outputs/correlation/linreg_cs_win_\" + str(w)+ \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, w in enumerate(wins):\n",
    "    for i, shift in enumerate([0,1, 5, 10]):\n",
    "        plt.figure()\n",
    "        for sent in sents:\n",
    "            d = pd.read_csv(\"/home/amy/Documents/Research/Makin/outputs/correlation/linreg_cs_win_\" + str(w)+ \"_\"+ str(sent) +\"_\" + str(shift)+ \".csv\", header=None)\n",
    "            d.columns = [\"channels\", \"reg_r2\", \"pearson_r2\"]\n",
    "\n",
    "            avg_r2 = d['reg_r2'].to_list()\n",
    "            pearson_r2 = d['pearson_r2'].to_list()\n",
    "            channels = d['channels'].to_list()\n",
    "            # plt.figure()\n",
    "            plt.plot(channels, avg_r2, label=str(sent))\n",
    "            plt.title(f\"Win={w}, Shift={shift}\")\n",
    "            # ax[i,j].set_ylabel(f\"Shift={shift}\")\n",
    "            plt.ylim(-0.5, 0.4)\n",
    "        # plt.xlabel(\"channels\")\n",
    "    # plt.title(f\"Win = {w}\" , fontsize=16)plt.legend()\n",
    "        # plt.savefig(\"/home/amy/Documents/Research/Makin/outputs/correlation/linreg_cs_win_\" + str(w)+ \".png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for sent in sents:\n",
    "    d2 = pd.read_csv(\"/home/amy/Documents/Research/Makin/outputs/correlation/linreg_loo_win_ms10_\"+ str(sent) +\".csv\", header=None)\n",
    "    d2.columns = [\"channels\", \"avg_r2\"]\n",
    "\n",
    "    avg_R2 = d2['avg_r2'].to_list()\n",
    "    channels = d2['channels'].to_list()\n",
    "    \n",
    "    plt.plot(channels, avg_R2 ,label=str(sent))\n",
    "    plt.ylim(-1.25, 0.8)\n",
    "plt.title(\"Correlation for sentences ms vs channels, w=10\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.zeros(100)\n",
    "b = np.zeros(100)\n",
    "ind_a = np.random.randint(0,100,10)\n",
    "ind_b = np.random.randint(0,100,10)\n",
    "\n",
    "a[ind_a] = 1    \n",
    "b[ind_b] = 1\n",
    "res = stats.linregress(a,b)\n",
    "\n",
    "res.rvalue**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [1]:\n",
    "    for sent in [12]:\n",
    "        data = neural_data.retrieve_spikes_count_for_all_trials(sent, w=w)\n",
    "\n",
    "        for j in [20]:\n",
    "            channel = data[j]\n",
    "            # for shift in [1, 5, 10]:\n",
    "            for i in range(1):\n",
    "                plt.plot(channel[i], label=j)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39ee5902541f8d9473741304b8cb1bb6d4326f8af27c9be63d89c1642eb0d066"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('research': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
