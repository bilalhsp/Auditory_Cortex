{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml import Loader\n",
    "\n",
    "conf_path = '/Users/akshita/Documents/Research/Makin/Auditory_Cortex/conf/ridge_conf.yaml'\n",
    "with open(conf_path, \"r\") as f:\n",
    "    manifest = yaml.load(f, Loader=Loader)\n",
    "\n",
    "data_path = manifest['data_path']\n",
    "subject = manifest['sub']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akamsali/anaconda3/envs/research_env/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630815121/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "from auditory_cortex.Regression import transformer_regression\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sub = '200206'\n",
    "\n",
    "# reg = transformer_regression(\"/Users/akshita/Documents/Research/Makin/data\", '200206')\n",
    "reg = transformer_regression('/depot/jgmakin/data/auditory_cortex/josh_data/data',sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = np.arange(450,499).tolist()\n",
    "\n",
    "a, b = reg.get_layer_values_and_spikes(layer=0, win=80, sent_list=test_list)\n",
    "\n",
    "# import \n",
    "# a = reg.spikes_dict[0]\n",
    "# spikes = list(map(lambda i: np.array(list(a[i].values())).T, test_list))\n",
    "# spikes = np.concatenate(spikes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akamsali/anaconda3/envs/research_env/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630815121/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    }
   ],
   "source": [
    "from auditory_cortex.Regression import transformer_regression\n",
    "\n",
    "import yaml\n",
    "from yaml import Loader\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "conf_path = '/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/conf/ridge_conf.yaml'\n",
    "\n",
    "# conf_path = '/Users/akshita/Documents/Research/Makin/Auditory_Cortex/conf/ridge_conf.yaml'\n",
    "with open(conf_path, \"r\") as f:\n",
    "    manifest = yaml.load(f, Loader=Loader)\n",
    "\n",
    "data_path = manifest['data_path']\n",
    "subject = manifest['sub']\n",
    "output_dir = manifest['output_dir']\n",
    "\n",
    "# data_path = '/Users/akshita/Documents/Research/Makin/data'\n",
    "# subject = '200206'\n",
    "# output_dir = '/Users/akshita/Documents/Research/Makin/Auditory_Cortex'\n",
    "\n",
    "reg = transformer_regression(data_path, subject)\n",
    "\n",
    "test_list = np.arange(450,499).tolist()\n",
    "# train_val_list = np.arange(1,450)\n",
    "train_list = np.arange(1,450).tolist()\n",
    "w = 80\n",
    "sp = 1\n",
    "num_layers = len(reg.layers)\n",
    "l = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1259, 512) (1259, 64)\n"
     ]
    }
   ],
   "source": [
    "l=1\n",
    "z_vals_test, n_vals_test = reg.get_layer_values_and_spikes(layer=l, win=80, sent_list=test_list)\n",
    "z_vals_train, n_vals_train = reg.get_layer_values_and_spikes(layer=l, win=80, sent_list=train_list)\n",
    "\n",
    "print(z_vals_test.shape, n_vals_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_model_sk = Ridge(alpha=100000)\n",
    "ridge_model_sk.fit(z_vals_train, n_vals_train)\n",
    "y_hat_train = ridge_model_sk.predict(z_vals_train)\n",
    "# y_hat_val = ridge_model.predict(x_val)\n",
    "y_hat_test = ridge_model_sk.predict(z_vals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex.ridge_regression import RidgeRegression \n",
    "alpha = 1\n",
    "ridge_model = RidgeRegression(alpha=alpha)\n",
    "ridge_model.fit(z_vals_train, n_vals_train)\n",
    "n_hat_train = ridge_model.predict(z_vals_train)\n",
    "# n_hat_val = ridge_model.predict(z_vals_val)\n",
    "n_hat_test = ridge_model.predict(z_vals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37655905062586736, 0.4450015411712978, 0.3738982906851931, 0.5682936523435732, 0.3454029437725193, 0.5113960279519028, 0.5165023766587291, 0.4870259764051346, 0.47278537823057226, 0.44674731783036203, 0.6050633650671854, 0.49129479830730144, 0.41305990712687796, 0.6672900504980572, 0.6520812804988342, 0.5811076316781143, 0.6945279816127912, 0.6462904845099381, 0.5289983696747738, 0.5673796928496246, 0.5911058761789999, 0.4655827315411057, 0.4358614762912036, 0.635025349356881, 0.6351760635437599, 0.4379832830003546, 0.4365922446163854, 0.3828786499504275, 0.3922924071659087, 0.5656926627456551, 0.6158888490527364, 0.5810059153503508, 0.732549906666409, 0.3692391562209384, 0.4611035866203903, 0.5307589448908084, 0.4665570915022749, 0.472359889261528, 0.4485252752346723, 0.4092908389591102, 0.4226504950381487, 0.45699083625544545, 0.24316062917523468, 0.5390737928039884, 0.4452689312929011, 0.5017726302725785, 0.45730745172826137, 0.5599630062217577, 0.5145251736764272, 0.40437596042955887, 0.4453130932041884, 0.5223142328708056, 0.586974207087954, 0.4144047325648956, 0.46871542438913966, 0.5358109609124159, 0.4525977010756701, 0.5592580292690132, 0.5378272486365296, 0.5732835455211609, 0.731830521662665, 0.6056144930995866, 0.7421871523032895, 0.6845356044273812] [0.1937191889779301, 0.3096707452061557, 0.24685192879236803, 0.47091605656663027, 0.13571502745504102, 0.3736196458051234, 0.38388095548082485, 0.3351600700280684, 0.33442499954346677, 0.3100771312345444, 0.48054199324216096, 0.34548779537070756, 0.2207572417911422, 0.6390216833649727, 0.559533975329405, 0.5070267660628297, 0.6243603570675784, 0.5974056957564858, 0.4380378303764541, 0.4747030666452451, 0.5012514794394123, 0.31471626868962754, 0.25303769357230527, 0.5775572439478686, 0.552591047345924, 0.2970497021662962, 0.32039553812674415, 0.21764086623453754, 0.28265764788694003, 0.4050251794467845, 0.4869445150309343, 0.4266898638086248, 0.6993223019055483, 0.24039774850169432, 0.3679661677702544, 0.33420730214669214, 0.4422179085306928, 0.3909149687728703, 0.4535647816161429, 0.2644632571196475, 0.3015441322896784, 0.35289589190111004, 0.024825519781846772, 0.40604233828750463, 0.3378156625169389, 0.43984371898676183, 0.3810726816044017, 0.549657566427095, 0.4750908757386928, 0.27918866280947413, 0.3605434560292112, 0.45403142170031047, 0.5804896416554344, 0.3303677223810926, 0.33329109103326626, 0.4837873469455302, 0.38579076436490595, 0.5095695399352134, 0.47334269777639293, 0.5239462213614716, 0.6962243162999411, 0.5391368520202197, 0.7183558534725373, 0.6212880579937415]\n"
     ]
    }
   ],
   "source": [
    "sp = 1\n",
    "r2t = []\n",
    "r2tt = []\n",
    "for i in range(64):\n",
    "    r2t.append(reg.cc_norm(n_hat_train[:, i], n_vals_train[:, i], sp=sp))\n",
    "    # r2v = reg.cc_norm(n_hat_val, n_vals_val, sp=sp)\n",
    "    r2tt.append(reg.cc_norm(n_hat_test[:, i], n_vals_test[:, i], sp=sp))\n",
    "\n",
    "# print(r2t, r2tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "a.append(r2t)\n",
    "a.append(r2tt)\n",
    "a.append(r2tt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "test = {1: {2:3, 4:5}}\n",
    "with open(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/experiments/test\", \"w\") as f:\n",
    "    json.dump(test, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.24503451602682352, test: 0.1958667412476236\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: {r2_score(n_vals_train, y_hat_train)}, test: {r2_score(n_vals_test, y_hat_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "from auditory_cortex.ridge_regression import RidgeRegression \n",
    "\n",
    "r2t = 0\n",
    "r2v = 0\n",
    "r2tt = 0\n",
    "sp = 1\n",
    "l = 0\n",
    "w = 80\n",
    "\n",
    "test_list = np.arange(450,499).tolist()\n",
    "train_val_list = np.arange(1,450)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "k_val_test , def_w_test, offset_test, z_vals_test = reg.get_layer_values(l, win=w, sent_list=test_list)\n",
    "print(f\"layer extract time = {time.time() - start}\")\n",
    "start = time.time()\n",
    "n_vals_test = reg.get_all_channels(def_w=def_w_test, offset=offset_test, k_val=k_val_test, sent_list=test_list)\n",
    "print(f\"spike extract time = {time.time() - start}\")\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "# kf.get_n_splits(train_val_list)\n",
    "\n",
    "# for alpha in \n",
    "ridge_model = RidgeRegression(alpha=10)\n",
    "for train, val in kf.split(train_val_list):\n",
    "    start = time.time()\n",
    "    \n",
    "    k_val_train , def_w_train, offset_train, z_vals_train = reg.get_layer_values(layer=l, win=w, sent_list=train_val_list[train])\n",
    "    n_vals_train = reg.get_all_channels(def_w=def_w_train, offset=offset_train, k_val=k_val_train, sent_list=train_val_list[train])\n",
    "\n",
    "    k_val_val , def_w_val, offset_val, z_vals_val = reg.get_layer_values(layer=l,win=w, sent_list=train_val_list[val])\n",
    "    n_vals_val = reg.get_all_channels(def_w=def_w_val, offset=offset_val, k_val=k_val_val, sent_list=train_val_list[val])\n",
    "\n",
    "    ridge_model.fit(z_vals_train, n_vals_train)\n",
    "    n_hat_train = ridge_model.predict(z_vals_train)\n",
    "    n_hat_val = ridge_model.predict(z_vals_val)\n",
    "\n",
    "    n_hat_test = ridge_model.predict(z_vals_test)\n",
    "    r2t += reg.cc_norm(n_hat_train, n_vals_train, sp=sp)\n",
    "    r2v += reg.cc_norm(n_hat_val, n_vals_val, sp=sp)\n",
    "    r2tt += reg.cc_norm(n_hat_test, n_vals_test, sp=sp)\n",
    "    print(f\"one iter time = {time.time() - start}, {[r2t, r2v, r2tt]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex.Regression import transformer_regression\n",
    "\n",
    "import json \n",
    "import sys\n",
    "\n",
    "# print(sys.argv)\n",
    "# sub = sys.argv[1]\n",
    "# w = sys.argv[2]\n",
    "\n",
    "# print(\"arg vals\",sub, int(w))\n",
    "sub = '200206'\n",
    "w = 80\n",
    "reg = transformer_regression('/depot/jgmakin/data/auditory_cortex/josh_data/data',sub)\n",
    "\n",
    "# channels = np.arange(0,reg.dataset.num_channels).tolist()\n",
    "num_layers = len(reg.layers)\n",
    "corr_values = {}\n",
    "for ch in range(1):\n",
    "    print(ch)\n",
    "    R2t =[]  \n",
    "    R2v =[] \n",
    "    R2tt =[]\n",
    "    for l in range(num_layers):\n",
    "        r2t, r2v,r2tt = reg.get_cc_norm(l,int(w),channel=ch, delay=0)\n",
    "        # print(r2t)\n",
    "        R2t.append(r2t.item())\n",
    "        R2v.append(r2v.item())\n",
    "        R2tt.append(r2tt.item())\n",
    "        # PCt.append(pct)\n",
    "        # PCv.append(pcv)\n",
    "        # PCtt.append(pctt)\n",
    "    corr_values[ch] =  {\"train\": R2t, \"val\": R2v, \"test\": R2tt}\n",
    "    print(corr_values[ch])\n",
    "# fig, ax = plt.subplots(1,2, figsize=(14,6), sharey=True)\n",
    "\n",
    "# with open(\"/scratch/gilbreth/akamsali/Research/Makin/outputs/neuron_corr/\"+sub + \"_\" + str(w), 'w') as f:\n",
    "#     json.dump(corr_values, f)\n",
    "\n",
    "with open(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/\"+sub + \"_\" + str(w), 'a') as f:\n",
    "    json.dump(corr_values, f)\n",
    "\n",
    "    \n",
    "# plt.plot(R2t, label='Training')\n",
    "# plt.plot(R2v, label='Val')\n",
    "# plt.plot(R2tt, label='Test')\n",
    "# plt.legend()\n",
    "\n",
    "\n",
    "# ax[0].plot(R2t, label='Training')\n",
    "# ax[0].plot(R2v, label='Val')\n",
    "# ax[0].plot(R2tt, label='Test')\n",
    "# ax[0].legend()\n",
    "# ax[0].set_title(\"R2\")\n",
    "\n",
    "\n",
    "# ax[1].plot(PCt, label='Training')\n",
    "# ax[1].plot(PCv, label='Val')\n",
    "# ax[1].plot(PCtt, label='Test')\n",
    "# ax[1].legend()\n",
    "# ax[1].set_title(\"PC\")\n",
    "\n",
    "# plt.title(\"200213, bin_width=\"+ str(w))\n",
    "# # plt.savefig(\"/Users/akshita/Documents/Research/Makin/outputs/200213_\" + str(w))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from Dataset import Neural_Data\n",
    "\n",
    "\n",
    "neural_data = Neural_Data('/Users/akshita/Documents/Research/Makin/data',\"200206\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_sents = {}\n",
    "for i in range(499):\n",
    "    data = neural_data.retrieve_spikes_count_for_all_trials(i, w=100)\n",
    "    if data[1].shape[0] > 1:\n",
    "        repeated_sents[i] = data[1].shape\n",
    "print(repeated_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "# print(channel.shape)\n",
    "\n",
    "# sents = [12,13,32,43,56,163,212,218,287,308]\n",
    "sents = [12]\n",
    "# sent_vals = {}\n",
    "# wins = [1,5,10,20,30,40,50,75,100,200]\n",
    "wins = [10]\n",
    "for w in wins:\n",
    "    for sent in sents:\n",
    "        data = neural_data.retrieve_spikes_count_for_all_trials(sent, w=w)\n",
    "\n",
    "        for j in range(len(data)):\n",
    "            channel = data[j]\n",
    "            # print(channel.shape)\n",
    "            cnt = 0\n",
    "            val = []\n",
    "            p_r = []\n",
    "            for shift in [0]:#1, 5, 10]:\n",
    "                for i in range(11):\n",
    "                    cnt+=1.0\n",
    "                    ind = np.arange(0,11,1)\n",
    "                    b_ind = ind[i]\n",
    "                    a_ind = np.delete(ind, i)\n",
    "                    # print(a_ind, b_ind)\n",
    "                    a = np.mean(channel[a_ind, :], axis=0)\n",
    "                    b = channel[b_ind,:]\n",
    "                    b = np.roll(b, shift)\n",
    "                    \n",
    "                    res = stats.linregress(a, b)\n",
    "                    pearson_r = stats.pearsonr(a, b)\n",
    "                    val.append(res.rvalue**2)\n",
    "                    p_r.append(pearson_r[0]**2)\n",
    "\n",
    "                with open(\"/home/amy/Documents/Research/Makin/outputs/good_sessions/linreg_cs_win_\" + str(w)+ \"_\"+ str(sent) +\"_\" + str(shift)+\".csv\", 'a') as f:\n",
    "                    writer=csv.writer(f)\n",
    "                    row = val \n",
    "                    writer.writerow(row)\n",
    "                    f.close()\n",
    "    print(\"done: \", w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.arange(0,11,1)\n",
    "b_ind = ind[i]\n",
    "a_ind = np.delete(ind, i)\n",
    "print(a_ind, b_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fig, ax = plt.subplots(4, len(wins),sharey=True,figsize=(5,6))\n",
    "\n",
    "for i, shift in enumerate([0, 1, 5, 10]):\n",
    "    for j, w in enumerate(wins):\n",
    "        for sent in sents:\n",
    "        # plt.figure()\n",
    "            d = pd.read_csv(\"/home/amy/Documents/Research/Makin/outputs/good_sessions/linreg_cs_win_\" + str(w)+ \"_\"+ str(sent) +\"_\" + str(shift)+ \".csv\", header=None)\n",
    "            d.columns = [\"channels\", \"reg_r2\", \"pearson_r2\"]\n",
    "\n",
    "            avg_r2 = d['reg_r2'].to_numpy()\n",
    "            pearson_r2 = d['pearson_r2'].to_numpy()\n",
    "            # print(avg_r2.shape, pearson_r2.shape)\n",
    "\n",
    "            # channels = d['channels'].to_numpy()\n",
    "            # plt.figure()\n",
    "            # ax[i, j].plot(channels, avg_r2, label=str(sent))\n",
    "            ax[i].plot(avg_r2-pearson_r2, label=str(sent))\n",
    "            ax[0].set_title(f\"Win={w}\")\n",
    "            ax[i].set_ylabel(f\"Shift={shift}\")\n",
    "            plt.ylim(-1.25, 0.8)\n",
    "        # plt.xlabel(\"channels\")\n",
    "    # plt.title(f\"Win = {w}\" , fontsize=16)plt.legend()\n",
    "        # plt.savefig(\"/home/amy/Documents/Research/Makin/outputs/correlation/linreg_cs_win_\" + str(w)+ \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, w in enumerate(wins):\n",
    "    for i, shift in enumerate([0,1, 5, 10]):\n",
    "        plt.figure()\n",
    "        for sent in sents:\n",
    "            d = pd.read_csv(\"/home/amy/Documents/Research/Makin/outputs/correlation/linreg_cs_win_\" + str(w)+ \"_\"+ str(sent) +\"_\" + str(shift)+ \".csv\", header=None)\n",
    "            d.columns = [\"channels\", \"reg_r2\", \"pearson_r2\"]\n",
    "\n",
    "            avg_r2 = d['reg_r2'].to_list()\n",
    "            pearson_r2 = d['pearson_r2'].to_list()\n",
    "            channels = d['channels'].to_list()\n",
    "            # plt.figure()\n",
    "            plt.plot(channels, avg_r2, label=str(sent))\n",
    "            plt.title(f\"Win={w}, Shift={shift}\")\n",
    "            # ax[i,j].set_ylabel(f\"Shift={shift}\")\n",
    "            plt.ylim(-0.5, 0.4)\n",
    "        # plt.xlabel(\"channels\")\n",
    "    # plt.title(f\"Win = {w}\" , fontsize=16)plt.legend()\n",
    "        # plt.savefig(\"/home/amy/Documents/Research/Makin/outputs/correlation/linreg_cs_win_\" + str(w)+ \".png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for sent in sents:\n",
    "    d2 = pd.read_csv(\"/home/amy/Documents/Research/Makin/outputs/correlation/linreg_loo_win_ms10_\"+ str(sent) +\".csv\", header=None)\n",
    "    d2.columns = [\"channels\", \"avg_r2\"]\n",
    "\n",
    "    avg_R2 = d2['avg_r2'].to_list()\n",
    "    channels = d2['channels'].to_list()\n",
    "    \n",
    "    plt.plot(channels, avg_R2 ,label=str(sent))\n",
    "    plt.ylim(-1.25, 0.8)\n",
    "plt.title(\"Correlation for sentences ms vs channels, w=10\", fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.zeros(100)\n",
    "b = np.zeros(100)\n",
    "ind_a = np.random.randint(0,100,10)\n",
    "ind_b = np.random.randint(0,100,10)\n",
    "\n",
    "a[ind_a] = 1    \n",
    "b[ind_b] = 1\n",
    "res = stats.linregress(a,b)\n",
    "\n",
    "res.rvalue**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in [1]:\n",
    "    for sent in [12]:\n",
    "        data = neural_data.retrieve_spikes_count_for_all_trials(sent, w=w)\n",
    "\n",
    "        for j in [20]:\n",
    "            channel = data[j]\n",
    "            # for shift in [1, 5, 10]:\n",
    "            for i in range(1):\n",
    "                plt.plot(channel[i], label=j)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ae26810785ba78c37a15c9eb002d2311c93b4a4adb47993511490e08153fac"
  },
  "kernelspec": {
   "display_name": "R 3.6.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
