{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adjsut the basic logging lovel of notebook\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as scp\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from palettable.colorbrewer import qualitative\n",
    "\n",
    "from auditory_cortex.analyses import Correlations\n",
    "from auditory_cortex import results_dir, aux_dir, saved_corr_dir, cache_dir\n",
    "from auditory_cortex.utils import CorrelationUtils\n",
    "from auditory_cortex.plotters.correlation_plotter import RegPlotter\n",
    "\n",
    "from pycolormap_2d import ColorMap2DBremm, ColorMap2DZiegler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/depot/jgmakin/data/auditory_cortex/results/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.data.to_csv(self.corr_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default normalizer file...\n",
      "'whisper_tiny'\n",
      "41\n",
      "[5. 4. 3. 6. 9. 7. 8.]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "# model_name = 'whisper_base'\n",
    "# model_name = 'deepspeech2'\n",
    "# model_name = 'w2v2_audioset'\n",
    "\n",
    "# id = '_trf_300_l2'\n",
    "id = '_trf_300'\n",
    "# id = '_trf_300_l19'\n",
    "# id = '_reset_weights0'\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    )\n",
    "print(f\"'{model_name}'\")\n",
    "print(corr_obj.data['session'].unique().size)\n",
    "print(corr_obj.data['opt_lmbda'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>layer</th>\n",
       "      <th>channel</th>\n",
       "      <th>bin_width</th>\n",
       "      <th>delay</th>\n",
       "      <th>test_cc_raw</th>\n",
       "      <th>normalizer</th>\n",
       "      <th>opt_lag</th>\n",
       "      <th>opt_lmbda</th>\n",
       "      <th>N_sents</th>\n",
       "      <th>poiss_entropy</th>\n",
       "      <th>uncertainty_per_spike</th>\n",
       "      <th>bits_per_spike_NLB</th>\n",
       "      <th>layer_type</th>\n",
       "      <th>normalized_test_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5330</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032489</td>\n",
       "      <td>0.058575</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.134238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5331</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006572</td>\n",
       "      <td>-0.018787</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007201</td>\n",
       "      <td>-0.007580</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>-0.003260</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100413</td>\n",
       "      <td>0.141999</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.266469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128379</td>\n",
       "      <td>0.100337</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.405288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052928</td>\n",
       "      <td>-0.002032</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>-0.016327</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5338</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.006528</td>\n",
       "      <td>-0.007103</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5339</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.179445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5340</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012792</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5341</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012465</td>\n",
       "      <td>-0.008276</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5342</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081641</td>\n",
       "      <td>0.066731</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.316039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029272</td>\n",
       "      <td>0.008376</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.319837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5344</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047501</td>\n",
       "      <td>0.013740</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.405228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5345</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057172</td>\n",
       "      <td>0.043545</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.273976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       session  layer  channel  bin_width  delay  test_cc_raw  normalizer  \\\n",
       "5330  180728.0    3.0      0.0       50.0    0.0     0.032489    0.058575   \n",
       "5331  180728.0    3.0      1.0       50.0    0.0     0.006572   -0.018787   \n",
       "5332  180728.0    3.0      2.0       50.0    0.0     0.007201   -0.007580   \n",
       "5333  180728.0    3.0      3.0       50.0    0.0     0.015761   -0.003260   \n",
       "5334  180728.0    3.0      4.0       50.0    0.0     0.100413    0.141999   \n",
       "5335  180728.0    3.0      5.0       50.0    0.0     0.128379    0.100337   \n",
       "5336  180728.0    3.0      6.0       50.0    0.0     0.052928   -0.002032   \n",
       "5337  180728.0    3.0      7.0       50.0    0.0     0.006711   -0.016327   \n",
       "5338  180728.0    3.0      8.0       50.0    0.0    -0.006528   -0.007103   \n",
       "5339  180728.0    3.0      9.0       50.0    0.0     0.021071    0.013788   \n",
       "5340  180728.0    3.0     10.0       50.0    0.0    -0.012792   -0.018507   \n",
       "5341  180728.0    3.0     11.0       50.0    0.0    -0.012465   -0.008276   \n",
       "5342  180728.0    3.0     12.0       50.0    0.0     0.081641    0.066731   \n",
       "5343  180728.0    3.0     13.0       50.0    0.0     0.029272    0.008376   \n",
       "5344  180728.0    3.0     14.0       50.0    0.0     0.047501    0.013740   \n",
       "5345  180728.0    3.0     15.0       50.0    0.0     0.057172    0.043545   \n",
       "\n",
       "      opt_lag  opt_lmbda  N_sents  poiss_entropy  uncertainty_per_spike  \\\n",
       "5330    300.0        5.0    500.0            0.0                    0.0   \n",
       "5331    300.0        5.0    500.0            0.0                    0.0   \n",
       "5332    300.0        5.0    500.0            0.0                    0.0   \n",
       "5333    300.0        5.0    500.0            0.0                    0.0   \n",
       "5334    300.0        5.0    500.0            0.0                    0.0   \n",
       "5335    300.0        5.0    500.0            0.0                    0.0   \n",
       "5336    300.0        5.0    500.0            0.0                    0.0   \n",
       "5337    300.0        5.0    500.0            0.0                    0.0   \n",
       "5338    300.0        5.0    500.0            0.0                    0.0   \n",
       "5339    300.0        5.0    500.0            0.0                    0.0   \n",
       "5340    300.0        5.0    500.0            0.0                    0.0   \n",
       "5341    300.0        5.0    500.0            0.0                    0.0   \n",
       "5342    300.0        5.0    500.0            0.0                    0.0   \n",
       "5343    300.0        5.0    500.0            0.0                    0.0   \n",
       "5344    300.0        5.0    500.0            0.0                    0.0   \n",
       "5345    300.0        5.0    500.0            0.0                    0.0   \n",
       "\n",
       "      bits_per_spike_NLB   layer_type  normalized_test_cc  \n",
       "5330                 0.0  transformer            0.134238  \n",
       "5331                 0.0  transformer                 NaN  \n",
       "5332                 0.0  transformer                 NaN  \n",
       "5333                 0.0  transformer                 NaN  \n",
       "5334                 0.0  transformer            0.266469  \n",
       "5335                 0.0  transformer            0.405288  \n",
       "5336                 0.0  transformer                 NaN  \n",
       "5337                 0.0  transformer                 NaN  \n",
       "5338                 0.0  transformer                 NaN  \n",
       "5339                 0.0  transformer            0.179445  \n",
       "5340                 0.0  transformer                 NaN  \n",
       "5341                 0.0  transformer                 NaN  \n",
       "5342                 0.0  transformer            0.316039  \n",
       "5343                 0.0  transformer            0.319837  \n",
       "5344                 0.0  transformer            0.405228  \n",
       "5345                 0.0  transformer            0.273976  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_obj.data[\n",
    "\t(corr_obj.data['session']==180728) &\\\n",
    "\t(corr_obj.data['layer']==3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default normalizer file...\n",
      "'deepspeech2'\n",
      "4\n",
      "[5. 7.]\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'whisper_tiny'\n",
    "# model_name = 'whisper_base'\n",
    "model_name = 'deepspeech2'\n",
    "# model_name = 'w2v2_audioset'\n",
    "\n",
    "id = '_trf_300_l3'\n",
    "# id = '_trf_300_l19'\n",
    "# id = '_reset_weights0'\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    )\n",
    "print(f\"'{model_name}'\")\n",
    "print(corr_obj.data['session'].unique().size)\n",
    "print(corr_obj.data['opt_lmbda'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180413., 180420., 180501., 180502., 180613., 180622., 180627.,\n",
       "       180717., 180719., 180720., 180724., 180728.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_obj.data['session'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default normalizer file...\n",
      "'deepspeech2'\n",
      "2\n",
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'whisper_tiny'\n",
    "# model_name = 'whisper_base'\n",
    "model_name = 'deepspeech2'\n",
    "# model_name = 'w2v2_audioset'\n",
    "\n",
    "id = '_trf_300_l3'\n",
    "# id = '_trf_300_l19'\n",
    "# id = '_reset_weights0'\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    )\n",
    "print(f\"'{model_name}'\")\n",
    "print(corr_obj.data['session'].unique().size)\n",
    "print(corr_obj.data['opt_lmbda'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default normalizer file...\n",
      "'deepspeech2'\n",
      "3\n",
      "[5.]\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'whisper_tiny'\n",
    "# model_name = 'whisper_base'\n",
    "model_name = 'deepspeech2'\n",
    "# model_name = 'w2v2_audioset'\n",
    "\n",
    "id = '_trf_300_l2'\n",
    "# id = '_trf_300_l19'\n",
    "# id = '_reset_weights0'\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    )\n",
    "print(f\"'{model_name}'\")\n",
    "print(corr_obj.data['session'].unique().size)\n",
    "print(corr_obj.data['opt_lmbda'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([48.,  0., 32.,  0.,  0.,  0.,  0.,  0.,  0., 32.]),\n",
       " array([ 5. ,  5.5,  6. ,  6.5,  7. ,  7.5,  8. ,  8.5,  9. ,  9.5, 10. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(corr_obj.data['opt_lmbda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>layer</th>\n",
       "      <th>channel</th>\n",
       "      <th>bin_width</th>\n",
       "      <th>delay</th>\n",
       "      <th>test_cc_raw</th>\n",
       "      <th>normalizer</th>\n",
       "      <th>opt_lag</th>\n",
       "      <th>opt_lmbda</th>\n",
       "      <th>N_sents</th>\n",
       "      <th>poiss_entropy</th>\n",
       "      <th>uncertainty_per_spike</th>\n",
       "      <th>bits_per_spike_NLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session  layer  channel  bin_width  delay  test_cc_raw  normalizer  \\\n",
       "181  180728.0    3.0      5.0       50.0    0.0     0.128379         0.0   \n",
       "\n",
       "     opt_lag  opt_lmbda  N_sents  poiss_entropy  uncertainty_per_spike  \\\n",
       "181    300.0        5.0    500.0            0.0                    0.0   \n",
       "\n",
       "     bits_per_spike_NLB  \n",
       "181                 0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = 180728\n",
    "ch=5\n",
    "corr_obj.data[(corr_obj.data['session']==sess)&\\\n",
    "\t(corr_obj.data['channel']==ch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default normalizer file...\n",
      "'whisper_tiny'\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "\n",
    "id = '_test_all_trials'\n",
    "# id = '_reset_weights0'\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    )\n",
    "print(f\"'{model_name}'\")\n",
    "print(corr_obj.data['session'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>layer</th>\n",
       "      <th>channel</th>\n",
       "      <th>bin_width</th>\n",
       "      <th>delay</th>\n",
       "      <th>train_cc_raw</th>\n",
       "      <th>test_cc_raw</th>\n",
       "      <th>poiss_entropy</th>\n",
       "      <th>uncertainty_per_spike</th>\n",
       "      <th>bits_per_spike_NLB</th>\n",
       "      <th>normalizer</th>\n",
       "      <th>N_sents</th>\n",
       "      <th>opt_delays</th>\n",
       "      <th>layer_type</th>\n",
       "      <th>normalized_test_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056051</td>\n",
       "      <td>1.764718e+00</td>\n",
       "      <td>1.229927e-02</td>\n",
       "      <td>-4.551600e-03</td>\n",
       "      <td>0.100337</td>\n",
       "      <td>500.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>conv</td>\n",
       "      <td>0.176951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078267</td>\n",
       "      <td>1.770179e+00</td>\n",
       "      <td>1.245770e-02</td>\n",
       "      <td>-4.607283e-03</td>\n",
       "      <td>0.100337</td>\n",
       "      <td>500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>conv</td>\n",
       "      <td>0.247086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098009</td>\n",
       "      <td>1.788465e+00</td>\n",
       "      <td>1.258639e-02</td>\n",
       "      <td>-4.735976e-03</td>\n",
       "      <td>0.100337</td>\n",
       "      <td>500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.309411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106846</td>\n",
       "      <td>1.759185e+00</td>\n",
       "      <td>1.238033e-02</td>\n",
       "      <td>-4.529915e-03</td>\n",
       "      <td>0.100337</td>\n",
       "      <td>500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.337310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081583</td>\n",
       "      <td>1.817622e+00</td>\n",
       "      <td>1.266799e-02</td>\n",
       "      <td>-4.949849e-03</td>\n",
       "      <td>0.100337</td>\n",
       "      <td>500.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.257556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135081</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.277417</td>\n",
       "      <td>1.619510e+05</td>\n",
       "      <td>1.578689e+03</td>\n",
       "      <td>-1.578652e+03</td>\n",
       "      <td>0.287904</td>\n",
       "      <td>500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>conv</td>\n",
       "      <td>-0.517023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135097</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.329363</td>\n",
       "      <td>9.862591e+05</td>\n",
       "      <td>9.613994e+03</td>\n",
       "      <td>-9.613957e+03</td>\n",
       "      <td>0.287904</td>\n",
       "      <td>500.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>-0.613834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135113</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.233008</td>\n",
       "      <td>1.503735e+06</td>\n",
       "      <td>1.455994e+04</td>\n",
       "      <td>-1.455990e+04</td>\n",
       "      <td>0.287904</td>\n",
       "      <td>500.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>-0.434257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135129</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.215377</td>\n",
       "      <td>5.085529e+08</td>\n",
       "      <td>4.924073e+06</td>\n",
       "      <td>-4.924073e+06</td>\n",
       "      <td>0.287904</td>\n",
       "      <td>500.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>-0.401399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135145</th>\n",
       "      <td>180728.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133831</td>\n",
       "      <td>7.924480e+09</td>\n",
       "      <td>7.830553e+07</td>\n",
       "      <td>-7.830553e+07</td>\n",
       "      <td>0.287904</td>\n",
       "      <td>500.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>transformer</td>\n",
       "      <td>0.249421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         session  layer  channel  bin_width  delay  train_cc_raw  test_cc_raw  \\\n",
       "1061    180728.0    0.0      5.0       50.0    0.0           0.0     0.056051   \n",
       "1077    180728.0    1.0      5.0       50.0    0.0           0.0     0.078267   \n",
       "1093    180728.0    2.0      5.0       50.0    0.0           0.0     0.098009   \n",
       "1109    180728.0    3.0      5.0       50.0    0.0           0.0     0.106846   \n",
       "1125    180728.0    4.0      5.0       50.0    0.0           0.0     0.081583   \n",
       "...          ...    ...      ...        ...    ...           ...          ...   \n",
       "135081  180728.0    1.0      5.0      800.0    0.0           0.0    -0.277417   \n",
       "135097  180728.0    2.0      5.0      800.0    0.0           0.0    -0.329363   \n",
       "135113  180728.0    3.0      5.0      800.0    0.0           0.0    -0.233008   \n",
       "135129  180728.0    4.0      5.0      800.0    0.0           0.0    -0.215377   \n",
       "135145  180728.0    5.0      5.0      800.0    0.0           0.0     0.133831   \n",
       "\n",
       "        poiss_entropy  uncertainty_per_spike  bits_per_spike_NLB  normalizer  \\\n",
       "1061     1.764718e+00           1.229927e-02       -4.551600e-03    0.100337   \n",
       "1077     1.770179e+00           1.245770e-02       -4.607283e-03    0.100337   \n",
       "1093     1.788465e+00           1.258639e-02       -4.735976e-03    0.100337   \n",
       "1109     1.759185e+00           1.238033e-02       -4.529915e-03    0.100337   \n",
       "1125     1.817622e+00           1.266799e-02       -4.949849e-03    0.100337   \n",
       "...               ...                    ...                 ...         ...   \n",
       "135081   1.619510e+05           1.578689e+03       -1.578652e+03    0.287904   \n",
       "135097   9.862591e+05           9.613994e+03       -9.613957e+03    0.287904   \n",
       "135113   1.503735e+06           1.455994e+04       -1.455990e+04    0.287904   \n",
       "135129   5.085529e+08           4.924073e+06       -4.924073e+06    0.287904   \n",
       "135145   7.924480e+09           7.830553e+07       -7.830553e+07    0.287904   \n",
       "\n",
       "        N_sents  opt_delays   layer_type  normalized_test_cc  \n",
       "1061      500.0        80.0         conv            0.176951  \n",
       "1077      500.0       100.0         conv            0.247086  \n",
       "1093      500.0       100.0  transformer            0.309411  \n",
       "1109      500.0       100.0  transformer            0.337310  \n",
       "1125      500.0        90.0  transformer            0.257556  \n",
       "...         ...         ...          ...                 ...  \n",
       "135081    500.0       100.0         conv           -0.517023  \n",
       "135097    500.0       100.0  transformer           -0.613834  \n",
       "135113    500.0        80.0  transformer           -0.434257  \n",
       "135129    500.0        80.0  transformer           -0.401399  \n",
       "135145    500.0        60.0  transformer            0.249421  \n",
       "\n",
       "[84 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = 180728\n",
    "ch=5\n",
    "corr_obj.data[(corr_obj.data['session']==sess)&\\\n",
    "\t(corr_obj.data['channel']==ch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine correlations for TRF models.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sessions_done(model_name, identifier, verbose=False):\n",
    "\t\"\"\"Display the number of sessions done for all bin widths\n",
    "\t\"\"\"\n",
    "\tif verbose:\n",
    "\t\tprint(f\"For '{model_name}', '{identifier}'\")\n",
    "\tcorr_obj = Correlations(model_name+'_'+identifier)\n",
    "\tbin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "\treturn_list = []\n",
    "\tfor bin_width in bin_widths:\n",
    "\t\tdata = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"For bin_width: {bin_width:03} ms, sessions done: {len(data['session'].unique())}\")\n",
    "\t\tif len(data['session'].unique()) != 41:\n",
    "\t\t\treturn_list.append(model_name+'_'+identifier+f'{bin_width}')\n",
    "\t\telse:\n",
    "\t\t\treturn_list.append(None)\n",
    "\treturn return_list\n",
    "\n",
    "def check_saved_results(model_names, identifier, verbose=False):\n",
    "\n",
    "\tmodels_not_done = []\n",
    "\tif 'whisper_tiny' in model_names:\n",
    "\t\tfor i in range(6):\n",
    "\t\t\tnot_done = display_sessions_done('whisper_tiny', identifier+f'_l{i}', verbose=verbose)\n",
    "\t\t\tmodels_not_done.extend(not_done)\n",
    "\tif 'whisper_base' in model_names:\n",
    "\t\tfor i in range(8):\n",
    "\t\t\tnot_done = display_sessions_done('whisper_base', identifier+f'_l{i}', verbose=verbose)\n",
    "\t\t\tmodels_not_done.extend(not_done)\n",
    "\tif 'wav2letter_modified' in model_names:\n",
    "\t\tfor i in range(14):\n",
    "\t\t\tnot_done = display_sessions_done('wav2letter_modified', identifier+f'_l{i}', verbose=verbose)\n",
    "\t\t\tmodels_not_done.extend(not_done)\n",
    "\tif 'wav2vec2' in model_names:\n",
    "\t\tfor i in range(21):\n",
    "\t\t\tnot_done = display_sessions_done('wav2vec2', identifier+f'_l{i}', verbose=verbose)\n",
    "\t\t\tmodels_not_done.extend(not_done)\n",
    "\n",
    "\tif 'w2v2_audioset' in model_names:\n",
    "\t\tfor i in range(21):\n",
    "\t\t\tnot_done = display_sessions_done('wav2vec2', identifier+f'_l{i}', verbose=verbose)\n",
    "\t\t\tmodels_not_done.extend(not_done)\n",
    "\n",
    "\tif 'speech2text' in model_names:\n",
    "\t\tfor i in range(14):\n",
    "\t\t\tnot_done = display_sessions_done('speech2text', identifier+f'_l{i}', verbose=verbose)\n",
    "\t\t\tmodels_not_done.extend(not_done)\n",
    "\n",
    "\tif 'deepspeech2' in model_names:\n",
    "\t\tfor i in range(7):\n",
    "\t\t\tnot_done = display_sessions_done('deepspeech2', identifier+f'_l{i}', verbose=verbose)\n",
    "\t\t\tmodels_not_done.extend(not_done)\n",
    "\n",
    "\n",
    "\t# remove None entries..\n",
    "\twhile None in models_not_done:\n",
    "\t\tmodels_not_done.remove(None)\n",
    "\t\n",
    "\tif len(models_not_done) ==0:\n",
    "\t\tprint(f\"All models done..for {identifier}\")\n",
    "\telse:\n",
    "\t\tprint(f\"Models with incomplete resutls:\")\n",
    "\t\tfor iden in models_not_done:\n",
    "\t\t\tprint(iden)\n",
    "\t\n",
    "\n",
    "def combine_results_for_all_models(identifier, model_names=None, ):\n",
    "\t\"\"\"Combines results for the list of models provided\"\"\"\n",
    "\tnormalizer_filename = 'modified_bins_normalizer.csv'\n",
    "\tif model_names is None or 'whisper_tiny' in model_names:\n",
    "\t\tids = []\n",
    "\t\tfor i in range(6):\n",
    "\t\t\tids.append(identifier+f'_l{i}')\n",
    "\t\tCorrelations.combine_and_ready('whisper_tiny',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename,\n",
    "\t\t\toutput_identifier=identifier)\n",
    "\tif model_names is None or 'whisper_base' in model_names:\n",
    "\t\tids = []\n",
    "\t\tfor i in range(8):\n",
    "\t\t\tids.append(identifier+f'_l{i}')\n",
    "\t\tCorrelations.combine_and_ready('whisper_base',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename,\n",
    "\t\t\toutput_identifier=identifier)\n",
    "\tif model_names is None or 'wav2letter_modified' in model_names:\n",
    "\t\tids = []\n",
    "\t\tfor i in range(14):\n",
    "\t\t\tids.append(identifier+f'_l{i}')\n",
    "\t\tCorrelations.combine_and_ready('wav2letter_modified',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename,\n",
    "\t\t\toutput_identifier=identifier)\n",
    "\tif model_names is None or 'wav2vec2' in model_names:\n",
    "\t\tids = []\n",
    "\t\tfor i in range(21):\n",
    "\t\t\tids.append(identifier+f'_l{i}')\n",
    "\t\tCorrelations.combine_and_ready('wav2vec2',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename,\n",
    "\t\t\toutput_identifier=identifier)\n",
    "\tif model_names is None or 'speech2text' in model_names:\n",
    "\t\tids = []\n",
    "\t\tfor i in range(14):\n",
    "\t\t\tids.append(identifier+f'_l{i}')\n",
    "\t\tCorrelations.combine_and_ready('speech2text',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename,\n",
    "\t\t\toutput_identifier=identifier)\n",
    "\tif model_names is None or 'deepspeech2' in model_names:\n",
    "\t\tids = []\n",
    "\t\tfor i in range(7):\n",
    "\t\t\tids.append(identifier+f'_l{i}')\n",
    "\t\tCorrelations.combine_and_ready('deepspeech2',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename,\n",
    "\t\t\toutput_identifier=identifier)\n",
    "\tif model_names is None or 'w2v2_audioset' in model_names:\n",
    "\t\tids = []\n",
    "\t\tfor i in range(21):\n",
    "\t\t\tids.append(identifier+f'_l{i}')\n",
    "\t\tCorrelations.combine_and_ready('w2v2_audioset',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename,\n",
    "\t\t\toutput_identifier=identifier)\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'whisper_tiny', 'trf_300_l0'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'whisper_tiny', 'trf_300_l1'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'whisper_tiny', 'trf_300_l2'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'whisper_tiny', 'trf_300_l3'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'whisper_tiny', 'trf_300_l4'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'whisper_tiny', 'trf_300_l5'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "All models done..for trf_300\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "\t# 'wav2letter_modified', 'whisper_base',\n",
    "\t'whisper_tiny',\n",
    "\t# 'deepspeech2', 'speech2text', 'wav2vec2',\n",
    "\t# 'w2v2_audioset'\n",
    "\t]\n",
    "\n",
    "\n",
    "identifier = 'trf_300'\t#in progress\n",
    "check_saved_results(model_names, identifier, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_trf_300_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_trf_300_corr_results.csv\n",
      "Writing back...!\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "\t# 'wav2letter_modified', 'whisper_base',\n",
    "\t'whisper_tiny',\n",
    "\t# 'deepspeech2', 'speech2text', 'wav2vec2',\n",
    "\t# 'w2v2_audioset'\n",
    "\t]\n",
    "identifier = 'trf_300'\t#in progress\n",
    "\n",
    "combine_results_for_all_models(identifier, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default normalizer file...\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_trf_300_corr_results.csv\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "\t# 'wav2letter_modified', 'whisper_base',\n",
    "\t'whisper_tiny',\n",
    "\t# 'deepspeech2', 'speech2text', 'wav2vec2',\n",
    "\t# 'w2v2_audioset'\n",
    "\t]\n",
    "identifier = 'trf_300'\t#in progress\n",
    "for model_name in model_names:\n",
    "\tcorr_obj = Correlations(model_name+'_'+identifier)\n",
    "\tcorr_obj.set_normalizers_using_bootsrap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### corr with modified normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "\n",
    "id = '_trained_all_bins'\n",
    "# id = '_reset_weights0'\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    )\n",
    "print(f\"'{model_name}'\")\n",
    "print(corr_obj.data['session'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sessions = [180725., 190607., 191212., 200226.]\n",
    "all_bad_ids = []\n",
    "for sess in bad_sessions:\n",
    "    all_bad_ids.append(corr_obj.data[corr_obj.data['session'] == sess].index)\n",
    "all_bad_ids = np.concatenate(all_bad_ids)\n",
    "corr_obj.data.drop(all_bad_ids, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wav2letter_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "\n",
    "model_name = 'wav2letter_spect'\n",
    "\n",
    "# id = '_untrained_study2'\n",
    "# id = '_untrained_study7'\n",
    "\n",
    "# id = '_units250_rf65'\n",
    "id = '_units512_rf65'\n",
    "# id = '_units1024_rf65'\n",
    "# id = '_units2048_rf65'\n",
    "# id = '_units256_rf65'\n",
    "\n",
    "# id = '_units2048_rf145'\n",
    "# id = '_units1024_rf145'\n",
    "# id = '_units512_rf145'\n",
    "# id = '_units256_rf145'\n",
    "\n",
    "# in-progress..\n",
    "# Done....\n",
    "\n",
    "# id = '_units2048_rf225'\t\n",
    "# id = '_units1024_rf225'\t\n",
    "# id = '_units512_rf225'\t\n",
    "\n",
    "\n",
    "\n",
    "# id = '_units256_rf225'\t# at 20ms\n",
    "# id = '_units2056rf225'\t# at 50ms\n",
    "\n",
    "# id = '_units256_rf785'\n",
    "# id = '_units512_rf785'\n",
    "# id = '_units1024_rf785'\n",
    "# id = '_units2048_rf785'\n",
    "\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    normalizer_filename=normalizer_filename\n",
    "    )\n",
    "print(f\"'{model_name}'\")\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.get_filepath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_spect'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "num_units = 2048\n",
    "rf = 65\t# RFs done: 65, 145, 225, 785\n",
    "ids = [\n",
    "    f'units{num_units}_rf{rf}',\n",
    "    ]\n",
    "# output_identifier = 'glm'\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename,\n",
    "                            #    output_identifier=output_identifier\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine correlations for models together.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sessions_done(model_name, identifier, verbose=False):\n",
    "\t\"\"\"Display the number of sessions done for all bin widths\n",
    "\t\"\"\"\n",
    "\tif verbose:\n",
    "\t\tprint(f\"For '{model_name}', '{identifier}'\")\n",
    "\tcorr_obj = Correlations(model_name+'_'+identifier)\n",
    "\tbin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "\treturn_list = []\n",
    "\tfor bin_width in bin_widths:\n",
    "\t\tdata = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"For bin_width: {bin_width:03} ms, sessions done: {len(data['session'].unique())}\")\n",
    "\t\tif len(data['session'].unique()) != 41:\n",
    "\t\t\treturn_list.append(model_name+'_'+identifier+f'{bin_width}')\n",
    "\t\telse:\n",
    "\t\t\treturn_list.append(None)\n",
    "\treturn return_list\n",
    "\n",
    "def check_saved_results(model_names, identifier, verbose=False):\n",
    "\n",
    "\tmodels_not_done = []\n",
    "\tif 'whisper_tiny' in model_names:\n",
    "\t\tnot_done = display_sessions_done('whisper_tiny', identifier, verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\tif 'whisper_base' in model_names:\n",
    "\t\tnot_done = display_sessions_done('whisper_base', identifier, verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\tif 'wav2letter_modified' in model_names:\n",
    "\t\tnot_done = display_sessions_done('wav2letter_modified', identifier, verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\t\tnot_done = display_sessions_done('wav2letter_modified', identifier+'_lasttwo', verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\tif 'wav2vec2' in model_names:\n",
    "\t\tnot_done = display_sessions_done('wav2vec2', identifier, verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\t\tnot_done = display_sessions_done('wav2vec2', identifier+'_features', verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\tif 'speech2text' in model_names:\n",
    "\t\tnot_done = display_sessions_done('speech2text', identifier, verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\t\tnot_done = display_sessions_done('speech2text', identifier+'_l0', verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\t\tnot_done = display_sessions_done('speech2text', identifier+'_l1', verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\tif 'deepspeech2' in model_names:\n",
    "\t\tnot_done = display_sessions_done('deepspeech2', identifier, verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\t\tnot_done = display_sessions_done('deepspeech2', identifier+'_l0', verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\t\tnot_done = display_sessions_done('deepspeech2', identifier+'_l1', verbose=verbose)\n",
    "\t\tmodels_not_done.extend(not_done)\n",
    "\n",
    "\t# remove None entries..\n",
    "\twhile None in models_not_done:\n",
    "\t\tmodels_not_done.remove(None)\n",
    "\t\n",
    "\tif len(models_not_done) ==0:\n",
    "\t\tprint(f\"All models done..for {identifier}\")\n",
    "\telse:\n",
    "\t\tprint(f\"Models with incomplete resutls:\")\n",
    "\t\tfor iden in models_not_done:\n",
    "\t\t\tprint(iden)\n",
    "\t\n",
    "\n",
    "def combine_results_for_all_models(identifier, model_names=None, ):\n",
    "\t\"\"\"Combines results for the list of models provided\"\"\"\n",
    "\tnormalizer_filename = 'modified_bins_normalizer.csv'\n",
    "\tif model_names is None or 'whisper_tiny' in model_names:\n",
    "\t\tids = [\n",
    "\t\t\tidentifier,\n",
    "\t\t\t]\n",
    "\t\tCorrelations.combine_and_ready('whisper_tiny',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename)\n",
    "\tif model_names is None or 'whisper_base' in model_names:\n",
    "\t\tids = [\n",
    "\t\t\tidentifier,\n",
    "\t\t\t]\n",
    "\t\tCorrelations.combine_and_ready('whisper_base',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename)\n",
    "\tif model_names is None or 'wav2letter_modified' in model_names:\n",
    "\t\tids = [\n",
    "\t\t\tidentifier,\n",
    "\t\t\tf'{identifier}_lasttwo',\n",
    "\t\t\t]\n",
    "\t\tCorrelations.combine_and_ready('wav2letter_modified',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename)\n",
    "\tif model_names is None or 'wav2vec2' in model_names:\n",
    "\t\tids = [\n",
    "\t\t\tidentifier,\n",
    "\t\t\tf'{identifier}_features',\n",
    "\t\t\t]\n",
    "\t\tCorrelations.combine_and_ready('wav2vec2',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename)\n",
    "\tif model_names is None or 'speech2text' in model_names:\n",
    "\t\tids = [\n",
    "\t\t\tidentifier,\n",
    "\t\t\tf'{identifier}_l1',\n",
    "\t\t\tf'{identifier}_l0',\n",
    "\t\t\t]\n",
    "\t\tCorrelations.combine_and_ready('speech2text',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename)\n",
    "\tif model_names is None or 'deepspeech2' in model_names:\n",
    "\t\tids = [\n",
    "\t\t\tidentifier,\n",
    "\t\t\tf'{identifier}_l1',\n",
    "\t\t\tf'{identifier}_l0',\n",
    "\t\t\t]\n",
    "\t\tCorrelations.combine_and_ready('deepspeech2',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename)\n",
    "\tif model_names is None or 'w2v2_audioset' in model_names:\n",
    "\t\tids = [\n",
    "\t\t\tidentifier,\n",
    "\t\t\tf'{identifier}_features',\n",
    "\t\t\t]\n",
    "\t\tCorrelations.combine_and_ready('w2v2_audioset',\n",
    "\t\t\tids, 0, normalizer_filename=normalizer_filename)\n",
    "\t\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'whisper_tiny', 'reset_delays_500'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'whisper_base', 'reset_delays_500'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'wav2letter_modified', 'reset_delays_500'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'wav2letter_modified', 'reset_delays_500_lasttwo'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'wav2vec2', 'reset_delays_500'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'wav2vec2', 'reset_delays_500_features'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'speech2text', 'reset_delays_500'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'speech2text', 'reset_delays_500_l0'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'speech2text', 'reset_delays_500_l1'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'deepspeech2', 'reset_delays_500'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'deepspeech2', 'reset_delays_500_l0'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'deepspeech2', 'reset_delays_500_l1'\n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "All models done..for reset_delays_500\n"
     ]
    }
   ],
   "source": [
    "model_names = [\n",
    "\t'wav2letter_modified', 'whisper_base', 'whisper_tiny',\n",
    "\t'deepspeech2', 'speech2text', 'wav2vec2',\n",
    "\t'w2v2_audioset'\n",
    "\t]\n",
    "\n",
    "# trial 0\n",
    "# identifier = 'test_trial_0'\t#in progress\n",
    "# identifier = 'reset_weights_test_trial_0'\t#in progress\n",
    "\n",
    "# identifier = 'test_all_trials_lmbdas'\t#Done\n",
    "# identifier = 'test_lmbdas_delays'\t#Done\n",
    "\n",
    "# identifier = 'delays_500'\t#Done\n",
    "# identifier = 'reset_delays_500'\t#Done\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "check_saved_results(model_names, identifier, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_reset_delays_500_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_reset_delays_500_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_base_reset_delays_500_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_base_reset_delays_500_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2letter_modified_reset_delays_500_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2letter_modified_reset_delays_500_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2vec2_reset_delays_500_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2vec2_reset_delays_500_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/speech2text_reset_delays_500_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/speech2text_reset_delays_500_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/deepspeech2_reset_delays_500_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/deepspeech2_reset_delays_500_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/w2v2_audioset_reset_delays_500_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/w2v2_audioset_reset_delays_500_corr_results.csv\n",
      "Writing back...!\n"
     ]
    }
   ],
   "source": [
    "# Trained...\n",
    "# bin widths: 20ms and 50ms\n",
    "# identifier = 'test_all_trials'\t#Done\n",
    "# identifier = 'test_all_trials_lmbdas'\t#Done\n",
    "# identifier = 'test_lmbdas_delays'\t#Done\n",
    "# identifier = 'delays_500'\t#Done\n",
    "# identifier = 'reset_delays_500'\t#Done\n",
    "\n",
    "combine_results_for_all_models(identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'wav2letter_modified'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2letter_modified_reset_delays_500_corr_results.csv\n",
      "'whisper_base'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_base_reset_delays_500_corr_results.csv\n",
      "'whisper_tiny'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_reset_delays_500_corr_results.csv\n",
      "'deepspeech2'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/deepspeech2_reset_delays_500_corr_results.csv\n",
      "'speech2text'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/speech2text_reset_delays_500_corr_results.csv\n",
      "'wav2vec2'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2vec2_reset_delays_500_corr_results.csv\n",
      "'w2v2_audioset'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/w2v2_audioset_reset_delays_500_corr_results.csv\n"
     ]
    }
   ],
   "source": [
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "\n",
    "model_names = [\n",
    "\t'wav2letter_modified',\n",
    "\t'whisper_base', 'whisper_tiny',\n",
    "\t'deepspeech2',\n",
    "\t 'speech2text', 'wav2vec2',\n",
    "\t 'w2v2_audioset',\n",
    "\t]\n",
    "for model_name in model_names:\n",
    "# model_name = 'deepspeech2'\n",
    "\t# identifier = '_test_all_trials'\n",
    "\t# identifier = 'test_all_trials_lmbdas'\t#Done\n",
    "\t# identifier = 'test_lmbdas_delays'\t#Done\n",
    "\t# identifier = 'delays_500'\t#Done\n",
    "\tidentifier = 'reset_delays_500'\t#in-progress\n",
    "\n",
    "\t# identifier = '_reset_weights_all_trials0'\n",
    "\t# identifier = '_reset_weights_all_trials1'\n",
    "\t# identifier = '_reset_weights_all_trials2'\n",
    "\t# identifier = '_reset_weights_all_trials3'\n",
    "\n",
    "\n",
    "\t\n",
    "\tcorr_obj = Correlations(\n",
    "\t\tmodel_name=model_name+'_'+identifier,\n",
    "\t\tnormalizer_filename=normalizer_filename\n",
    "\t\t)\n",
    "\tprint(f\"'{model_name}'\")\n",
    "\tcorr_obj.set_normalizers_using_bootsrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 'deepspeech2', 'reset_weights_test_trial1_0'\n",
      "Using default normalizer file...\n",
      "Creating normalizer object from: modified_bins_normalizer.csv\n",
      "Reading existing dataframe.\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'deepspeech2', 'reset_weights_test_trial1_0_l0'\n",
      "Using default normalizer file...\n",
      "Creating normalizer object from: modified_bins_normalizer.csv\n",
      "Reading existing dataframe.\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "For 'deepspeech2', 'reset_weights_test_trial1_0_l1'\n",
      "Using default normalizer file...\n",
      "Creating normalizer object from: modified_bins_normalizer.csv\n",
      "Reading existing dataframe.\n",
      "For bin_width: 50.0 ms, sessions done: 41\n",
      "All models done..for reset_weights_test_trial1_0\n"
     ]
    }
   ],
   "source": [
    "model_names = ['deepspeech2']\n",
    "\n",
    "# trial 0\n",
    "# identifier = 'test_trial_0'\t#Done\n",
    "# identifier = 'reset_weights_test_trial_0'\t#Done\n",
    "# identifier = 'reset_weights_test_trial1_0'\t#Done\n",
    "\n",
    "# Rest of the trials\n",
    "# identifier = 'test_trial_1'\t#Done\n",
    "# identifier = 'test_trial_2'\t#Done\n",
    "# identifier = 'test_trial_3'\t#Done\n",
    "# identifier = 'test_trial_4'\t#Done\n",
    "# identifier = 'test_trial_5'\t#Done\n",
    "# identifier = 'test_trial_6'\t#Done\n",
    "# identifier = 'test_trial_7'\t#Done\n",
    "# identifier = 'test_trial_8'\t#Done\n",
    "# identifier = 'test_trial_9'\t#Done\n",
    "# identifier = 'test_trial_10'\t#Done\n",
    "\n",
    "\n",
    "\n",
    "check_saved_results(model_names, identifier, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/deepspeech2_reset_weights_test_trial1_0_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/deepspeech2_reset_weights_test_trial1_0_corr_results.csv\n",
      "Writing back...!\n",
      "Creating normalizer object from: modified_bins_normalizer.csv\n",
      "Reading existing dataframe.\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/deepspeech2_reset_weights_test_trial1_0_corr_results.csv\n"
     ]
    }
   ],
   "source": [
    "model_names = ['deepspeech2']\n",
    "\n",
    "# trial 0\n",
    "# identifier = 'test_trial_0'\t#Done\n",
    "# identifier = 'test_trial_1'\t#Done\n",
    "# identifier = 'test_trial_2'\t#Done\n",
    "# identifier = 'test_trial_3'\t#Done\n",
    "# identifier = 'test_trial_4'\t#Done\n",
    "# identifier = 'test_trial_5'\t#Done\n",
    "# identifier = 'test_trial_6'\t#Done\n",
    "# identifier = 'test_trial_7'\t#Done\n",
    "# identifier = 'test_trial_8'\t#Done\n",
    "# identifier = 'test_trial_9'\t#Done\n",
    "# identifier = 'test_trial_10'\t#Done\n",
    "\n",
    "# identifier = 'reset_weights_test_trial_0'\t#Done\n",
    "# identifier = 'reset_weights_test_trial1_0'\t#Done\n",
    "\n",
    "\n",
    "combine_results_for_all_models(identifier, model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = [1]\n",
    "new_list = [2,3]\n",
    "\n",
    "new_list.extend(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'wav2letter_modified'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2letter_modified_test_all_trials_lmbdas_corr_results.csv\n",
      "'whisper_base'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_base_test_all_trials_lmbdas_corr_results.csv\n",
      "'whisper_tiny'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_test_all_trials_lmbdas_corr_results.csv\n",
      "'deepspeech2'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/deepspeech2_test_all_trials_lmbdas_corr_results.csv\n",
      "'speech2text'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/speech2text_test_all_trials_lmbdas_corr_results.csv\n",
      "'wav2vec2'\n",
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2vec2_test_all_trials_lmbdas_corr_results.csv\n"
     ]
    }
   ],
   "source": [
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "\n",
    "model_names = [\n",
    "\t'wav2letter_modified',\n",
    "\t'whisper_base', 'whisper_tiny',\n",
    "\t'deepspeech2',\n",
    "\t 'speech2text', 'wav2vec2'\n",
    "\t]\n",
    "for model_name in model_names:\n",
    "# model_name = 'deepspeech2'\n",
    "\t# identifier = '_test_all_trials'\n",
    "\tidentifier = 'test_all_trials_lmbdas'\t#Done\n",
    "\t# identifier = '_reset_weights_all_trials0'\n",
    "\t# identifier = '_reset_weights_all_trials1'\n",
    "\t# identifier = '_reset_weights_all_trials2'\n",
    "\t# identifier = '_reset_weights_all_trials3'\n",
    "\n",
    "\n",
    "\t\n",
    "\tcorr_obj = Correlations(\n",
    "\t\tmodel_name=model_name+'_'+identifier,\n",
    "\t\tnormalizer_filename=normalizer_filename\n",
    "\t\t)\n",
    "\tprint(f\"'{model_name}'\")\n",
    "\tcorr_obj.set_normalizers_using_bootsrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combine models separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For w2v2_audioset sessions done: \n",
      "Using default normalizer file...\n",
      "For bin_width: 50.0 ms= 41\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# res = 'wav2vec2'\n",
    "# res = 'speech2text'\n",
    "# res = 'deepspeech2'\n",
    "# res = 'whisper_tiny'\n",
    "res = 'w2v2_audioset'\n",
    "# res = 'whisper_base'\n",
    "# res = 'wav2letter_modified'\n",
    "print(f\"For {res} sessions done: \")\n",
    "\n",
    "# iden = '_test_lmbdas_wider_range'\n",
    "# iden = '_test_lmbdas_delays'\n",
    "# iden = '_reset_weights_trials_lmbdas_delays'\n",
    "iden = '_reset_weights_trials_lmbdas_delays_features'\n",
    "# iden = '_test_lmbdas'\n",
    "res += iden\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizers updated using normalizer (random pairs) dist , writing back now...\n",
      "Saved at /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/w2v2_audioset_test_lmbdas_delays_corr_results.csv\n"
     ]
    }
   ],
   "source": [
    "corr_obj.set_normalizers_using_bootsrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.remove(corr_obj.get_filepath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '_test_lmbdas_wider_range, 0.4025668378920213')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYy0lEQVR4nO3de7hcVX3G8e9LQuRiYhISKSTAiRKkQFU0IhVBFFQENVHQokhDDUarIm1sMWLViJcCtbX2ES8pKFFQoGgFzYOISFBUqEERGiKUSzChCYRLIAlYhfz6x1pDdoaZM/ucnDmTlbyf55kne8/al9/eM+fda9bsc6KIwMzMyrNdrwswM7PBcYCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAb6ZJJ0v6VODXHeepAuGY19DRdLpks7tp32ZpCOHsyazbdVWFeBDFR6STpJ03VDUtLWJiM9ExMm9rmNLJuntku6RtF7SdyWNr7HOX0oKSSdXnpOksyQ9mB9nSVJu20fSZZJWS3pI0pWSnldZ9yRJT0paV3kc3rTPUyXdnetcKmmfSttESd+U9IikhyVdWGkbL+niXNMDki6UNKbSfk2u61FJv5E0vdJ2elNNj0vaIGlCzW2/TNJ/SVor6WZJL6+0HSPpOklrJK2SdK6k0ZX2Z0j6aq5rlaQ5lbaDJV2Vz+VqSf8habdK+yvzcT0iaVmL16/tMXfTVhXgVi5JI7ux7HCTtD/wFeBEYFfgMeCLHdYZB5wOLGlqmg3MAF4APB94A/Du3DYWuBx4Xt7PfwGXNa3/i4h4ZuWxqLLPk4FZwDHAM4HXAw9U1v0OsArYE3g28NlK26eAccAU4Ll5//Mq7acCu0XEmHwMFzTCMHcAnqoJOAtYFBEPdNp2vhB+D/infPxnA9/L5w/gWXn93YE/BSblZRvmAVOBvYBXAqdJOiq3jQPmA325fS3wtcq664GvAn9Pa22PuasiYqt4AN8ANgCPA+uA0/LzBwM/B9YAvwEOr6xzEnAX6cW6GziB9ML/Hngyb2dNh/2eD3wqTx8OrABOA+4HVpJ+AI8GbgceAk6vrDsPuBS4ONfwK+AFlfYD83Nr8zIXVfY1Dvg+sBp4OE9P7u/YOhzHPcCL8/QJQAD75/lZwHcrNV9QWe/EvO6DwEeAZcCRuW07YC5wZ26/BBif2/ryPmYBvwN+0k9tLZcF/oMUMo8AP2nUW3ldzgEW5nNwA/DcSvtrgNvyul8ErgVOrrS/E1iaz+2VwF4134efAb5ZmX8u8AdgdD/rfBl4L7CoqYafA7Mr87OA69tsY3w+R7tUXv/r2iy7HbAcOKJN+2vy6ziiTfsVwHsr8+8Drmyz7EGkn6eDWrQpv0dn1tk26SKzpGkbtwOz2uz7zcAtlfn/BV5Tmf8kcFGbdV8ErG3x/JHAsg7vgbbHPNSPraYHHhEnkn643xDp6n62pEmkH+BPkd7gfwd8O3883Bn4N+B1ETEaeBlwU0QsBd7Dxt7L2AGW8ifADqSr/8eAfwfeAbwYOBT4qKQpleWnk4JoPPBN4LuStpc0Cvgu6cI0Pi9zbGW97Ug9hL1IvaTHgS8AtDu2DnVfS7oAAbyC9IN1WGX+2uYVJO0HfIkU4rsDuwCTK4ucQrqAvSK3P0wK1apXkC6ar+1QX6tlryD1qJ5NutBd2LT88cAnSBe7O4BP57onkC6cH84130Y6R43jmk7qEb8ZmAj8FPhWjfoA9id1FACIiDtJAb5Pq4UlHQRMI4V4v9vK0/u32e9hwKqIeLDy3IF5GOJ2SR+tfHKZnB8HSFqeh1E+IamRBweTzsmCPJTxS0mvqGz3HOD1ksbl3u+xpNeielzfl/R70oVzEbC4Rc2Hkl67bw9g22rahoAD+jknS3I944DdGNj5bP5E1K+axzy0un2FGM4Hld5fnv8Q8I2mZa4EZgI7k3rlxwI7Ni1zEm16Ly32eT6b9sAfJ/dcgNGkXtFLK8vfCMzI0/Oo9KhIobyS9MY+jNRjUKX95419tajjhcDDebrtsfVzHLOAy/P0UuBkcu+E1MN+UaXmC/L0x6j0YPJ+/8DGHvhSKr080g/QH4GRbOxVP6dGbR2XJX2kDuBZldfl3Er70cBv8/Rfki7QjTaReqQn5/krqPTq8uvyGDV64cDVwHuanruXyie/yvMjSD/kB+f5RWzaA38S2LcyPzUfo5q2Mznv422V555DGobYDvgz4Fbgw7ntZXk7C/N56yP1ZN+V2+ez8RPP9qQL4RpgQm7fHfgR6RPvBuAqYFSL49seeB0wp825Og84v+m5ttsmXWzXAG/L256Zl/lKi22/mtRh2CfP75GPaYemZZa1WPf5pE/Lh7Zo67cH3umYh/qx1fTA29gLeEv+UmONpDXAy0ljVeuBvyD1tldKWihp3yHY54MR8WSefjz/e1+l/XHSmGPD8sZERGwgDcHsnh/3Rn5XZPc0JiTtJOkrSl+WPUoaQhgracQgj+1a4NA8bjeCNNxxiKQ+0tjiTS3W2b2p/vWkoZKGvYD/rJz7paRQ2rXV8dfw1LKSRkg6U9Kd+fiX5aYJleVXVaYfY+N5b647SOe9WvfnK3U/RAr5STVqXAeMaXpuDGkYp9l7gZsj4vqa2xoDrKu+JyRNBH4IfDEinvqUEBF3RcTdEbEhIm4BzgCOy82N9+XZEbEmIpaRxu2PrrQvi4jzIuKPEXER6XwdktsvIQX+6FzTncDT7qbK614BvEbSG6ttknYC3gIsaFqt7bYjfbqYDswh/UwdRQr76muHpINJn2aPi4jbK+eycQ6pTK9tWndv0gX81Ij4afMxddLfMXfD1hbg0TS/nNQDH1t57BwRZwJExJUR8WpSz/C3pOGOVtvppj0aE/kj7GRSz3slMElS9SPjnpXpD5K+wHpppC9OGsMdgn6PraWIuIMUcqeQxpgfJQXgbNKnkQ0tVlvZVP9OpF5Sw3LSME71/O8QEfdWd91fXc1lVqbfTvphPpJ0gelrlFFjOyupDPXkc1wd+lkOvLup7h0j4uc1tr2E9KVjY9vPAZ5BCqVmRwBvyndErCL1jP9Z0hdabStPP/WxPg8L/JD0yenTHeoKNp6b20iflKKpveFmnv66VOdfSOr1ro+IdaThn6NpbyTpu4CqN5EujIuanu932xFxbUS8JCLGk4bu9iV9gQuApANJX+6+MyKurqz3MOl17+987kW6IHwyIr7Rz/HU0eqYh9zWFuD3kT46NlwAvEHSa3OPbQdJh0uaLGlXSdPzePH/ka7QGyrbmZzHobvtxZLenMcn/ybXcj3wC+AJ4AN5TPzNpC9HGkaTekpr8rfzH280dDi2/lwLvJ+N492LmuabXUoar3x5PldnsOl76svAp/MPRuPWtOk16qhjNOnYHgR2In15WNdC4M8kzcjn/X2k7y4avgx8ON9RgqRnSXpLo1HSIknz2mz7QtJ77tB8/s8AvhMRrXrgJ5HG9F+YH4tJY/Yfye1fB+ZImiRpd9JF+/xcwxjScODPImJu84YlvU7Srnl6X+Cj5LtUIuIx0pfip0kaLWky6UL9/bz6fwLjJM3MPzfHkS5wP8vtvwROlrSjpB3zujc39pX3vWN+376D1Llofg/NBL7e9Amz323n7R+YtzuGdGfM8oi4MrcdAPwAOCUivtfifH8d+Ic8vr4v8K7K+ZwE/Bj4QkQ87fsISdtJ2oE0RKKcJaMGeMxDbzjGaYbrQeqR/Y40TvZ3+bmX5hP5EOmOjYWknuxu+flH8vKLgP3yOqPycg8BD3TY5/k03YVSaRtJ6rn0VZ67DnhHnp7Hpneh/Jo81pzbp+XnGnehXFzZ1+655nWk3t27875G9ndsHY6lsY298vzrefoY/jw2vQtlZj7n7e5CmUPq8a0lfRz+TG7ra9Rbo66nLUsaDrksb/ce0rh2AHs3vy5tXpuj8nlr3IXyC+DESvuJwC3Ao6Qe+VcrbXcCr+6n3rfnc7I+1zi+0nYFlTuRmtZbxKZj4CLdKvdQfpxNHv/O5z3yPtZVHnvm9s+SOiLrSV9InwFsX9n2GNJdTWvz8X2sse3cfmg+/nWkC8uhlbYppNv5Hsx1/QCYmtv+lPQl3lrSe++XwJuajnMSqXOyd4tz0Hbbuf1b+TV7hPTz8OxK29dIHZXq+VhSaX8G6VbAR/O5mVNp+3g+n9V11zW9f6LpsajuMXfr0XgzmG2z8tDVCtKtltd0WHYycElEvKy/5cyGw9Y2hGJWSx5WGyvpGaRbBkUauupXRKxweNuWorgAl7SnNv1V3Opjz85bGNQ+l7TZ3wnd2F+3SPpym+NodQ/ycNd2QpvaBnQv7gD8OWko5AHSbzjOiIjH+1/FbMviIRQzs0IV1wM3M7NkWP8o0IQJE6Kvr284d2lmVrwbb7zxgYiY2Pz8sAZ4X18fixd3/88DmJltTSTd0+p5D6GYmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRVqWH8T02xL1Td3Yc/2vezMY3q2byube+BmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygJuZFcoBbmZWKAe4mVmhHOBmZoVygJuZFcoBbmZWqFoBLulvJS2R9N+SviVpB0lTJN0g6Q5JF0sa1e1izcxso44BLmkS8AFgWkQcAIwAjgfOAj4XEXsDDwOzulmomZltqu4QykhgR0kjgZ2AlcCrgEtz+wJgxpBXZ2ZmbXUM8Ii4F/gs8DtScD8C3AisiYgn8mIrgEmt1pc0W9JiSYtXr149NFWbmVmtIZRxwHRgCrA7sDNwVN0dRMT8iJgWEdMmTpw46ELNzGxTdYZQjgTujojVEfFH4DvAIcDYPKQCMBm4t0s1mplZC3UC/HfAwZJ2kiTgCOBW4BrguLzMTOCy7pRoZmat1BkDv4H0ZeWvgFvyOvOBDwFzJN0B7AKc18U6zcysycjOi0BEfBz4eNPTdwEHDXlFZmZWi38T08ysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NC1fpzsmbDpW/uwl6XYFYM98DNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzApVK8AljZV0qaTfSloq6c8ljZd0laT/yf+O63axZma2Ud0e+OeBH0TEvsALgKXAXODqiJgKXJ3nzcxsmHQMcEnPAg4DzgOIiD9ExBpgOrAgL7YAmNGdEs3MrJU6PfApwGrga5J+LelcSTsDu0bEyrzMKmDXVitLmi1psaTFq1evHpqqzcysVoCPBF4EfCkiDgTW0zRcEhEBRKuVI2J+REyLiGkTJ07c3HrNzCyrE+ArgBURcUOev5QU6PdJ2g0g/3t/d0o0M7NWOgZ4RKwClkt6Xn7qCOBW4HJgZn5uJnBZVyo0M7OWRtZc7hTgQkmjgLuAvyKF/yWSZgH3AG/tTolmZtZKrQCPiJuAaS2ajhjSaszMrDb/JqaZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlYoB7iZWaEc4GZmhXKAm5kVygFuZlaouv8jj21D+uYu7HUJ25Rene9lZx7Tk/3a0HEP3MysUA5wM7NCeQjFbBvVy6EyD98MDffAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQtUOcEkjJP1a0vfz/BRJN0i6Q9LFkkZ1r0wzM2s2kB74qcDSyvxZwOciYm/gYWDWUBZmZmb9qxXgkiYDxwDn5nkBrwIuzYssAGZ0oT4zM2ujbg/8X4HTgA15fhdgTUQ8kedXAJNarShptqTFkhavXr16c2o1M7OKjgEu6fXA/RFx42B2EBHzI2JaREybOHHiYDZhZmYt1Plf6Q8B3ijpaGAHYAzweWCspJG5Fz4ZuLd7ZZqZWbOOPfCI+HBETI6IPuB44McRcQJwDXBcXmwmcFnXqjQzs6fZnPvAPwTMkXQHaUz8vKEpyczM6qgzhPKUiFgELMrTdwEHDX1JZmZWh38T08ysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzArlADczK5QD3MysUA5wM7NCOcDNzAo1oP8T08xsKPTNXdiT/S4785ie7Ldb3AM3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK1THAJe0h6RpJt0paIunU/Px4SVdJ+p/877jul2tmZg11euBPAB+MiP2Ag4H3SdoPmAtcHRFTgavzvJmZDZOOAR4RKyPiV3l6LbAUmARMBxbkxRYAM7pUo5mZtTCg/xNTUh9wIHADsGtErMxNq4Bd26wzG5gNsOeeew66UDOzzbW1/V+ctb/ElPRM4NvA30TEo9W2iAggWq0XEfMjYlpETJs4ceJmFWtmZhvVCnBJ25PC+8KI+E5++j5Ju+X23YD7u1OimZm1UucuFAHnAUsj4l8qTZcDM/P0TOCyoS/PzMzaqTMGfghwInCLpJvyc6cDZwKXSJoF3AO8tSsVmplZSx0DPCKuA9Sm+YihLcfMzOryb2KamRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVqgB/Z+YNrx69f/3mVkZ3AM3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFAOcDOzQjnAzcwK5QA3MyuUA9zMrFDF/Cq9f63czGxT7oGbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVigHuJlZoRzgZmaFcoCbmRXKAW5mVqjNCnBJR0m6TdIdkuYOVVFmZtbZoANc0gjgHOB1wH7A2yTtN1SFmZlZ/zanB34QcEdE3BURfwAuAqYPTVlmZtbJ5vw1wknA8sr8CuClzQtJmg3MzrPrJN22GfvstgnAA70uYpBce2+49t4oqnad9dTkYOveq9WTXf9zshExH5jf7f0MBUmLI2Jar+sYDNfeG669N0qtfajr3pwhlHuBPSrzk/NzZmY2DDYnwH8JTJU0RdIo4Hjg8qEpy8zMOhn0EEpEPCHp/cCVwAjgqxGxZMgq640ihnracO294dp7o9Tah7RuRcRQbs/MzIaJfxPTzKxQDnAzs0JtkwHe6U8ASDpM0q8kPSHpuF7U2E6N2udIulXSzZKultTy/tFeqFH7eyTdIukmSddtSb/ZW/fPRkg6VlJI2iJucatxzk+StDqf85skndyLOlupc84lvTW/35dI+uZw19hOjfP+uco5v13SmkHtKCK2qQfpC9c7gecAo4DfAPs1LdMHPB/4OnBcr2seYO2vBHbK038NXNzrugdQ+5jK9BuBH/S67rq15+VGAz8BrgemlVA3cBLwhV7XOsjapwK/Bsbl+Wf3uu6BvF8qy59CuglkwPvaFnvgHf8EQEQsi4ibgQ29KLAfdWq/JiIey7PXk+7P3xLUqf3RyuzOwJbyDXvdPxvxSeAs4PfDWVw/Sv5zF3VqfxdwTkQ8DBAR9w9zje0M9Ly/DfjWYHa0LQZ4qz8BMKlHtQzUQGufBVzR1Yrqq1W7pPdJuhM4G/jAMNXWScfaJb0I2CMiFg5nYR3Ufb8cm4fcLpW0R4v2XqhT+z7APpJ+Jul6SUcNW3X9q/1zmoc4pwA/HsyOtsUA3yZIegcwDfinXtcyEBFxTkQ8F/gQ8A+9rqcOSdsB/wJ8sNe1DML3gL6IeD5wFbCgx/UMxEjSMMrhpF7sv0sa28uCBuF44NKIeHIwK2+LAV7ynwCoVbukI4GPAG+MiP8bpto6Geh5vwiY0c2CBqBT7aOBA4BFkpYBBwOXbwFfZHY85xHxYOU9ci7w4mGqrZM675cVwOUR8ceIuBu4nRTovTaQ9/rxDHL4BNgmv8QcCdxF+tjS+IJh/zbLns+W9SVmx9qBA0lfoEztdb2DqH1qZfoNwOJe1z3Q90xefhFbxpeYdc75bpXpNwHX97ruAdR+FLAgT08gDVvsUkLtebl9gWXkX6gc1L56fbA9OsFHk67WdwIfyc+dQeqxAryEdHVfDzwILOl1zQOo/UfAfcBN+XF5r2seQO2fB5bkuq/pLyS3tNqblt0iArzmOf/HfM5/k8/5vr2ueQC1izR0dStwC3B8r2seyPsFmAecuTn78a/Sm5kValscAzcz2yo4wM3MCuUANzMrlAPczKxQDnAzs0I5wM3MCuUANzMr1P8DK8dfuIsxqz8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(corr_obj.data['test_cc_raw'])\n",
    "plt.title(f\"{iden}, {np.median(corr_obj.data['test_cc_raw'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '_test_lmbdas_wider_range')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmbdas = np.log10(corr_obj.data['opt_lmbdas'])\n",
    "plt.hist(lmbdas)\n",
    "plt.title(iden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4376591917199979"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(corr_obj.data[corr_obj.data['layer']==2]['test_cc_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '_test_lmbdas, 0.4014892749859427')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(corr_obj.data['test_cc_raw'])\n",
    "plt.title(f\"{iden}, {np.median(corr_obj.data['test_cc_raw'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '_test_lmbdas')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lmbdas = np.log10(corr_obj.data['opt_lmbdas'])\n",
    "plt.hist(lmbdas)\n",
    "plt.title(iden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "\n",
    "# \n",
    "model_name = 'deepspeech2'\n",
    "# model_name = 'speech2text'\n",
    "# model_name = 'wav2vec2'\n",
    "# model_name = 'whisper_tiny'\n",
    "# model_name = 'whisper_base'\n",
    "# model_name = 'wav2letter_modified'\n",
    "# \n",
    "id = '_reset_weights53'\n",
    "# id = '_reset_weights53_l0'\n",
    "# id = '_reset_weights53_l1'\n",
    "# id = '_reset_weights53_features'\n",
    "\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    normalizer_filename=normalizer_filename\n",
    "    )\n",
    "print(f\"'{model_name}'\")\n",
    "print(corr_obj.data['session'].unique().size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data['bin_width'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data['bin_width'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "# model_names = [\n",
    "#     'deepspeech2', 'speech2text', 'wav2vec2',\n",
    "#     'whisper_base', 'whisper_tiny', 'wav2letter_modified',\n",
    "#     ]\n",
    "# iden = '_test_all_trials'\n",
    "# for model_name in model_names:\n",
    "# \tcorr_obj = Correlations(\n",
    "# \t\tmodel_name=model_name+iden,\n",
    "# \t\tnormalizer_filename=normalizer_filename\n",
    "# \t\t)\n",
    "# \tprint(f\"Deleting file for {model_name}\")\n",
    "# \tfilepath = corr_obj.get_filepath()\n",
    "# \tos.remove(filepath)\n",
    "# \tprint(f\"Removed: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_done = corr_obj.data['session'].unique()\n",
    "\n",
    "sessions = np.array([180627., 180719., 180720., 180731., 180807., 180808., 180814.,\n",
    "                190606., 191113., 191115., 191121., 191125., 191206., 191210.,\n",
    "                200205., 200206., 200207., 200213., 200313.])\n",
    "sessions_done[np.isin(sessions_done, sessions)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data['session'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "    'test_all_trials',\n",
    "    'test_all_trials_l1',\n",
    "    'test_all_trials_l0',\n",
    "\n",
    "    ]\n",
    "# output_identifier = 'glm'\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename,\n",
    "                            #    output_identifier=output_identifier\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "    'test_all_trials',\n",
    "    'test_all_trials_l1',\n",
    "    'test_all_trials_l0',\n",
    "    ]\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/speech2text_test_all_trials_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/speech2text_test_all_trials_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2vec2_test_all_trials_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2vec2_test_all_trials_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_base_test_all_trials_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_base_test_all_trials_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_test_all_trials_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/whisper_tiny_test_all_trials_corr_results.csv\n",
      "Writing back...!\n",
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2letter_modified_test_all_trials_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/wav2letter_modified_test_all_trials_corr_results.csv\n",
      "Writing back...!\n"
     ]
    }
   ],
   "source": [
    "# model_name = 'deepspeech2'\n",
    "# model_name = 'speech2text'\n",
    "# model_name = 'wav2vec2'\n",
    "# model_name = 'whisper_base'\n",
    "# model_name = 'whisper_tiny'\n",
    "# model_name = 'wav2letter_modified'\n",
    "model_names = [\n",
    "    # 'deepspeech2',\n",
    "\t'speech2text', 'wav2vec2',\n",
    "    'whisper_base', 'whisper_tiny', 'wav2letter_modified',\n",
    "    ]\n",
    "for model_name in model_names:\n",
    "    output_id = 0\n",
    "    normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "    ids = [\n",
    "\t\t'test_all_trials',\n",
    "\t\t'test_all_trials_10',\n",
    "\t\t'test_all_trials_40',\n",
    "\t\t'test_all_trials_60', \n",
    "\t\t'test_all_trials_80',\n",
    "\t\t'test_all_trials_100',\n",
    "\t\t'test_all_trials_200',\n",
    "\t\t'test_all_trials_300',\n",
    "\t\t'test_all_trials_400',\n",
    "\t\t'test_all_trials_500',\n",
    "\t\t'test_all_trials_600',\n",
    "\t\t'test_all_trials_700',\n",
    "\t\t'test_all_trials_800',\n",
    "        ]\n",
    "    # output_identifier = 'reset_weights_all_trials2'\n",
    "    Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename,\n",
    "                                # output_identifier=output_identifier\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model_name = 'whisper_base'\n",
    "# model_name = 'whisper_tiny'\n",
    "model_name = 'wav2letter_modified'\n",
    "# model_name = 'wav2vec2'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "    'test_all_trials',\n",
    "    # 'test_all_trials_features',\n",
    "    ]\n",
    "# output_identifier = 'test_all_trials_old'\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename,\n",
    "\t\t\t\t\t\t\t# output_identifier=output_identifier\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.remove(corr_obj.get_filepath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved at: \n",
      " /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/w2v2_audioset_test_lmbdas_delays_corr_results.csv\n",
      "reading from /depot/jgmakin/data/auditory_cortex/results/cross_validated_correlations/w2v2_audioset_test_lmbdas_delays_corr_results.csv\n",
      "Writing back...!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# model_name = 'whisper_base'\n",
    "# model_name = 'whisper_tiny'\n",
    "# model_name = 'wav2letter_modified'\n",
    "# model_name = 'wav2vec2'\n",
    "model_name = 'w2v2_audioset'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "    'test_lmbdas_delays',\n",
    "    'test_lmbdas_delays_features',\n",
    "    ]\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### significant sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "model_name = 'wav2vec2'\n",
    "id = '_bins_corrected_100'\n",
    "\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    normalizer_filename=normalizer_filename\n",
    "    )\n",
    "\n",
    "bin_width = 20\n",
    "threshold = corr_obj.get_normalizer_threshold(bin_width=bin_width)\n",
    "corr_obj.get_significant_sessions(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.array([180627., 180719., 180720., 180731., 180807., 180808., 180814.,\n",
    "                    190606., 191113., 191115., 191121., 191125., 191206., 191210.,\n",
    "                    200205., 200206., 200207., 200213., 200313.]).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of sig. channels as function of bin_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "model_name = 'wav2vec2'\n",
    "id = '_bins_corrected_100'\n",
    "\n",
    "corr_obj = Correlations(\n",
    "    model_name=model_name+id,\n",
    "    normalizer_filename=normalizer_filename\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_sessions = corr_obj.get_significant_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_sessions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex.neural_data import NeuralMetaData\n",
    "metadata = NeuralMetaData()\n",
    "sessions_available = metadata.get_all_available_sessions()\n",
    "sessions_available = sessions_available.astype(np.float32)\n",
    "sessions_available.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_sessions[np.isin(sig_sessions, sessions_available, invert=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_sessions.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_available.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex import bad_sessions\n",
    "\n",
    "sig_sessions[np.isin(sig_sessions, bad_sessions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area = 'core'\n",
    "area = 'belt'\n",
    "bin_width = 20\n",
    "# threshold = 0.061\n",
    "poisson_dist = True\n",
    "\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    threshold = corr_obj.get_normalizer_threshold(bin_width=bin_width, poisson_normalizer=poisson_dist)\n",
    "    print(f\"At bin_width: {bin_width}, threshold={threshold:.2f}\")\n",
    "    area_sessions = corr_obj.metadata.get_all_sessions(area)\n",
    "\n",
    "    total_channels = 0\n",
    "    select_data = corr_obj.get_selected_data(\n",
    "            sessions=area_sessions,\n",
    "            bin_width=bin_width, \n",
    "            layer=7,\n",
    "            delay=0,\n",
    "            threshold=threshold,\n",
    "            N_sents=499\n",
    "        )\n",
    "\n",
    "    print(select_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete right away..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All networks Best layerss.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex.plotters.correlation_plotter import RegPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegPlotter.bar_plot_best_layer_all_networks(area='core',\n",
    "                    identifier='_sampling_rate_opt_neural_delay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegPlotter.bar_plot_best_layer_all_networks(area='core',\n",
    "                    identifier='_sampling_rate_opt_neural_delay', threshold=0.061)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegPlotter.bar_plot_best_layer_all_networks(area='belt', \n",
    "                threshold=0.061,\n",
    "                identifier='_sampling_rate_opt_neural_delay',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegPlotter.bar_plot_best_layer_all_networks(area='belt', \n",
    "                threshold=0.061,\n",
    "                identifier='_sampling_rate_opt_neural_delay',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex import model_names\n",
    "identifier = '_sampling_rate_opt_neural_delay'\n",
    "area = 'core'\n",
    "bin_width = 20\n",
    "delay = 0\n",
    "threshold = 0.061\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dist_peak_layer_each_model = {}\n",
    "for model_name in model_names: \n",
    "\n",
    "    corr_obj = Correlations(model_name+identifier)\n",
    "    # print(f\"Object created for {model_name}, with id {identifier}\")\n",
    "    corr_dict = corr_obj.get_corr_all_layers_for_bin_width(\n",
    "        neural_area=area, bin_width=bin_width,\n",
    "        delay=0, threshold=threshold,\n",
    "        normalized=True\n",
    "    )\n",
    "    layer_medians = {np.median(v):k for k,v in corr_dict.items()}\n",
    "    peak_median = max(layer_medians)\n",
    "    peak_layer = layer_medians[peak_median]\n",
    "    dist_peak_layer_each_model[model_name] = corr_dict[peak_layer]\n",
    "\n",
    "# baseline is same for all networks..\n",
    "corr_baseline = corr_obj.get_baseline_corr_for_area(neural_area=area,\n",
    "                                                    threshold=threshold)\n",
    "dist_peak_layer_each_model['baseline'] = corr_baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_peak_layer_each_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "p_values = {}\n",
    "statistic = {}\n",
    "for model_name in model_names:\n",
    "    out = scipy.stats.wilcoxon(\n",
    "        x = dist_peak_layer_each_model[model_name], \n",
    "        y=dist_peak_layer_each_model['baseline']\n",
    "    )\n",
    "    p_values[model_name] = out.pvalue\n",
    "    statistic[model_name] = out.statistic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_peak_layer_each_model[model_names[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_peak_layer_each_model['baseline'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_peak_layer_each_model[model_names[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All network layers at bin_width=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "area = 'core'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "area = 'belt'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "area = 'core'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "area = 'belt'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "area = 'core'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "area = 'belt'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "area = 'core'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "area = 'belt'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "area = 'core'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "area = 'belt'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "area = 'core'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "area = 'belt'\n",
    "bin_width = 20\n",
    "threshold = 0.061\n",
    "RegPlotter.plot_all_network_layers_at_bin_width(\n",
    "    model_name=model_name, area = area, bin_width=bin_width,\n",
    "    threshold=threshold, identifier='_sampling_rate_opt_neural_delay'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network layer at all bin_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "identifier = '_opt_neural_delay'\n",
    "corr_obj = Correlations(model_name+identifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with different normalizer and DIFFERENT threshold as well..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### deepspeech2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer = 3\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer = 3\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### speech2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "layer = 3\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "layer = 3\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wav2vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "identifier = '_sampling_rate_opt_neural_delay'\n",
    "res = model_name + identifier\n",
    "corr_obj = Correlations(res)\n",
    "corr_obj.set_normalizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "layer = 7\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "layer = 7\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wav2letter_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "layer = 6\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "layer = 6\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whisper_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "identifier = '_sampling_rate_opt_neural_delay'\n",
    "res = model_name + identifier\n",
    "corr_obj = Correlations(res)\n",
    "corr_obj.set_normalizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "layer = 4\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "layer = 4\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### whisper_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "identifier = '_sampling_rate_opt_neural_delay'\n",
    "res = model_name + identifier\n",
    "corr_obj = Correlations(res)\n",
    "corr_obj.set_normalizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "layer = 4\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "layer = 4\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with different normalizer at each bin_width.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### deepspeech2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "identifier = '_sampling_rate_opt_neural_delay'\n",
    "res = model_name + identifier\n",
    "corr_obj = Correlations(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.set_normalizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer = 3\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer = 3\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### speech2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "identifier = '_sampling_rate_opt_neural_delay'\n",
    "res = model_name + identifier\n",
    "corr_obj = Correlations(res)\n",
    "corr_obj.set_normalizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "layer = 3\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "layer = 3\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wav2vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "identifier = '_sampling_rate_opt_neural_delay'\n",
    "res = model_name + identifier\n",
    "corr_obj = Correlations(res)\n",
    "corr_obj.set_normalizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "layer = 7\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "layer = 7\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with same normalizer at all bin_widths..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_baseline = corr_obj.get_baseline_corr_for_area(neural_area='core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "layer = 6\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "layer = 6\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "layer = 3\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "layer = 3\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer = 3\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "layer = 3\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "layer = 7\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "layer = 7\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "layer = 4\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "layer = 4\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "layer = 4\n",
    "area = 'core'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "layer = 4\n",
    "area = 'belt'\n",
    "RegPlotter.plot_one_network_layer_at_all_bin_width(\n",
    "    model_name=model_name, area=area, layer=layer, normalized=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shaded Line plots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from auditory_cortex.analyses import Correlations\n",
    "from palettable.colorbrewer import qualitative\n",
    "from auditory_cortex.neural_data import NeuralMetaData\n",
    "from auditory_cortex.plotters.plotter_utils import PlotterUtils\n",
    "from auditory_cortex import results_dir\n",
    "colors = qualitative.Dark2_8.mpl_colors\n",
    "from utils_jgm.tikz_pgf_helpers import tpl_save\n",
    "\n",
    "def plot_shaded_line(data_dict, color, alpha=0.2, low_percentile=25, \n",
    "    high_percentile=75, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    medians = []\n",
    "    x_coordinates = []\n",
    "    lower_percentiles = []\n",
    "    higher_percentiles = []\n",
    "    for layer_ID, layer_data in data_dict.items():\n",
    "        medians.append(np.median(layer_data))\n",
    "        x_coordinates.append(layer_ID)\n",
    "        lower_percentiles.append(np.percentile(layer_data, low_percentile))\n",
    "        higher_percentiles.append(np.percentile(layer_data, high_percentile))\n",
    "    \n",
    "    ax.plot(x_coordinates, medians, color=color)\n",
    "    ax.fill_between(x=x_coordinates, y1=lower_percentiles, y2=higher_percentiles,\n",
    "    alpha=alpha, color=color)\n",
    "    \n",
    "\n",
    "def save_tikz(file_name):\n",
    "    file_name = file_name+'.tex'\n",
    "    tikz_dir = os.path.join(results_dir, 'tikz_plots')\n",
    "    if not os.path.exists(tikz_dir):\n",
    "        os.makedirs(tikz_dir)\n",
    "    extra_axis_parameters = {\n",
    "        'width=\\\\figwidth',\n",
    "        'height=\\\\figheight',\n",
    "        'every x tick label/.append style={rotate=90}',\n",
    "        'xticklabel style={opacity=\\\\thisXticklabelopacity, align=center}',\n",
    "    }\n",
    "    tpl_save(\n",
    "        filepath=os.path.join(tikz_dir, file_name),\n",
    "        extra_axis_parameters=extra_axis_parameters,\n",
    "        tex_relative_path_to_data='pngs',\n",
    "        extra_lines_start={\n",
    "            '\\\\providecommand{\\\\figwidth}{5.7in}%',\n",
    "            '\\\\providecommand{\\\\figheight}{2.0in}%',\n",
    "            '\\\\providecommand{\\\\thisXticklabelopacity}{1.0}%',\n",
    "        },\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex.analyses import Correlations\n",
    "model_name = 'wav2letter_modified'\n",
    "# res = 'wav2vec2'\n",
    "\n",
    "# res = 'whisper_tiny'\n",
    "# res = 'whisper_test'\n",
    "# res = 'whisper_small'\n",
    "# res = 'whisper_base'\n",
    "id = '_opt_neural_delay'\n",
    "result = model_name + id\n",
    "corr_obj = Correlations(result)\n",
    "len(corr_obj.get_all_sessions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['wav2letter_modified', 'wav2vec2',\n",
    "'deepspeech2', 'speech2text', 'whisper_tiny', \n",
    "'whisper_base']\n",
    "id = '_opt_neural_delay'\n",
    "layer_wise_data = {}\n",
    "mdata = NeuralMetaData()\n",
    "area = 'core'\n",
    "sessions = mdata.get_all_sessions(area=area)\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "    result = model_name + id\n",
    "    corr_obj = Correlations(result)\n",
    "    bin_width = 20\n",
    "    delay = 0\n",
    "    N_sents = 499\n",
    "    threshold = 0.068\n",
    "    normalized=True\n",
    "    ax, layer_spread = corr_obj.box_plot_correlations(\n",
    "        sessions=sessions,\n",
    "        bin_width=bin_width, delay=delay, threshold=threshold,\n",
    "        N_sents=N_sents, normalized=normalized\n",
    "        )\n",
    "    layer_wise_data[model_name] = layer_spread\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_layers_for_bin_width(self, bin_width=20, delay=0, \n",
    "        N_sents=499):\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_with_shaded_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, (model_name, layer_spread) in enumerate(layer_wise_data.items()):\n",
    "    alpha = 0.2\n",
    "    color = colors[ind]\n",
    "    plot_shaded_line(layer_spread, color=color, alpha=alpha)\n",
    "    plt.title(f\"{model_name}, bw-{bin_width}ms, area-{area}\")\n",
    "    plt.xlabel(f\"Layer IDs\")\n",
    "    plt.ylabel(f\"$\\\\rho$\")\n",
    "    plt.ylim([0,1])\n",
    "    # save_tikz(f\"correlation-layerwise-{area}-{model_name}\")\n",
    "\n",
    "    filepath = os.path.join(results_dir, 'tikz_plots', f\"correlation-layerwise-{area}-{model_name}.tex\")\n",
    "    PlotterUtils.save_tikz(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Belt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['wav2letter_modified', 'wav2vec2',\n",
    "'deepspeech2', 'speech2text', 'whisper_tiny', \n",
    "'whisper_base']\n",
    "id = '_opt_neural_delay'\n",
    "layer_wise_data = {}\n",
    "mdata = NeuralMetaData()\n",
    "area = 'belt'\n",
    "sessions = mdata.get_all_sessions(area=area)\n",
    "\n",
    "for model_name in model_names:\n",
    "\n",
    "    result = model_name + id\n",
    "    corr_obj = Correlations(result)\n",
    "    bin_width = 20\n",
    "    delay = 0\n",
    "    N_sents = 499\n",
    "    threshold = 0.068\n",
    "    normalized=True\n",
    "    ax, layer_spread = corr_obj.box_plot_correlations(\n",
    "        sessions=sessions,\n",
    "        bin_width=bin_width, delay=delay, threshold=threshold,\n",
    "        N_sents=N_sents, normalized=normalized\n",
    "        )\n",
    "    layer_wise_data[model_name] = layer_spread\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, (model_name, layer_spread) in enumerate(layer_wise_data.items()):\n",
    "    alpha = 0.2\n",
    "    color = colors[ind]\n",
    "    plot_shaded_line(layer_spread, color=color, alpha=alpha)\n",
    "    plt.title(f\"{model_name}, bw-{bin_width}ms, area-{area}\")\n",
    "    plt.xlabel(f\"Layer IDs\")\n",
    "    plt.ylabel(f\"$\\\\rho$\")\n",
    "    plt.ylim([0,1])\n",
    "    # save_tikz(f\"correlation-layerwise-{area}-{model_name}\")\n",
    "\n",
    "    filepath = os.path.join(results_dir, 'tikz_plots', f\"correlation-layerwise-{area}-{model_name}.tex\")\n",
    "    PlotterUtils.save_tikz(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(layer_spread[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(layer_spread[0], 95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine results and ready to use...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex.plotters.plotter_utils import PlotterUtils\n",
    "\n",
    "i = 0\n",
    "res = PlotterUtils.model_names[i]\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "id = '_randn_weights'\n",
    "# id = '_weights_shuffled_l0'\n",
    "# id = '_weights_shuffled_l1'\n",
    "res += id\n",
    "corr_obj = Correlations(res,\n",
    "                        # normalizer_filename='modified_bins_normalizer.csv'\n",
    "                        )\n",
    "\n",
    "filepath = corr_obj.get_filepath()\n",
    "os.remove(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_ready(\n",
    "        model_name, identifiers_list, output_id, normalizer_filename=None\n",
    "    ):\n",
    "    \"\"\"Merges results for all identifiers, copies layer types and\n",
    "    sets normalizer.\"\"\"\n",
    "\n",
    "    Correlations.merge_correlation_results(\n",
    "            model_name=model_name,\n",
    "            file_identifiers=identifiers_list,\n",
    "            idx=output_id\n",
    "        )\n",
    "\n",
    "    identifier = identifiers_list[output_id]\n",
    "    Correlations.add_layer_types(\n",
    "        model_name, identifier\n",
    "    )\n",
    "\n",
    "    res = model_name + '_' + identifiers_list[output_id]\n",
    "    corr_obj = Correlations(res, normalizer_filename=normalizer_filename)\n",
    "\n",
    "    corr_obj.set_normalizers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whisper_small ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'whisper_small'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "id = '_random_weights'\n",
    "id = '_random_weights'\n",
    "# id = '_sampling_rate_opt_neural_delay_feature_extractor'\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.set_normalizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wav2letter_modified..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'wav2letter_modified'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_random_weights'\n",
    "id = '_weights_shuffled'\n",
    "# id = '_sampling_rate_opt_neural_delay_feature_extractor'\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'wav2letter_modified'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_bins_corrected_10'\n",
    "id = '_bins_corrected_100'\n",
    "# id = '_bins_corrected_300'\n",
    "# id = '_bins_corrected_500'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2letter_modified'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "    'bins_corrected_poiss',\n",
    "    ]\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'wav2letter_modified'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "id = '_sampling_100'\n",
    "# id = '_sampling_rate_opt_neural_delay_feature_extractor'\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wav2vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'wav2vec2'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_100'\n",
    "# id = '_random_weights'\n",
    "id = '_weights_shuffled'\n",
    "# id = '_weights_shuffled_features'\n",
    "# id = '_random_weights_features'\n",
    "# id = '_sampling_rate_opt_neural_delay_feature_extractor'\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "        # 'bins_corrected_100',\n",
    "ids = [\n",
    "        'bins_corrected_poiss',\n",
    "        'bins_corrected_poiss_features'\n",
    "    ]\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'wav2letter_modified'\n",
    "res = 'wav2vec2'\n",
    "# res = 'speech2text'\n",
    "# res = 'deepspeech2'\n",
    "\n",
    "# res = 'whisper_tiny'\n",
    "# res = 'whisper_test'\n",
    "# res = 'whisper_small'\n",
    "# res = 'whisper_base'\n",
    "print(f\"For {res} sessions done: \")\n",
    "id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_sampling_rate_opt_neural_delay_feature_extractor'\n",
    "# id = '_verification_20'\n",
    "# id = '_verification_20_feature_extractor'\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'wav2vec2'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_bins_corrected_features_80'\n",
    "# id = '_bins_corrected_features_60'\n",
    "# id = '_bins_corrected_features_40'\n",
    "# id = '_bins_corrected_features_20'\n",
    "# id = '_bins_corrected_features_10'\n",
    "# id = '_bins_corrected_features_100'\n",
    "# id = '_bins_corrected_features_300'\n",
    "# id = '_bins_corrected_features_500'\n",
    "id = '_bins_corrected_features_700'\n",
    "# id = '_bins_corrected_10'\n",
    "\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "res += id\n",
    "corr_obj = Correlations(res, normalizer_filename=normalizer_filename)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.norm_obj.dataframe['bin_width'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speech2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = 'speech2text'\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_weights_shuffled'\n",
    "# id = '_weights_shuffled_l0'\n",
    "# id = '_bins_corrected_poiss'\n",
    "# id = '_bins_corrected_poiss_0'\n",
    "id = '_bins_corrected_poiss_1'\n",
    "\n",
    "# id = '_random_weights_l1'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "    'bins_corrected_poiss',\n",
    "    'bins_corrected_poiss_0',\n",
    "    'bins_corrected_poiss_1'\n",
    "    ]\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'wav2letter_modified'\n",
    "res = 'speech2text'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "id = '_time_averaged_no_grid'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'speech2text'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_bins_corrected_100'\n",
    "id = '_bins_corrected_l1_80'\n",
    "id = '_bins_corrected_l1_60'\n",
    "id = '_bins_corrected_l1_40'\n",
    "id = '_bins_corrected_l1_20'\n",
    "id = '_bins_corrected_l1_10'\n",
    "id = '_bins_corrected_l1_100'\n",
    "id = '_bins_corrected_l1_300'\n",
    "id = '_bins_corrected_l1_500'\n",
    "id = '_bins_corrected_l1_700'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.get_filepath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'wav2letter_modified'\n",
    "# res = 'wav2vec2'\n",
    "# res = 'speech2text'\n",
    "res = 'deepspeech2'\n",
    "\n",
    "# res = 'whisper_tiny'\n",
    "# res = 'whisper_test'\n",
    "# res = 'whisper_small'\n",
    "# res = 'whisper_base'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "id = '_sampling_100'\n",
    "# id = '_sampling_rate_opt_neural_delay_feature_extractor'\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### deepspeech2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'deepspeech2'\n",
    "# id = '_random_weights'\n",
    "\n",
    "# id = '_weights_shuffled'\n",
    "# id = '_weights_shuffled_l0'\n",
    "id = '_weights_shuffled_l1'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {data['layer'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'deepspeech2'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "    'bins_corrected_poiss',\n",
    "    'bins_corrected_poiss_0',\n",
    "    'bins_corrected_poiss_1'\n",
    "    ]\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'wav2letter_modified'\n",
    "res = 'deepspeech2'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "id = '_time_averaged_no_grid'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'deepspeech2'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_bins_corrected_100'\n",
    "id = '_bins_corrected_l0_80'\n",
    "id = '_bins_corrected_l0_60'\n",
    "id = '_bins_corrected_l0_40'\n",
    "id = '_bins_corrected_l0_20'\n",
    "id = '_bins_corrected_l0_10'\n",
    "# id = '_bins_corrected_l0_100'\n",
    "# id = '_bins_corrected_l0_300'\n",
    "# id = '_bins_corrected_l0_500'\n",
    "# id = '_bins_corrected_l0_700'\n",
    "\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whisper_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'whisper_tiny'\n",
    "# res = 'whisper_test'\n",
    "# res = 'whisper_small'\n",
    "# res = 'whisper_base'\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_random_weights'\n",
    "id = '_weights_shuffled'\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {data['layer'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_tiny'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "        'bins_corrected_poiss',\n",
    "    ]\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'wav2letter_modified'\n",
    "res = 'whisper_tiny'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "id = '_time_averaged_no_grid'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'whisper_tiny'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "id = '_bins_corrected_100'\n",
    "# id = '_bins_corrected_10'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {data['layer'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whisper_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = 'whisper_base'\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "# id = '_random_weights'\n",
    "id = '_weights_shuffled'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# # bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper_base'\n",
    "output_id = 0\n",
    "normalizer_filename = 'modified_bins_normalizer.csv'\n",
    "ids = [\n",
    "        'bins_corrected_poiss',\n",
    "    ]\n",
    "\n",
    "Correlations.combine_and_ready(model_name, ids, output_id, normalizer_filename=normalizer_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'wav2letter_modified'\n",
    "res = 'whisper_base'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "id = '_time_averaged_no_grid'\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['layer'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'whisper_base'\n",
    "\n",
    "print(f\"For {res} sessions done: \")\n",
    "# id = '_sampling_rate_opt_neural_delay'\n",
    "id = '_bins_corrected_100'\n",
    "\n",
    "\n",
    "\n",
    "res += id\n",
    "corr_obj = Correlations(res)\n",
    "\n",
    "# bin_widths = [5, 10, 20, 40, 60, 80, 100, 200, 400, 800]\n",
    "bin_widths = np.sort(corr_obj.data['bin_width'].unique())\n",
    "for bin_width in bin_widths:\n",
    "    data = corr_obj.get_selected_data(bin_width=bin_width)\n",
    "    print(f\"For bin_width: {bin_width:03} ms= {len(data['session'].unique())}\")\n",
    "    # print(f\"For bin_width: {bin_width:03} ms= {data['layer'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.get_normalizer_threshold(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Earlier made plots.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data[corr_obj.data['bin_width']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data[corr_obj.data['bin_width']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data[corr_obj.data['bin_width']==20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.get_selected_data()['layer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_file = res\n",
    "filename = f'{corr_file}_corr_results.csv'\n",
    "corr_file_path = os.path.join(saved_corr_dir, filename)\n",
    "data1 = pd.read_csv(corr_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'whisper_tiny'\n",
    "# model_name = 'whisper_test'\n",
    "# model_name = 'whisper_base'\n",
    "model_name = 'wav2letter_modified'\n",
    "id = 'sampling_rate_opt_neural_delay'\n",
    "\n",
    "# id = 'opt_neural_delay'\n",
    "filler = ''\n",
    "if id != '':\n",
    "    filler = '_'\n",
    "model_identifier = model_name + filler + id\n",
    "# add layer types...\n",
    "print(\"adding layer types...\")\n",
    "CorrelationUtils.add_layer_types(model_name, id)\n",
    "print(\"Copying normalizer...\")\n",
    "CorrelationUtils.copy_normalizer(model_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'whisper_tiny'\n",
    "# res = 'whisper_test'\n",
    "# res = 'wav2vec2'\n",
    "id = '_opt_neural_delay'\n",
    "res += id\n",
    "corr_obj = analysis.Correlations(res)\n",
    "out = corr_obj.box_plot_correlations(\n",
    "    threshold=0.068,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'whisper_base'\n",
    "# res = 'whisper_test'\n",
    "# res = 'wav2vec2'\n",
    "id = '_opt_neural_delay'\n",
    "res += id\n",
    "corr_obj = analysis.Correlations(res)\n",
    "out = corr_obj.box_plot_correlations(\n",
    "    threshold=0.068,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'whisper_tiny'\n",
    "res = 'wav2vec2'\n",
    "id = '_opt_neural_delay'\n",
    "res += id\n",
    "corr_obj = analysis.Correlations(res)\n",
    "out = corr_obj.box_plot_correlations(\n",
    "    threshold=0.068,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'whisper_tiny'\n",
    "res = 'wav2letter_modified'\n",
    "id = '_opt_neural_delay'\n",
    "res += id\n",
    "corr_obj = analysis.Correlations(res)\n",
    "out = corr_obj.box_plot_correlations(\n",
    "    threshold=0.068,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 'whisper_tiny'\n",
    "res = 'speech2text'\n",
    "id = '_opt_neural_delay'\n",
    "res += id\n",
    "corr_obj = analysis.Correlations(res)\n",
    "out = corr_obj.box_plot_correlations(\n",
    "    threshold=0.068,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 'deepspeech2'\n",
    "id = '_opt_neural_delay'\n",
    "res += id\n",
    "corr_obj = analysis.Correlations(res)\n",
    "out = corr_obj.box_plot_correlations(\n",
    "    threshold=0.068,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, dist in out[1].items():\n",
    "    print(f\"Layer-{layer}, median: {np.median(dist):.2f}, max: {np.max(dist):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### adding layer types and normalizer...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.add_layer_types('mix')\n",
    "CorrelationUtils.copy_normalizer(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ensemble'\n",
    "id = '_opt_neural_delay'\n",
    "model_name += id\n",
    "session = 200206\n",
    "threshold = 0.068\n",
    "delay = 48\n",
    "corr_obj = analysis.Correlations(model_name)\n",
    "ax = corr_obj.box_plot_correlations(threshold=threshold,\n",
    "                                    delay=delay,\n",
    "                                    # normalized=True,\n",
    "                                    # sessions=[session]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_layers = ax[1]\n",
    "for k, v in data_layers.items():\n",
    "    print(f\"L-{k}, median: {np.median(v):.2f}, max: {np.max(v):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = 20\n",
    "model = models_list[0]\n",
    "model_name = model['model_name'] + '_opt_neural_delay'\n",
    "corr_obj = analysis.Correlations(model_name)\n",
    "select_data = corr_obj.get_session_data(\n",
    "            threshold=threshold, bin_width=bin_width\n",
    "        )\n",
    "\n",
    "# ax = corr_obj.box_plot_correlations(threshold=threshold,\n",
    "#                                     delay=delay,\n",
    "#                                     # normalized=True,\n",
    "#                                     # sessions=[session]\n",
    "#                                     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the ensemble model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### function definations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    {\n",
    "        'model_name': 'wav2letter_modified',\n",
    "        'layer': 6,\n",
    "        'opt_neural_delay': 37.75,\n",
    "        'layer_type': 'conv'\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'speech2text',\n",
    "        'layer': 4,\n",
    "        'opt_neural_delay': 49.83,\n",
    "        'layer_type': 'transformer'\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'wav2vec2',\n",
    "        'layer': 7,\n",
    "        'opt_neural_delay': 49.23,\n",
    "        'layer_type': 'transformer'\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'deepspeech2',\n",
    "        'layer': 2,\n",
    "        'opt_neural_delay': 54.73,\n",
    "        'layer_type': 'rnn'\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'ensemble',\n",
    "        'layer': 0,\n",
    "        'opt_neural_delay': 54.73,\n",
    "        'layer_type': 'mix'\n",
    "    },\n",
    "]\n",
    "def plot_box_and_whiskers(data_spread, colors, ax=None, lw=1.5):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_spread (dict): dict of distributions... \n",
    "        colors (list): list of colors, len(colors)=len(data_spread) \n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "        # plotting function\n",
    "    median_lines = dict(color='k', linewidth=lw*2)  \n",
    "    other_lines = dict(color='k', linewidth=lw)\n",
    "    bplot = ax.boxplot(data_spread.values(), positions = np.arange(1, len(data_spread.keys())+1),\n",
    "                labels=data_spread.keys(),\n",
    "                whis=[5,95],\n",
    "                capprops=other_lines,\n",
    "                whiskerprops=other_lines,\n",
    "                medianprops=median_lines,\n",
    "                patch_artist=True\n",
    "                )\n",
    "    \n",
    "    # setting the colors of the boxes as per layer type..\n",
    "    for color, box, flier in zip(colors, bplot['boxes'], bplot['fliers']):\n",
    "        box.set(\n",
    "            facecolor = color,\n",
    "            linewidth=lw\n",
    "        )\n",
    "        flier.set(\n",
    "                markeredgecolor='k',\n",
    "                markerfacecolor=color,\n",
    "        )\n",
    "    return ax\n",
    "\n",
    "\n",
    "def compare_ensemble(models_list, threshold=0.068, bin_width=20, \n",
    "                     normalized=False, verbose=True):\n",
    "    delay = 0\n",
    "    column = 'test_cc_raw'\n",
    "    aug_title = ''\n",
    "    if normalized:\n",
    "        column = 'normalized_test_cc'\n",
    "        aug_title = ', norm'\n",
    "\n",
    "    data_spread = {}\n",
    "    colors = []\n",
    "    for model in models_list:\n",
    "        # model = models_list[0]\n",
    "        model_name = model['model_name']\n",
    "        if 'ensemble' in model_name:\n",
    "            delay = 48\n",
    "        layer_type = model['layer_type']\n",
    "        layer = model['layer']\n",
    "        corr_obj = analysis.Correlations(model_name+'_opt_neural_delay')\n",
    "        select_data = corr_obj.get_selected_data(\n",
    "                    threshold=threshold, bin_width=bin_width, delay=delay, N_sents=499,\n",
    "                    layer=layer\n",
    "                )\n",
    "        ids = select_data[select_data['layer']==layer].index\n",
    "        data_spread[model_name] = np.array(select_data.loc[ids, column]).squeeze()\n",
    "        colors.append(corr_obj.fill_color[layer_type])\n",
    "        if verbose:\n",
    "            print(f\"{model_name:20}: Med = {np.median(data_spread[model_name]):.2f},\\\n",
    "            max: {np.max(data_spread[model_name]):.2f}\")\n",
    "    # plotting box and whiskers\n",
    "    ax = plot_box_and_whiskers(data_spread, colors)\n",
    "    ax.set_title(f\"Ensemble vs individual models{aug_title}\")\n",
    "    ax.set_xlabel('models')\n",
    "    ax.grid(color='grey', axis='y', linestyle='-', linewidth = 0.5, alpha=0.5)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= compare_ensemble(models_list=models_list,\n",
    "                normalized=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = compare_ensemble(models_list=models_list,\n",
    "                normalized=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge corr results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "output_id = 1\n",
    "\n",
    "ids = [\n",
    "        'all_opt_delays_feature_extractor',\n",
    "        'all_opt_delays',\n",
    "    ]\n",
    "# ids = [\n",
    "#         'opt_neural_delay_1_third_feature_extractor',\n",
    "#         'opt_neural_delay_1_third',\n",
    "\n",
    "#     ]\n",
    "CorrelationUtils.merge_correlation_results(\n",
    "        model_name=model_name,\n",
    "        file_identifiers=ids,\n",
    "        idx=output_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add layer types and copy normalizer.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'wav2letter_modified'\n",
    "# model_name = 'speech2text'\n",
    "# model_name = 'deepspeech2'\n",
    "\n",
    "\n",
    "# model_name = 'ensemble'\n",
    "# model_name = 'whisper_tiny'\n",
    "model_name = 'whisper_base'\n",
    "# model_name = 'wav2vec2'\n",
    "\n",
    "\n",
    "ids = [\n",
    "    # 'robust1'\n",
    "    # 'normal_109'\n",
    "    # 'robust_26'\n",
    "    # 'opt_neural_delay'\n",
    "    'sampling_rate_opt_neural_delay'\n",
    "    # 'opt_neural_delay_1_third',\n",
    "    # 'opt_neural_delay_2_third',\n",
    "    # 'opt_neural_delay_3_third'\n",
    "]\n",
    "\n",
    "# id = 'opt_neural_delay_2_third'\n",
    "\n",
    "for id in ids:\n",
    "    filler = ''\n",
    "    if id != '':\n",
    "        filler = '_'\n",
    "    model_identifier = model_name + filler + id\n",
    "\n",
    "    # add layer types...\n",
    "    print(\"adding layer types...\")\n",
    "    CorrelationUtils.add_layer_types(model_name, id)\n",
    "\n",
    "    print(\"Copying normalizer...\")\n",
    "    CorrelationUtils.copy_normalizer(model_identifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'speech2text'\n",
    "model_name = 'deepspeech2'\n",
    "\n",
    "\n",
    "id = '_sampling_rate_opt_neural_delay'\n",
    "corr_file = model_name + id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'{corr_file}_corr_results.csv'\n",
    "corr_file_path = os.path.join(saved_corr_dir, filename)\n",
    "data1 = pd.read_csv(corr_file_path)\n",
    "print(f\"Reading file from: \\n {corr_file_path}\")\n",
    "# data1['session'].unique()\n",
    "\n",
    "ids = data1[data1['session']==0].index\n",
    "data1.drop(ids, inplace=True)\n",
    "print(f\"Writing back..\")\n",
    "data1.to_csv(corr_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = sessions[0]\n",
    "select_data = data1[data1['session']==session]\n",
    "channels = select_data['channel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = channels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ids = select_data[select_data['channel'] == ch].index\n",
    "\n",
    "# norm = data2[(data2['session']==session) &(data2['channel']==ch)]['normalizer'].head(1).item() \n",
    "\n",
    "# data1.loc[ids, 'normalizer'] = norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[(data2['session']==session) &(data2['channel']==ch)]['normalizer'].head(1).item() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for session in sessions:\n",
    "\n",
    "\n",
    "data1.to_csv(corr_file_path, index=False)\n",
    "print(f\"Normalizer updated and written back to file: \\n {corr_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyzing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'ensemble'\n",
    "# model_name = 'wav2letter_modified'\n",
    "# model_name = 'speech2text'\n",
    "# model_name = 'wav2vec2'\n",
    "model_name = 'deepspeech2'\n",
    "# id = 'opt_neural_delay_1_third'\n",
    "id = 'opt_neural_delay'\n",
    "# id = 'robust1'\n",
    "# id = 'normal_109'\n",
    "# id = ''\n",
    "filler = ''\n",
    "if id != '':\n",
    "    filler = '_'\n",
    "session = 200206\n",
    "model_identifier = model_name + filler + id\n",
    "corr_obj = analysis.Correlations(model_identifier)\n",
    "ax = corr_obj.box_plot_correlations(threshold=0.068,\n",
    "                                    # normalized=True\n",
    "                                    # sessions=[session]\n",
    "                                    )\n",
    "# len(corr_obj.get_all_sessions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_layers = ax[1]\n",
    "for k, v in data_layers.items():\n",
    "    print(f\"L-{k}, median: {np.median(v):.2f}, max: {np.max(v):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean optimal delays \\n for '{model_identifier}', :\")\n",
    "corr_obj.get_selected_data(\n",
    "            # layer=6,\n",
    "            # session=200206,\n",
    "            bin_width=20, delay=0, N_sents=499, threshold=0.1\n",
    "        ).groupby(['layer'], as_index=False).mean()['opt_delays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CorrelationUtils.copy_normalizer(model_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [\n",
    "    {\n",
    "        'model_name': 'wav2letter_modified',\n",
    "        'layer': 6,\n",
    "        'opt_neural_delay': 37.75,\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'speech2text',\n",
    "        'layer': 4,\n",
    "        'opt_neural_delay': 49.83,\n",
    "    },\n",
    "    # {\n",
    "    #     'model_name': 'wav2vec',\n",
    "    #     'layer': 8\n",
    "    # },\n",
    "    {\n",
    "        'model_name': 'wav2vec2',\n",
    "        'layer': 7,\n",
    "        'opt_neural_delay': 49.23,\n",
    "    },\n",
    "    {\n",
    "        'model_name': 'deepspeech2',\n",
    "        'layer': 2,\n",
    "        'opt_neural_delay': 54.73,\n",
    "    },\n",
    "]\n",
    "\n",
    "opt_delays = []\n",
    "for model in models_list:\n",
    "    opt_delays.append(model['opt_neural_delay'])\n",
    "avg_delay = sum(opt_delays)/len(opt_delays)\n",
    "avg_delay = int(avg_delay + 0.5) \n",
    "# avg_delay = int(avg_delay/5.0 + 0.5)\n",
    "print(avg_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(avg_delay/5.0 + 0.5)*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj = analysis.Correlations(model_identifier)\n",
    "\n",
    "ax = corr_obj.box_plot_correlations(threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex import analysis\n",
    "\n",
    "model_name = 'wav2letter_modified'\n",
    "# model_name = 'wav2vec'\n",
    "# model_name = 'deepspeech2'\n",
    "# id = 'opt_neural_delay_3_third'\n",
    "# id = 'opt_neural_delay_2_third'\n",
    "# id = 'normal_109'\n",
    "id = 'robust_26'\n",
    "\n",
    "filler = ''\n",
    "if id != '':\n",
    "    filler = '_'\n",
    "model_identifier = model_name + filler + id\n",
    "corr = analysis.Correlations(model_name=model_identifier)\n",
    "corr.get_all_sessions().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from auditory_cortex import saved_corr_dir\n",
    "\n",
    "strf_file = 'STRF_3_third_corr_results.csv'\n",
    "file_path = os.path.join(saved_corr_dir, strf_file)\n",
    "df = pd.read_csv(file_path)\n",
    "len(df['session'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex import config\n",
    "from auditory_cortex import subject_to_session\n",
    "\n",
    "\n",
    "normalizer_model = 'wav2letter_modified_normalizer2'\n",
    "\n",
    "corr_obj = analysis.Correlations(normalizer_model)\n",
    "\n",
    "data_dir = config['neural_data_dir']\n",
    "bad_sessions = config['bad_sessions']\n",
    "\n",
    "## read the sessions available in data_dir\n",
    "sessions = np.array(os.listdir(data_dir))\n",
    "sessions = np.delete(sessions, np.where(sessions == \"out_sentence_details_timit_all_loudness.mat\"))\n",
    "for s in bad_sessions:\n",
    "    sessions = np.delete(sessions, np.where(sessions == s))\n",
    "sessions = np.sort(sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr_obj.get_selected_data(bin_width=20, delay=0, N_sents=499, threshold=0.068)['session'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session = sessions[0]\n",
    "threshold = 0.068\n",
    "num_sig_sessions = 0\n",
    "total_num_channels = 0\n",
    "total_sig_channels = 0\n",
    "for session in sessions:\n",
    "    channels = os.listdir(os.path.join(data_dir,session))\n",
    "    num_channels = len(channels)\n",
    "    subject = channels[0][:1]\n",
    "    corr_channels = corr_obj.get_all_channels(session)\n",
    "    sig_channels = corr_obj.get_good_channels(session, threshold=threshold)\n",
    "\n",
    "    total_num_channels += num_channels\n",
    "    total_sig_channels += len(sig_channels)\n",
    "    if len(sig_channels) > 0:\n",
    "        num_sig_sessions += 1\n",
    "    sub = [k for k,v in subject_to_session.items() if int(session) in v][0]\n",
    "    # print(session, end=', ')\n",
    "    # print(num_channels, end=' - ')\n",
    "    # print(len(corr_channels), end=', ')\n",
    "    # print(subject, end='')\n",
    "    # print(sub, end=', ')\n",
    "    # print(len(sig_channels))\n",
    "\n",
    "print(f\"Total recording sessions: {len(sessions)}\")\n",
    "print(f\"Number of sig sessions: {num_sig_sessions}\")\n",
    "print(f\"Total recording channels: {total_num_channels}\")\n",
    "print(f\"Number of sig channels: {total_sig_channels}\")\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualizing box plots..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 200206\n",
    "threshold = 0.068\n",
    "normalized_list = [False]#, True]\n",
    "delta_corr_list = [False]#, True]\n",
    "bin_width = 20\n",
    "delay = 0\n",
    "save_fig = False\n",
    "y_axis_lim = 0.7\n",
    "\n",
    "identifier = ''\n",
    "# model_name = 'wav2letter_modified'\n",
    "# identifier = 'test7'\n",
    "# identifier = 'test8'\n",
    "# identifier = 'test9'\n",
    "\n",
    "# identifier = 'normalizer2'\n",
    "\n",
    "# identifier = 'RF_delayed_with_audio_zeropad'\n",
    "# identifier = 'opt_delay_with_audio_zeropad'\n",
    "# identifier = 'opt_delay_L6_D0'\n",
    "# identifier = 'opt_delays_final'\n",
    "# identifier = 'all_opt_delays'\n",
    "# identifier = 'opt_neural_delay'\n",
    "\n",
    "\n",
    "# model = 'wav2letter_modified_opt_delays'\n",
    "# model = 'wav2letter_modified_RF_delayed'\n",
    "# model = 'wav2letter_modified'\n",
    "# model = 'wav2vec2_encoder'\n",
    "# model = 'wav2vec2_feature_extractor'\n",
    "\n",
    "# model_name = 'wav2letter_modified'\n",
    "model_name = 'wav2vec2'\n",
    "# model_name = 'whisper'\n",
    "# model_name = 'speech2text'\n",
    "# identifier = 'opt_delay'\n",
    "# identifier = 'basic'\n",
    "# identifier = 'RF_delay'\n",
    "# identifier = 'neural_delay_only_l0'\n",
    "\n",
    "# model_name = 'deepspeech2'\n",
    "# identifier = 'bi_lstm'\n",
    "\n",
    "# model = 'deepspeech2_bi_lstm'\n",
    "# model = 'speech2text_initial'\n",
    "# model = 'speech2text'\n",
    "# model = 's2t_updated'\n",
    "\n",
    "# model = 'w2l_original'\n",
    "\n",
    "# model = 'deepspeech2_rnn_1st_half'\n",
    "# model = 'deepspeech2_rnn_2nd_half'\n",
    "# model = 'wav2letter_modified_delay_zeropad'\n",
    "# delay = 60\n",
    "filler = ''\n",
    "if identifier != '':\n",
    "    filler = '_'\n",
    "model_identifier = model_name + filler + identifier\n",
    "\n",
    "\n",
    "\n",
    "for normalized in normalized_list:\n",
    "    for delta_corr in delta_corr_list:\n",
    "\n",
    "        corr_obj = analysis.Correlations(model_identifier)\n",
    "\n",
    "\n",
    "        print(len(np.unique(corr_obj.get_all_sessions())))\n",
    "        ax, layers_data = corr_obj.box_plot_correlations(\n",
    "            # session,\n",
    "            normalized=normalized, threshold=threshold, delta_corr=delta_corr, bin_width=bin_width,\n",
    "            delay=delay, y_axis_lim=y_axis_lim\n",
    "            )\n",
    "\n",
    "\n",
    "        post_str = 'rho'\n",
    "        if normalized:\n",
    "            post_str = post_str + '_' + 'normalized'\n",
    "        if delta_corr:\n",
    "            post_str = 'delta_' + post_str\n",
    "        fig_name = f\"{model_identifier}_{post_str}.jpg\"\n",
    "\n",
    "\n",
    "        # NIPS_dir = 'C\\:\\Users\\\\ahmedb\\\\Desktop\\\\PhD\\\\Academic\\\\Makin\\'s Lab\\\\auditory_cortex\\\\Results\\\\NIPS'\n",
    "        saved_figures = os.path.join(results_dir, 'saved_figures', 'correlations')\n",
    "        filepath = os.path.join(saved_figures, model_name, fig_name)\n",
    "        if save_fig:\n",
    "            plt.savefig(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data['layer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Results for '{model_identifier}':\")\n",
    "for key, value in layers_data.items():\n",
    "    print(f\"Layer-{key}: {np.median(value):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Results for '{model_identifier}':\")\n",
    "for key, value in layers_data.items():\n",
    "    print(f\"Layer-{key}: {np.median(value):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing optimal delays..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean optimal delays \\n for '{model_identifier}', :\")\n",
    "corr_obj.get_selected_data(\n",
    "            # layer=6,\n",
    "            # session=200206,\n",
    "            bin_width=20, delay=0, N_sents=499, threshold=0.1\n",
    "        ).groupby(['layer'], as_index=False).mean()['opt_delays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_data = corr_obj.get_selected_data(\n",
    "            layer=6, bin_width=20, delay=0, threshold=0.1, N_sents=499\n",
    "        ).groupby(['session'], as_index=False).mean()\n",
    "\n",
    "sessions = select_data['session'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 5\n",
    "opt_delays = []\n",
    "\n",
    "x_coordinates = []\n",
    "y_coordinates = []\n",
    "peak_layers = []\n",
    "peak_median_corr = []   \n",
    "for session in sessions:\n",
    "    opt_delays.append(select_data.loc[select_data['session']==session, ['opt_delays']]*s)\n",
    "    c_x, c_y = session_to_coordinates[int(session)]\n",
    "    x_coordinates.append(c_x)\n",
    "    y_coordinates.append(c_y)\n",
    "\n",
    "    # print(f\"session: {session}, opt_delay: {opt_delay}\")\n",
    "fig, ax = plt.subplots()\n",
    "fontsize = 12\n",
    "scatt = ax.scatter(\n",
    "            x_coordinates, y_coordinates, s=opt_delays, \n",
    "            # c=peak_layers, cmap='magma', vmin=0, vmax= num_layers, \n",
    "        )\n",
    "# formating plot and adding colorbar\n",
    "# adding background circle\n",
    "circle = plt.Circle((0,0),2, fill=False)\n",
    "ax.set_aspect(1)\n",
    "ax.add_artist(circle)\n",
    "ax.set_xlim([-2.5,2.5])\n",
    "ax.set_ylim([-2.5,2.5])\n",
    "ax.set_title(f\"bin_width-{bin_width}ms, optimal_delays\", fontsize=fontsize)\n",
    "ax.set_xlabel('caudal - rostral', fontsize=fontsize)\n",
    "ax.set_ylabel('ventral - dorsal', fontsize=fontsize)\n",
    "plt.grid(True)\n",
    "# plt.colorbar(scatt, ax=ax, label='layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay=0\n",
    "corr_obj.plot_topographical_peaks(\n",
    "        # unit_circles=False,\n",
    "        # sessions=c_LH_sessions,\n",
    "        bin_width=20,\n",
    "        normalized=False,\n",
    "        delay=delay,\n",
    "        alpha=0.2,\n",
    "        # threshold=0.05\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combining corr data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(results_dir, 'cross_validated_correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyzing STRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 200206\n",
    "threshold = 0.1\n",
    "bin_width = 20\n",
    "delay = 0\n",
    "N_sents = 499\n",
    "column = 'test_cc_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'STRF_corr_RidgeCV.npy'\n",
    "# path = os.path.join(config.results_dir, config.corr_sub_dir, filename)\n",
    "file_path = os.path.join(results_dir, filename)\n",
    "baseline_corr = np.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.plot(baseline_corr, label='STRF corr')\n",
    "plt.title(\"STRF correlations\")\n",
    "plt.xlabel(\"channels\")\n",
    "plt.ylabel(\"Correlation coefficient\")\n",
    "plt.ylim([0,0.7])\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, label='mean')\n",
    "# plt.axhline(np.max(baseline_corr), c='gray', alpha=0.5,linewidth=5, label='peak')\n",
    "\n",
    "\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'STRF_corr_elasticNetCV.npy'\n",
    "path = os.path.join(config.results_dir, config.corr_sub_dir, filename)\n",
    "baseline_corr = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(baseline_corr, label='STRF corr')\n",
    "plt.title(\"STRF correlations, (L1 regularization)\")\n",
    "plt.xlabel(\"channels\")\n",
    "plt.ylabel(\"Correlation coefficient\")\n",
    "plt.ylim([0,0.7])\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, label='mean')\n",
    "# plt.axhline(np.max(baseline_corr), c='gray', alpha=0.5,linewidth=5, label='peak')\n",
    "\n",
    "\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(baseline_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results for NIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'wav2letter'\n",
    "# # # results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations'\n",
    "# # filename = f\"{model_name}_corr_results.csv\"\n",
    "# filename = 'c_w2l_correlations.csv'\n",
    "# file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "# corr_obj = analysis.correlations()\n",
    "session = 200206\n",
    "threshold = 0.1\n",
    "normalized = True\n",
    "delta_corr = False\n",
    "bin_width = 20\n",
    "\n",
    "model = 'wav2letter_modified'\n",
    "# model = 'wav2vec2'\n",
    "# model = 'speech2text_initial'\n",
    "# model = 'w2l_original'\n",
    "\n",
    "corr_obj = analysis.correlations(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 200206\n",
    "threshold = 0.1\n",
    "normalized = True\n",
    "delta_corr = False\n",
    "\n",
    "ax = corr_obj.box_plot_correlations(session, normalized=normalized, threshold=threshold, delta_corr=delta_corr)\n",
    "\n",
    "extra_axis_parameters = {\n",
    "    'width=\\\\figwidth',\n",
    "    'height=\\\\figheight',\n",
    "    'every x tick label/.append style={rotate=90}',\n",
    "    'xticklabel style={opacity=\\\\thisXticklabelopacity, align=center}',\n",
    "}\n",
    "tpl_save(\n",
    "    filepath=os.path.join(results_dir, 'saved_figures', 'correlations', \"correlations.tex\"),\n",
    "    extra_axis_parameters=extra_axis_parameters,\n",
    "    tex_relative_path_to_data='pngs',\n",
    "    extra_lines_start={\n",
    "        '\\\\providecommand{\\\\figwidth}{5.7in}%',\n",
    "        '\\\\providecommand{\\\\figheight}{2.0in}%',\n",
    "        '\\\\providecommand{\\\\thisXticklabelopacity}{1.0}%',\n",
    "    },\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "column = 'test_cc_raw'\n",
    "column = 'normalized_test_cc'\n",
    "summary = corr_obj.summarize(session=session,\n",
    "                        threshold=0.1,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=N_sents,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "median = summary['50%']\n",
    "std = summary['std']\n",
    "max = summary['max']\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(median.shape[0])/median.shape[0])\n",
    "plt.bar(x=np.arange(median.shape[0]), height=median, color=colors)\n",
    "# plt.ylim([0, 0.7])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(f\"Un-normalized correlations-{model_name}\")\n",
    "\n",
    "# plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "\n",
    "# plotting the baseline...\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "print(np.std(baseline_corr))\n",
    "plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting topographical bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 200206\n",
    "threshold = 0.1\n",
    "normalized = True\n",
    "delta_corr = False\n",
    "bin_width = 20\n",
    "delay = 0\n",
    "N_sents = 499\n",
    "\n",
    "model = 'wav2letter_modified'\n",
    "# model = 'wav2vec2'\n",
    "# model = 'speech2text_initial'\n",
    "# model = 'w2l_original'\n",
    "\n",
    "corr_obj = analysis.correlations(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.topographic_bar_plots(figsize=8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting topological peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 200206\n",
    "threshold = 0.1\n",
    "normalized = True\n",
    "delta_corr = False\n",
    "bin_width = 20\n",
    "delay = 0\n",
    "N_sents = 499\n",
    "\n",
    "model = 'wav2letter_modified'\n",
    "# model = 'wav2vec2'\n",
    "# model = 'speech2text_initial'\n",
    "# model = 'w2l_original'\n",
    "\n",
    "corr_obj = analysis.correlations(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.plot_topographical_peaks(\n",
    "        # unit_circles=False,\n",
    "        # sessions=c_LH_sessions,\n",
    "        bin_width=20,\n",
    "        normalized=False,\n",
    "        alpha=0.2\n",
    "        )\n",
    "\n",
    "fig_name = f\"topographical_peaks_all_sessions_20ms.tex\"\n",
    "extra_axis_parameters = {\n",
    "    'width=\\\\figwidth',\n",
    "    'height=\\\\figheight',\n",
    "    'every x tick label/.append style={rotate=90}',\n",
    "    'xticklabel style={opacity=\\\\thisXticklabelopacity, align=center}',\n",
    "}\n",
    "tpl_save(\n",
    "    filepath=os.path.join(results_dir, 'saved_figures', 'topographical', fig_name),\n",
    "    extra_axis_parameters=extra_axis_parameters,\n",
    "    tex_relative_path_to_data='pngs',\n",
    "    extra_lines_start={\n",
    "        '\\\\providecommand{\\\\figwidth}{5.7in}%',\n",
    "        '\\\\providecommand{\\\\figheight}{2.0in}%',\n",
    "        '\\\\providecommand{\\\\thisXticklabelopacity}{1.0}%',\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topographical_peaks(\n",
    "            sessions = None,\n",
    "            bin_width = 20,\n",
    "            delay = 0,\n",
    "            ax = None,\n",
    "            threshold = 0.1,\n",
    "            normalized = False,\n",
    "            fontsize = 12,\n",
    "            N_sents = 499\n",
    "            \n",
    "        ):\n",
    "\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    if normalized:\n",
    "        norm = 'normalized'\n",
    "        column = 'normalized_test_cc'\n",
    "    else:\n",
    "        norm = ''\n",
    "        column = 'test_cc_raw'\n",
    "\n",
    "\n",
    "    x_coordinates = []\n",
    "    y_coordinates = []\n",
    "    peak_layers = []\n",
    "    peak_median_corr = []\n",
    "\n",
    "    scale_size = 500\n",
    "    if sessions is None:\n",
    "        sessions = corr_obj.get_all_sessions()\n",
    "    num_layers = len(corr_obj.get_all_layers('200206'))\n",
    "\n",
    "    for session in sessions:\n",
    "        select_data = corr_obj.get_session_data(\n",
    "            session, threshold=threshold, bin_width=bin_width, delay=delay, N_sents=N_sents\n",
    "        )\n",
    "        if not select_data.empty:\n",
    "            median_across_channels = select_data.groupby('layer', as_index=False).median()\n",
    "            id = median_across_channels.idxmax()[column]\n",
    "\n",
    "            # plots 'dot' with size (area) propotional to correlations,\n",
    "            # and color as function of peak layer\n",
    "            peak_median_corr.append(median_across_channels.loc[id, column]*scale_size)\n",
    "            peak_layers.append(median_across_channels.loc[id, 'layer'])\n",
    "            c_x, c_y = session_to_coordinates[int(session)]\n",
    "            x_coordinates.append(c_x)\n",
    "            y_coordinates.append(c_y)\n",
    "\n",
    "    \n",
    "    # adding circles of unit area..\n",
    "    unit_areas = scale_size*np.ones(len(x_coordinates))\n",
    "    ax.scatter(x_coordinates, y_coordinates, s=unit_areas,\n",
    "                facecolor='none', edgecolor='black'\n",
    "            )\n",
    "    scatt = ax.scatter(\n",
    "                x_coordinates, y_coordinates, s=peak_median_corr, \n",
    "                c=peak_layers, cmap='magma', vmin=0, vmax= num_layers-1, \n",
    "            )\n",
    "    \n",
    "    # formating plot and adding colorbar\n",
    "    # adding background circle\n",
    "    circle = plt.Circle((0,0),2, fill=False)\n",
    "    ax.set_aspect(1)\n",
    "    ax.add_artist(circle)\n",
    "    ax.set_xlim([-2.5,2.5])\n",
    "    ax.set_ylim([-2.5,2.5])\n",
    "    ax.set_title(f\"bin_width-{bin_width}ms, delay-{delay}\", fontsize=fontsize)\n",
    "    ax.set_xlabel('caudal - rostral', fontsize=fontsize)\n",
    "    ax.set_ylabel('ventral - dorsal', fontsize=fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.colorbar(scatt, ax=ax, label='layers')\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topographical_peaks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyzing whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auditory_cortex.dataloader import DataLoader\n",
    "\n",
    "dataloader = DataLoader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_0 = dataloader.get_DNN_layer_features('whisper_small', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = dataloader.get_DNN_layer_features('whisper_small', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_0[12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1[12].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'whisper_small'\n",
    "dataloader.get_layer_IDs(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'whisper_tiny'\n",
    "# model = 'whisper_base'\n",
    "# model = 'whisper_small'\n",
    "# model = 'deepspeech2'\n",
    "model = 'wav2vec2'\n",
    "for layer in dataloader.get_layer_IDs(model):\n",
    "    layer_f = dataloader.get_DNN_layer_features(model, layer)\n",
    "    print(f\"Layer: {layer}, shape: {layer_f[12].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'whisper'\n",
    "results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations'\n",
    "filename = f\"{model_name}_corr_results.csv\"\n",
    "file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "corr_obj = analysis.correlations(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = 200206\n",
    "threshold = 0.1\n",
    "bin_width = 20\n",
    "delay = 0\n",
    "N_sents = 499\n",
    "column = 'test_cc_raw'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "column = 'test_cc_raw'\n",
    "mean, std, max = corr_obj.summarize(session=session,\n",
    "                        # threshold=threshold,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=N_sents,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(mean.shape[0])/mean.shape[0])\n",
    "plt.bar(x=np.arange(mean.shape[0]), height=mean, yerr=std, color=colors)\n",
    "plt.ylim([0, 0.7])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(f\"Un-normalized correlations-{model_name}\")\n",
    "\n",
    "plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "\n",
    "# plotting the baseline...\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "print(np.std(baseline_corr))\n",
    "plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyzing wav2vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "column = 'test_cc_raw'\n",
    "mean, std, max = corr_obj.summarize(session=session,\n",
    "                        # threshold=threshold,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=N_sents,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(mean.shape[0])/mean.shape[0])\n",
    "plt.bar(x=np.arange(mean.shape[0]), height=mean, yerr=std, color=colors)\n",
    "plt.ylim([0, 0.7])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(f\"Un-normalized correlations-{model_name}\")\n",
    "\n",
    "plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "\n",
    "# plotting the baseline...\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "print(np.std(baseline_corr))\n",
    "plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'wav2vec2'\n",
    "# results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations'\n",
    "filename = f\"{model_name}_corr_results.csv\"\n",
    "file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "corr_obj = analysis.correlations(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "column = 'test_cc_raw'\n",
    "mean, std, max = corr_obj.summarize(session=session,\n",
    "                        # threshold=threshold,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=N_sents,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(mean.shape[0])/mean.shape[0])\n",
    "plt.bar(x=np.arange(mean.shape[0]), height=mean, yerr=std, color=colors)\n",
    "plt.ylim([0, 0.7])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(f\"Un-normalized correlations-{model_name}\")\n",
    "\n",
    "plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "\n",
    "# plotting the baseline...\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "print(np.std(baseline_corr))\n",
    "plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "column = 'test_cc_raw'\n",
    "column = 'normalized_test_cc'\n",
    "summary = corr_obj.summarize(session=session,\n",
    "                        # threshold=0.1,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=N_sents,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "median = summary['50%']\n",
    "std = summary['std']\n",
    "max = summary['max']\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(median.shape[0])/median.shape[0])\n",
    "plt.bar(x=np.arange(median.shape[0]), height=median, color=colors)\n",
    "# plt.ylim([0, 0.7])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(f\"Un-normalized correlations-{model_name}\")\n",
    "\n",
    "# plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "\n",
    "# plotting the baseline...\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "print(np.std(baseline_corr))\n",
    "plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_data = corr_obj.data[\n",
    "    (corr_obj.data['session']==float(session)) & \\\n",
    "    (corr_obj.data['bin_width']==bin_width) & \\\n",
    "    (corr_obj.data['delay']==delay) & \\\n",
    "    (corr_obj.data['N_sents']>=N_sents) &\\\n",
    "    (corr_obj.data['normalizer'] >= threshold)     \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'test_cc_raw'\n",
    "col_name = 'normalized_test_cc'\n",
    "select_data.groupby(['layer'])[col_name].describe()\n",
    "# std = select_data.groupby(['layer'])[col_name].describe()['std']\n",
    "# mean = select_data.groupby(['layer'])[col_name].describe()['mean']\n",
    "# max = select_data.groupby(['layer'])[col_name].describe()['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = select_data.groupby(['layer'])[col_name].describe()['50%']\n",
    "plt.plot(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyzing S2T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text'\n",
    "# results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations'\n",
    "filename = f\"{model_name}_corr_results.csv\"\n",
    "# filename = 'speech2text_testing_for_modified_code.csv'\n",
    "file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "corr_obj = analysis.correlations(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "column = 'test_cc_raw'\n",
    "mean, std, max = corr_obj.summarize(session=session,\n",
    "                        # threshold=threshold,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=N_sents,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(mean.shape[0])/mean.shape[0])\n",
    "plt.bar(x=np.arange(mean.shape[0]), height=mean, yerr=std, color=colors)\n",
    "plt.ylim([0, 0.7])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(f\"Un-normalized correlations-{model_name}\")\n",
    "\n",
    "plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "\n",
    "# plotting the baseline...\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "print(np.std(baseline_corr))\n",
    "plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyzing W2L (modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'c_mod_w2l_correlations.csv'\n",
    "file_path = os.path.join(results_dir, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj = analysis.correlations(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_data = corr_obj.data[\n",
    "    (corr_obj.data['session']==float(session)) & \\\n",
    "    (corr_obj.data['bin_width']==bin_width) & \\\n",
    "    (corr_obj.data['delay']==delay) & \\\n",
    "    (corr_obj.data['N_sents']>=N_sents) &\\\n",
    "    (corr_obj.data['normalizer'] >= threshold)     \n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std = select_data.groupby(['layer'])[col_name].describe()['std']\n",
    "mean = select_data.groupby(['layer'])[col_name].describe()['mean']\n",
    "max = select_data.groupby(['layer'])[col_name].describe()['max']\n",
    "return mean, std, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,8))\n",
    "column = 'test_cc_raw'\n",
    "mean, std, max = corr_obj.summarize(session=session,\n",
    "                        threshold=0.1,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=499,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "cmap = mpl.colormaps.get_cmap('magma')\n",
    "colors = cmap(np.arange(mean.shape[0])/mean.shape[0])\n",
    "plt.plot(mean)\n",
    "plt.show()\n",
    "# plt.plot(x=np.arange(mean.shape[0]), height=mean, yerr=std, color=colors)\n",
    "# plt.ylim([0, 0.7])\n",
    "# plt.ylabel('\\u0393 (mean)')\n",
    "# plt.xlabel(\"layer IDs\")\n",
    "# plt.title(\"Un-normalized correlations - W2L\")\n",
    "# plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "# # plt.savefig(os.path.join(saved_results, 'svg_files',f'correlations_plot_unnormalized.svg'))\n",
    "# # saved_results = '/home/ahmedb/projects/Wav2Letter/saved_results/tikz_files'\n",
    "# # extra_axis_parameters = {\n",
    "# #     'width=\\\\figwidth',\n",
    "# #     'height=\\\\figheight',\n",
    "# #     'every x tick label/.append style={rotate=90}',\n",
    "# #     'xticklabel style={opacity=\\\\thisXticklabelopacity, align=center}',\n",
    "# # }\n",
    "# # tpl_save(\n",
    "# #     filepath=os.path.join(saved_results, f'correlations_plot_unnormalized.tex'),\n",
    "# #     extra_axis_parameters=extra_axis_parameters,\n",
    "# #     tex_relative_path_to_data='pngs',\n",
    "# #     pre_tikzpicture_lines={\n",
    "# #         '\\\\providecommand{\\\\figwidth}{5.7in}%',\n",
    "# #         '\\\\providecommand{\\\\figheight}{2.0in}%',\n",
    "# #         '\\\\providecommand{\\\\thisXticklabelopacity}{1.0}%',\n",
    "# #     },\n",
    "# # )\n",
    "# # plotting the baseline...\n",
    "# plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "# print(np.std(baseline_corr))\n",
    "# plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "# plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "# plt.legend(loc='best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w2l original "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'w2l_original'\n",
    "# results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations'\n",
    "filename = f\"{model_name}_corr_results.csv\"\n",
    "file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "corr_obj = analysis.correlations(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "column = 'test_cc_raw'\n",
    "mean, std, max = corr_obj.summarize(session=session,\n",
    "                        # threshold=threshold,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=500,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(mean.shape[0])/mean.shape[0])\n",
    "plt.bar(x=np.arange(mean.shape[0]), height=mean, yerr=std, color=colors)\n",
    "plt.ylim([0, 0.7])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(f\"Un-normalized correlations-{model_name}\")\n",
    "\n",
    "plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "\n",
    "# plotting the baseline...\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "print(np.std(baseline_corr))\n",
    "plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S2T initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'speech2text_initial'\n",
    "# results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations'\n",
    "filename = f\"{model_name}_corr_results.csv\"\n",
    "file_path = os.path.join(results_dir, filename)\n",
    "\n",
    "corr_obj = analysis.correlations(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "# column = 'normalized_test_cc'\n",
    "column = 'test_cc_raw'\n",
    "mean, std, max = corr_obj.summarize(session=session,\n",
    "                        # threshold=threshold,\n",
    "                        bin_width=40,\n",
    "                        delay=delay,\n",
    "                        N_sents=500,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(mean.shape[0])/mean.shape[0])\n",
    "plt.bar(x=np.arange(mean.shape[0]), height=mean, yerr=std, color=colors)\n",
    "# plt.ylim([0, 0.8])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(f\"Un-normalized correlations-{model_name}\")\n",
    "\n",
    "plt.plot(max, 'o-', markersize=8, color='k', label='DNN peak correrlation')\n",
    "\n",
    "# plotting the baseline...\n",
    "plt.axhline(np.mean(baseline_corr), c='r', linewidth=3, ls='--', label='STRF baseline - (mean)')\n",
    "print(np.std(baseline_corr))\n",
    "plt.axhline(np.max(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3, label='STRF baseline - (peak)')\n",
    "plt.axhline(np.min(baseline_corr), c='r', linewidth=3, ls='--', alpha=0.3)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj = analysis.correlations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding normalizer to S2T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2l_obj = analysis.correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in np.arange(64):\n",
    "    norm = w2l_obj.data[\n",
    "        (w2l_obj.data['channel']==ch) &\\\n",
    "        (w2l_obj.data['bin_width']==20) &\\\n",
    "        (w2l_obj.data['delay']==0) &\\\n",
    "        (w2l_obj.data['session']==200206)  \n",
    "    ]['normalizer'].unique().item()\n",
    "\n",
    "\n",
    "    indices = corr_obj.data[\n",
    "        (corr_obj.data['session'] == 200206) &\\\n",
    "        (corr_obj.data['delay'] == 0) &\\\n",
    "        (corr_obj.data['bin_width'] == 40) &\\\n",
    "        (corr_obj.data['channel'] == ch)\n",
    "                 ].index\n",
    "\n",
    "    corr_obj.data.iloc[indices,9] = [norm]*len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = 0\n",
    "corr_obj.data[\n",
    "    (corr_obj.data['session'] == 200206) &\\\n",
    "    (corr_obj.data['delay'] == 0) &\\\n",
    "    (corr_obj.data['bin_width'] == 40) &\\\n",
    "    (corr_obj.data['channel'] == ch)\n",
    "             ]['normalizer'] =  [w2l_obj.data[\n",
    "    (w2l_obj.data['channel']==0) &\\\n",
    "    (w2l_obj.data['bin_width']==20) &\\\n",
    "    (w2l_obj.data['delay']==0) &\\\n",
    "    (w2l_obj.data['session']==200206)  \n",
    "]['normalizer'].unique().item()]*corr_obj.data[\n",
    "    (corr_obj.data['session'] == 200206) &\\\n",
    "    (corr_obj.data['delay'] == 0) &\\\n",
    "    (corr_obj.data['bin_width'] == 40) &\\\n",
    "    (corr_obj.data['channel'] == ch)\n",
    "             ].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data.iloc[indices,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "corr_obj.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/'\n",
    "path = os.path.join(results_dir, 'S2T_correlations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'train_cc': 'train_cc_raw',\n",
    "                    'test_cc': 'test_cc_raw'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = [200206.0]*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['session'] = session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(columns=['session', 'layer', 'channel', 'bin_width', 'delay', 'train_cc_raw', 'test_cc_raw', 'val_cc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalizer'] = [1.0]*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['N_sents'] = [500.0]*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = '/depot/jgmakin/data/auditory_cortex/correlation_results/cross_validated_correlations/'\n",
    "name = 'speech2text_initial_corr_results.csv'\n",
    "path = os.path.join(target_dir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rest of the code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = corr_obj.get_all_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sess in sessions:\n",
    "    ch = corr_obj.get_all_channels(sess)\n",
    "    if len(ch) < 60:\n",
    "        print(f\"For {sess}, number of channels:{len(ch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = 'normalized_test_cc'\n",
    "mean, std = corr_obj.summarize(session=session,\n",
    "                        threshold=threshold,\n",
    "                        bin_width=bin_width,\n",
    "                        delay=delay,\n",
    "                        N_sents=N_sents,\n",
    "                        col_name=column\n",
    "                        )\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "cmap = cm.get_cmap('magma')\n",
    "colors = cmap(np.arange(mean.shape[0])/mean.shape[0])\n",
    "plt.bar(x=np.arange(mean.shape[0]), height=mean, yerr=std, color=colors)\n",
    "# plt.ylim([0, 1.0])\n",
    "plt.ylabel('\\u0393 (mean)')\n",
    "plt.xlabel(\"layer IDs\")\n",
    "plt.title(\"Normalized correlations\")\n",
    "# plt.savefig(os.path.join(saved_results, 'svg_files',f'correlations_plot_normalized.svg'))\n",
    "# saved_results = '/home/ahmedb/projects/Wav2Letter/saved_results/tikz_files'\n",
    "# extra_axis_parameters = {\n",
    "#     'width=\\\\figwidth',\n",
    "#     'height=\\\\figheight',\n",
    "#     'every x tick label/.append style={rotate=90}',\n",
    "#     'xticklabel style={opacity=\\\\thisXticklabelopacity, align=center}',\n",
    "# }\n",
    "# tpl_save(\n",
    "#     filepath=os.path.join(saved_results, f'correlations_plot_normalized.tex'),\n",
    "#     extra_axis_parameters=extra_axis_parameters,\n",
    "#     tex_relative_path_to_data='pngs',\n",
    "#     pre_tikzpicture_lines={\n",
    "#         '\\\\providecommand{\\\\figwidth}{5.7in}%',\n",
    "#         '\\\\providecommand{\\\\figheight}{2.0in}%',\n",
    "#         '\\\\providecommand{\\\\thisXticklabelopacity}{1.0}%',\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_obj.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
