{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/s2t-small-librispeech-asr were not used when initializing Speech2TextModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing Speech2TextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Speech2TextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Speech2TextModel were not initialized from the model checkpoint at facebook/s2t-small-librispeech-asr and are newly initialized: ['model.encoder.embed_positions.weights', 'model.decoder.embed_positions.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Speech2TextFeatureExtractor, Speech2TextModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io.wavfile import read\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display as ld\n",
    "\n",
    "\n",
    "from auditory_cortex.models import Regression\n",
    "from auditory_cortex.dataset import Neural_Data\n",
    "\n",
    "# initialise and load pretrained models\n",
    "model = Speech2TextModel.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "feature_extractor = Speech2TextFeatureExtractor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "# reg = Regression(dir, subject)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\"encoder.conv.conv_layers.0\",\"encoder.conv.conv_layers.1\",\"encoder.layers.0.fc2\",\n",
    "\t\t\t\"encoder.layers.1.fc2\",\"encoder.layers.2.fc2\",\"encoder.layers.3.fc2\",\n",
    "\t\t\t\"encoder.layers.4.fc2\",\"encoder.layers.5.fc2\",\"encoder.layers.6.fc2\",\n",
    "\t\t\t\"encoder.layers.7.fc2\",\"encoder.layers.8.fc2\",\"encoder.layers.9.fc2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gradient_extraction.get_values import GetValues\n",
    "\n",
    "# get_layer_output = GetValues(model, feature_extractor)\n",
    "# # aud = aud_data\n",
    "# # n = 0 \n",
    "# l = layers[1]\n",
    "# layer_outs = []\n",
    "# for i in range(500):\n",
    "#     sr, aud = read(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/audio_data/sent_\" + str(i) +\".wav\")\n",
    "# # for n, l in enumerate(layers[:1]):\n",
    "#     # print(n, l)\n",
    "#     get_layer_output.get_layer_output(aud, l)\n",
    "#     x =  get_layer_output.hook.output_f[0].detach().numpy().mean(1)\n",
    "#     # print(x.shape)\n",
    "#     layer_outs.append(get_layer_output.hook.output_f[0].detach().numpy().mean(1))\n",
    "\n",
    "# np.save('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_1.npy', layer_outs, allow_pickle=True)\n",
    "# a = np.load('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_1.npy', allow_pickle=True)\n",
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.load('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_0.npy', allow_pickle=True)\n",
    "b = np.load('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_1.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbdklEQVR4nO3df3RV5ZX/8fcGVOrQCAJaStBQEQyiEzVDZVE6ClNB5SugLEVpBwmWARxpqdpibSmd2iXIVEa+iJYSC7qsoFCRpX4HbYKWdhUxIgo1oCBUwo8SEaMtCkT29497Q2O4kPvjnNzck89rrSzuec5zzt536dp58uRkX3N3REQkWlplOwEREQmeiruISASpuIuIRJCKu4hIBKm4i4hEUJtsJwDQqVMnLygoyHYaIiI55bXXXnvf3TsnOtcsintBQQEVFRXZTkNEJKeY2V+Od07bMiIiEaTiLiISQSruIiIR1Cz23EVEgnL48GGqqqr49NNPs51KYNq2bUt+fj4nnXRS0teouItIpFRVVfHFL36RgoICzCzb6WTM3dm3bx9VVVV079496eu0LSMikfLpp5/SsWPHSBR2ADOjY8eOKf8kouIuIpETlcJeJ533o+IuIhJB2nMXkUgrmPpcoPfbPuPqQO8XFhV3kQhLpbDlStHKBdu3b2fo0KFs3Lix0bnbtm1j1KhR7Nu3j0suuYTHHnuMk08+OeMctC0jIpJFP/jBD5gyZQpbtmyhQ4cOlJaWBnJfFXcRkRDU1tYyevRoCgsLGTlyJAcOHDhmjrtTXl7OyJEjARgzZgzLly8PJL6Ku4hICDZv3sykSZOorKwkLy+PefPmHTNn3759tG/fnjZtYjvk+fn57Ny5M5D4Ku4iIiHo1q0b/fv3B+Cb3/wmf/jDH5o0voq7iEgIGj6bnuhZ9Y4dO/Lhhx9SW1sLxP66tmvXroHE19MyIhJp2XoK6L333uNPf/oT/fr14ze/+Q1f+9rXjpljZlx++eUsXbqUUaNGsWjRIoYNGxZIfK3cRURC0KtXLx588EEKCwvZv38/EydOTDhv5syZ3H///fTo0YN9+/Yxbty4QOJr5S4iErCCggI2bdqU1NyvfOUrrF27NvActHIXEYkgrdxFRJrAiBEj2LZt2+fGZs6cyeDBg0OJp+IuItIEnn766SaNp20ZEZEIarS4m9kjZrbXzI7pgGNmt5uZm1mn+LGZ2Rwz22Jmb5rZxWEkLSIiJ5bMyn0hMKThoJl1A64A3qs3fCVwbvxrPPBQ5imKiEiqGt1zd/ffm1lBglOzge8Dz9QbGwY86u4OrDGz9mbWxd13B5KtiEiqpp8W8P1qgr1fSNLaczezYcBOd3+jwamuwI56x1XxsUT3GG9mFWZWUV1dnU4aIiLN0vbt2+nTp09Sc+fOnUuPHj0wM95///3Acki5uJvZqcAPgWmZBHb3+e5e7O7FnTt3zuRWIiI5q3///vzud7/j7LPPDvS+6azczwG6A2+Y2XYgH1hnZl8CdgLd6s3Nj4+JiLQoyfRzB7jooosoKCgIPH7Kxd3dN7j7Ge5e4O4FxLZeLnb3PcAK4N/jT81cCtRov11EWqJk+rmHKZlHIZ8A/gT0MrMqMztRV5vngXeBLcCvgEmBZCkikmOy3c89madlbmzkfEG91w7cmnlaIiK5LZl+7mFS+wERibYsPbqYTD/3MKn9gIhICJLt5z5nzhzy8/Opqqriwgsv5JZbbgkkvlbuIiIBS6Wf++TJk5k8eXLgOWjlLiISQVq5i7Rgnw7+xx+Qf2nV+qOv91xe1PTJRJz6uWdJ1dTVnzvOnzEgS5mISBSpn7uIiGRMxV1EJIJU3EVEIkh77iISaRcsuiDQ+20YsyHQ+4VFK3cRkYCl0s999OjR9OrViz59+lBSUsLhw4cDyUHFXUQki0aPHs2mTZvYsGEDn3zyCQsWLAjkvtqWEZETO97H1OXIx81lS10/93Xr1nH++efz6KOPcuqppx4z76qrrjr6um/fvlRVVQUSX8VdJMcUTH0u2ylIEjZv3kxpaSn9+/enpKSEefPmcccddxx3/uHDh3nsscd44IEHAomvbZnjqJq6+nNfIiKpSLWf+6RJk/j617/OgAHB/AGlVu4iIiFIpZ/7T3/6U6qrq/nlL38ZWHwVdxGJtGw9uphsP/cFCxawcuVKysrKaNUquM0UFXcRSajyvML4qy8nnrC4MPF4AoWbKjNPKMfU9XMvKSmhd+/ex+3nPmHCBM4++2z69esHwLXXXsu0adMyjt9ocTezR4ChwF537xMfmwX8H+AQsBUY6+4fxs/dBYwDPgMmu/vKjLMUEckhqfRzr62tDSWHZH4GWAgMaTD2ItDH3S8E3gbuAjCz3sAo4Pz4NfPMrHVg2YqISFIaLe7u/nvggwZjL7h73bebNUB+/PUwYLG7H3T3bcAWoG+A+YqI5KQRI0ZQVFT0ua+VK8Pb2Ahiz70EWBJ/3ZVYsa9TFR87hpmNB8YDnHXWWQGkISLSfOVUP3czuxuoBR5P9Vp3n+/uxe5e3Llz50zSEBGRBtJeuZvZzcR+0TrI3T0+vBPoVm9afnxMRHJU+WUPJhwf+NKtTZyJpCKtlbuZDQG+D1zj7gfqnVoBjDKzU8ysO3AusDbzNEVEJBXJPAr5BHAZ0MnMqoCfEHs65hTgxfhfXa1x9wnu/mczexJ4i9h2za3u/llYyYuIAEyfPv3o68GDB7Nr166jxzUDBwUaK1ee2W+0uLv7jQmGS08w/+fAzzNJSkQkl23fvp2hQ4eycePGRueOGzeOiooK3J2ePXuycOFC2rVrl3EOahwmIpJFs2fP5o033uDNN9/krLPOYu7cuYHcV8VdRCQEdf3cCwsLGTlyJAcOHEg4Ly8vDwB355NPPjlhg7FUqLeMSA67bdtDxz33f7sn7mWSjAcnlMNxnpKR5KTSz33s2LE8//zz9O7dm1/84heBxNfKXUQkBKn0c//1r3/Nrl27KCwsZMmSJcedlwoVdxGREKTSzx2gdevWjBo1imXLlgUSX9syIhJpp5WX8eUvH6dtcYiS6efu7mzdupUePXrg7qxYsYLzzjsvkPhauYuIhKCun3thYSH79+9P2M/d3RkzZgwXXHABF1xwAbt37w6klzto5S7SbJWVn5NwvPSK2L/jXpgTWuyf3XB6wvEfL/kg4bh8XrL93Fu1asUf//jHUHLQyl1EJIK0cheRyKvfjiCRptiTHzFiBNu2bfvc2MyZMxk8eHAo8VTcRUSaQE71cxcRkeZJK3cRafbqd32U5GjlLiISQVq5i0ikPf1fjT+SCMnMibn14YHpJ9OEtHIXEQnY9u3b6dOnT0rXTJ48OZA+7nW0chfJUaVXTD7xhBeaJg/JXEVFBfv37w/0nlq5i4iEINl+7p999hl33nkn9913X6DxGy3uZvaIme01s431xk43sxfN7J34vx3i42Zmc8xsi5m9aWYXB5qtiEiO2Lx5M5MmTaKyspK8vDzmzZuXcN7cuXO55ppr6NKlS6Dxk1m5LwSGNBibCpS5+7lAWfwY4Erg3PjXeOD4nyQgIjmt/LIHj/mSf0imn/uuXbt46qmnuO222wKP32hxd/ffAw27BQ0DFsVfLwKG1xt/1GPWAO3NLNhvRyIiOSCZfu6vv/46W7ZsoUePHhQUFHDgwAF69OgRSPx0f6F6prvvjr/eA5wZf90V2FFvXlV8bDciIlkwYlrj/dHD6C2TTD/3q6++mj179hw9bteuHVu2bAkkfsZPy7i7m5mnep2ZjSe2dcNZZ52VaRoi0kBYn68qyanr515SUkLv3r0T9nMPU7rF/a9m1sXdd8e3XfbGx3cC3erNy4+PHcPd5wPzAYqLi1P+5iAi0lwl28+9ob/97W+B5ZDuo5ArgDHx12OAZ+qN/3v8qZlLgZp62zciItJEGl25m9kTwGVAJzOrAn4CzACeNLNxwF+A6+PTnweuArYAB4CxIeQsIpJzml0/d3e/8TinBiWY68CtmSYlIhI16ucuIiIZU3EXEYkgFXcRkQhSV0gRibQnpowP9H63L3k20PuFRSt3EZGApdLP/eabb6Z79+4UFRVRVFTE+vXrA8lBK3cRkSybNWsWI0eODPSeWrmLiIQg2X7uYVFxFxEJQbL93AHuvvtuLrzwQqZMmcLBgwcDia/iLiISgmT6uQPce++9bNq0iVdffZUPPviAmTNnBhJfxV1EJATJ9HMH6NKlC2bGKaecwtixY1m7dm0g8fULVRGJtBtnz290Trb6uQPs3r2bLl264O4sX7486adsGqPiLtICzJpwT7ZTaHGS7ec+evRoqqurcXeKiop4+OGHA4mv4i4iErBU+rmXl5eHkoP23EVEIkgrdxGRJtDs+rmLiEjmmrqfe4ss7lVTV2c7BRGRUGnPXUQkglTcRUQiKKNtGTObAtwCOLCB2AdidwEWAx2B14BvufuhDPMUEUnLkTlbG51TReNz6uTPGJBJOk0m7eJuZl2ByUBvd//EzJ4ERgFXAbPdfbGZPQyMAx4KJFsRyUmV5xU2OqdwU2UTZNI0tm/fztChQ9m4cWOjc92dH/3oRzz11FO0bt2aiRMnMnny5IxzyPQXqm2AL5jZYeBUYDcwELgpfn4RMB0VdxGRhBYuXMiOHTvYtGkTrVq1Yu/evYHcN+09d3ffCfw38B6xol5DbBvmQ3evjU+rAromut7MxptZhZlVVFdXp5uGiEizlGw/94ceeohp06bRqlWsHJ9xxhmBxE+7uJtZB2AY0B34MvBPwJBkr3f3+e5e7O7FnTt3TjcNEZFmKdl+7lu3bmXJkiUUFxdz5ZVX8s477wQSP5OnZf4N2Obu1e5+GPgt0B9ob2Z12z35wM4McxQRyTnJ9nM/ePAgbdu2paKigm9/+9uUlJQEEj+T4v4ecKmZnWqxRsWDgLeAVUDdhwGOAZ7JLEURkdyTbD/3/Px8rr32WiDWouDNN98MJH7av1B191fMbCmwDqgFXgfmA88Bi83snvhYaRCJioiko9Xkcxqdk81+7sOHD2fVqlV0796dl19+mZ49ewYSP6OnZdz9J8BPGgy/C/TN5L4iIrku2X7uU6dOZfTo0cyePZt27dqxYMGCQOK3yN4yIiJhSqWfe/v27XnuuecCz0HFXSSiiv4jOn8UJKlTcRcRaQLq5y4iEkFN3c9dXSFFRCJIK3eRLCkrb/wRPZF0qbiLSIu3a9eu454L4xn4pqDiLiKRNn/+/EDvN3369EbnpNLyd8CAAXz88ccA7N27l759+7J8+fIMs1RxFxHJqtWr//GZztdddx3Dhg0L5L76haqISAiSbflb56OPPqK8vJzhw4cHEl/FXUQkBMm2/K2zfPlyBg0aRF5eXiDxVdxFREKQbMvfOk888QQ33nhjYPFV3EVEQpBsy1+A999/n7Vr13L11VcHFl/FXUQkBHUtf4ETtvwFWLp0KUOHDqVt27aBxdfTMiISaePHj8/o+nSfc0+25S/A4sWLmTp1aropJqTiLiISsFRa/gK89NJLgeegbRkRkQjSyl1EkvazG05POP7jJR80cSa5J6da/ppZe2AB0AdwoATYDCwBCoDtwPXuvj+TOM1B1dTVnzvOnzEgS5mISC7KtZa/DwD/6+7nAf8MVAJTgTJ3Pxcoix+LiEgTSru4m9lpwNeBUgB3P+TuHwLDgEXxaYuA4ZmlKCIiqcpk5d4dqAZ+bWavm9kCM/sn4Ex33x2fswc4M9HFZjbezCrMrKK6ujqDNEREpKFM9tzbABcDt7n7K2b2AA22YNzdzcwTXezu84H5AMXFxQnniEhuKb/swYTjA1+6tYkzkUyKexVQ5e6vxI+XEivufzWzLu6+28y6AHszTVJEJF2VmzJ7+KGywePqgwZubfSaVPq5l5WVceedd3LkyBHatWvHwoUL6dGjR7rpHpX2toy77wF2mFmv+NAg4C1gBTAmPjYGeCajDEVEImzixIk8/vjjrF+/nptuuol77rknkPtm+pz7bcDjZnYy8C4wltg3jCfNbBzwF+D6DGOIiOScun7u69at4/zzz+fRRx/l1FNPPWaemfHRRx8BUFNTE9jH+mVU3N19PVCc4NSgTO4rIpLrNm/eTGlpKf3796ekpIR58+Zxxx13HDNvwYIFXHXVVXzhC18gLy+PNWvWBBJf7QdEREKQbD/32bNn8/zzz1NVVcXYsWP53ve+F0h8tR8QkaxbMuoGSOKDp3NJMv3cq6ureeONN/jqV78KwA033MCQIUMCia+Vu4hICJLp596hQwdqamp4++23AXjxxRcpLCwMJL5W7iISaYXnrW580gmE2c+9TZs2/OpXv+K6666jVatWdOjQgUceeSSjfI/eO5C7iIjIUan0cx8xYgQjRowIPAdty4iIRJBW7iIiTSCn+rmLiEhycq2fu4iINEMq7iIiEaTiLiISQSruIiIRpF+oikikXbw5w4+UaHD9nsuLGr0klX7u5eXl3HHHHRw6dIhLLrmE0tJS2rTJvDSruItEyGhblu0UJAVHjhxhzJgxlJWV0bNnT6ZNm8aiRYsYN25cxvfWtoyISAjq+rkXFhYycuRIDhw4cMycffv2cfLJJ9OzZ08AvvGNb7BsWTDfoFXcRURCsHnzZiZNmkRlZSV5eXnMmzfvmDmdOnWitraWiooKAJYuXcqOHTsCia9tGZGQlJWfk+0UJIsa9nOfM2fOMR/WYWYsXryYKVOmcPDgQa644gpat24dSHwVdxGRECTTzx2gX79+rF4d61z5wgsvHG3/m6mMt2XMrLWZvW5mz8aPu5vZK2a2xcyWxD9fVUSkRUmmnzvA3r2xp3EOHjzIzJkzmTBhQiDxg1i5fweoBPLixzOB2e6+2MweBsYBDwUQp1mpmnpsj+j8GQOykImInMi6XmdkdH2Y/dwBZs2axbPPPsuRI0eYOHEiAwcOzCTdozIq7maWD1wN/Bz4nsV+7hgI3BSfsgiYTgSLu4jI8aTSz33WrFnMmjUr8Bwy3Zb5H+D7wJH4cUfgQ3evjR9XAV0TXWhm482swswqqqurM0xDRETqS7u4m9lQYK+7v5bO9e4+392L3b24c+fO6aYhIpITRowYQVFR0ee+Vq5cGVq8TLZl+gPXmNlVQFtie+4PAO3NrE189Z4P7Mw8TRGR5Ln7cZ9OyZZM+rm7e8rXpL1yd/e73D3f3QuAUUC5u48GVgEj49PGAM+kG0NEJFU1NTX8/e9/T6sgNkfuzr59+2jbtm1K14XxnPsPgMVmdg/wOlAaQgwRkYTWrVsHwGmnnRbI/WpqagK5Tybatm1Lfn5+StcEUtzd/SXgpfjrd4G+QdxXRCRVhw4dYs2aNYHdb/r06YHdqympt4yISASpuIuIRJCKu4hIBKm4i4hEkIq7iEgEqbiLiESQiruISASpuIuIRJCKu4hIBLWIj9lL9MEaIhKcn91wesLxHy/5oIkzkTpauYuIRJCKu4hIBKm4i4hEkIq7iEgEqbiLiESQiruISASpuIuIRJCKu4hIBKVd3M2sm5mtMrO3zOzPZvad+PjpZvaimb0T/7dDcOmKiEgyMlm51wK3u3tv4FLgVjPrDUwFytz9XKAsfiwiIk0o7eLu7rvdfV389cdAJdAVGAYsik9bBAzPMEcREUlRIHvuZlYAXAS8Apzp7rvjp/YAZwYRQ0REkpdxcTezdsAy4Lvu/lH9c+7ugB/nuvFmVmFmFdXV1ZmmISIi9WRU3M3sJGKF/XF3/218+K9m1iV+vguwN9G17j7f3Yvdvbhz586ZpCEiIg2k3fLXzAwoBSrd/f56p1YAY4AZ8X+fyShDEZEsmj59ekbnsyWTfu79gW8BG8xsfXzsh8SK+pNmNg74C3B9RhmKiEjK0i7u7v4HwI5zelC69xURkczpL1RFRCKoRXzMnkhYysrPyXYKIglp5S4iEkEq7iIiEaRtGREJzc9uOD3+7xOfG1818cZspNOiqLiL5KDRtizbKWRkyagbsp1C5GlbRkQkglTcRUQiKJLbMlVTV2c7BRGRrNLKXUQkgiK5cs+Whj8x5M8YkKVMRKSl08pdRCSCtHIXEclAc20JrJW7iEgEaeUeIu3Bi0i2aOUuIhJBWrmLSJN7+F+HJxyf8PLyJs0jyrRyFxGJIBV3EZEICm1bxsyGAA8ArYEF7j4jrFgiIs1Vth6VDKW4m1lr4EHgG0AV8KqZrXD3t4KOpT4yItGhvfjghLUt0xfY4u7vuvshYDEwLKRYIiLSgLl78Dc1GwkMcfdb4sffAr7q7v9Zb854YHz8sBewOfBEjtUJeL8J4oQl1/MHvYfmItffQ67nD8G8h7PdvXOiE1l7FNLd5wPzmzKmmVW4e3FTxgxSrucPeg/NRa6/h1zPH8J/D2Fty+wEutU7zo+PiYhIEwiruL8KnGtm3c3sZGAUsCKkWCIi0kAo2zLuXmtm/wmsJPYo5CPu/ucwYqWoSbeBQpDr+YPeQ3OR6+8h1/OHkN9DKL9QFRGR7NJfqIqIRJCKu4hIBLWo4m5mRWa2xszWm1mFmfXNdk7pMLPbzGyTmf3ZzO7Ldj7pMrPbzczNrFO2c0mVmc2K/zd408yeNrP22c4pGWY2xMw2m9kWM5ua7XxSZWbdzGyVmb0V////O9nOKR1m1trMXjezZ8OK0aKKO3Af8FN3LwKmxY9zipldTuyvff/Z3c8H/jvLKaXFzLoBVwDvZTuXNL0I9HH3C4G3gbuynE+j6rUFuRLoDdxoZr2zm1XKaoHb3b03cClwaw6+B4DvAJVhBmhpxd2BvPjr04BdWcwlXROBGe5+EMDd92Y5n3TNBr5P7L9JznH3F9y9Nn64htjfcjR3Od8WxN13u/u6+OuPiRXIrtnNKjVmlg9cDSwIM05LK+7fBWaZ2Q5iK95mv9pKoCcwwMxeMbOXzexfsp1QqsxsGLDT3d/Idi4BKQH+X7aTSEJXYEe94ypyrDDWZ2YFwEXAK1lOJVX/Q2xhcyTMIJH7JCYz+x3wpQSn7gYGAVPcfZmZXQ+UAv/WlPklo5H30AY4ndiPpP8CPGlmX/Fm9kxrI+/hh8S2ZJq1E70Hd38mPuduYlsFjzdlbi2dmbUDlgHfdfePsp1PssxsKLDX3V8zs8tCjdXMakKozKwGaO/ubmYG1Lh7XmPXNSdm9r/ATHdfFT/eClzq7tXZzSw5ZnYBUAYciA/lE9se6+vue7KWWBrM7GbgP4BB7n6gkelZZ2b9gOnuPjh+fBeAu9+b1cRSZGYnAc8CK939/mznkwozuxf4FrEFQVti28S/dfdvBh2rpW3L7AL+Nf56IPBOFnNJ13LgcgAz6wmcTA51x3P3De5+hrsXuHsBsa2Bi3OwsA8h9qP1NblQ2ONyvi1IfFFWClTmWmEHcPe73D0//v/+KKA8jMIOEdyWacS3gQfMrA3wKf9oOZxLHgEeMbONwCFgTHPbkmkh5gKnAC/G6g1r3H1CdlM6sWbcFiQV/YmtfDeY2fr42A/d/fnspdQ8tahtGRGRlqKlbcuIiLQIKu4iIhGk4i4iEkEq7iIiEaTiLiISQSruIiIRpOIuIhJB/x8Dc+F1GT6t7QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(10):\n",
    "    # plt.figure()\n",
    "    plt.hist(a[:, i], label=\"a_\" + str(i))\n",
    "    # plt.hist(b[:, i], label=\"b_\" + str(i))\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# plt.hist(b)\n",
    "for i in range(10):\n",
    "    # plt.figure()\n",
    "    # plt.hist(a[:, i], label=\"a_\" + str(i))\n",
    "    plt.hist(b[:, i], label=\"b_\" + str(i))\n",
    "\n",
    "# plt.hist(b)\n",
    "# plt.show()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_extraction.get_optimal_input import GetOptInput\n",
    "\n",
    "get_opt_input = GetOptInput(model, feature_extractor)\n",
    "spect_lists = []\n",
    "loss_lists = []\n",
    "\n",
    "n = 0 \n",
    "l = layers[0]\n",
    "for i in range(1):\n",
    "    sr, aud = read(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/audio_data/sent_\" + str(i) +\".wav\")\n",
    "# for n, l in enumerate(layers[:1]):\n",
    "    # print(n, l)\n",
    "    get_opt_input.get_opt_input(aud, n, l, iterations=100)\n",
    "    \n",
    "    # spect_lists.append(get_opt_input.spect_list)\n",
    "    # loss_lists.append(get_opt_input.loss_lists)\n",
    "    np.save('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/opt_inputs/conv_layer_0_sent_'+str(i)+'.npy', get_opt_input.spect_list, allow_pickle=True)\n",
    "    # np.save('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/opt_inputs/conv_layer_0_sent_'+str(i)+'.npy', get_opt_input.lo_list, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "# fig, ax = plt.figure()\n",
    "\n",
    "sr, aud = read(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/aud.wav\")\n",
    "\n",
    "S = librosa.feature.melspectrogram(y=aud, sr=sr, n_mels=80, fmax=8000)\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure()\n",
    "ld.specshow(S_dB, sr=sr, x_axis='time', y_axis='linear')\n",
    "plt.title(\"Librosa - Mel_Spec power to dB\")\n",
    "print(\"librosa shape: \", S_dB.shape)\n",
    "\n",
    "# plt.plot(aud[5000:10000])\n",
    "plt.figure()\n",
    "plt.specgram(aud, Fs=16000)\n",
    "plt.title(\"Matplot_specshow\")\n",
    "\n",
    "plt.figure()\n",
    "f, t, Sxx = signal.spectrogram(aud, fs=16000, nfft=512)\n",
    "plt.pcolormesh(t, f, np.log10(Sxx))\n",
    "print(\"Scipy shape: \", Sxx.shape)\n",
    "plt.title(\"Scipy\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "spect = feature_extractor(aud, padding=False, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "ld.specshow(spect.numpy()[0].T, sr=sr, x_axis='time', y_axis='linear')\n",
    "plt.title(\"FEature extractor\")\n",
    "\n",
    "print(\"feature extractor: \",spect.shape)\n",
    "# plt.imshow(spect[0].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr, aud = read(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/aud.wav\")\n",
    "\n",
    "aud = aud[5000:10000]\n",
    "S = librosa.feature.melspectrogram(y=aud, sr=sr, n_mels=80, fmax=8000)\n",
    "S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure()\n",
    "ld.specshow(S_dB, sr=sr, x_axis='time', y_axis='linear')\n",
    "plt.title(\"Librosa - Mel_Spec power to dB\")\n",
    "print(\"librosa shape: \", S_dB.shape)\n",
    "\n",
    "# plt.plot(aud[5000:10000])\n",
    "plt.figure()\n",
    "plt.specgram(aud, Fs=16000)\n",
    "plt.title(\"Matplot_specshow\")\n",
    "\n",
    "plt.figure()\n",
    "f, t, Sxx = signal.spectrogram(aud, fs=16000, nfft=512)\n",
    "plt.pcolormesh(t, f, np.log10(Sxx))\n",
    "print(\"Scipy shape: \", Sxx.shape)\n",
    "plt.title(\"Scipy\")\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "spect = feature_extractor(aud, padding=False, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "ld.specshow(spect.numpy()[0].T, sr=sr, x_axis='time', y_axis='linear')\n",
    "plt.title(\"FEature extractor\")\n",
    "\n",
    "print(\"feature extractor: \",spect.shape)\n",
    "# plt.imshow(spect[0].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Speech2TextForConditionalGeneration, Speech2TextProcessor\n",
    "\n",
    "model_cg = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor_cg = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "decoder_input_ids = torch.tensor([[1, 1]]) * model.config.decoder_start_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spect = feature_extractor(aud, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "\n",
    "generated_ids = model_cg.generate(s)\n",
    "print(generated_ids.dtype)\n",
    "transcription = processor_cg.batch_decode(generated_ids)[0]\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aud)\n",
    "plt.figure()\n",
    "plt.specgram(aud)\n",
    "plt.figure()\n",
    "plt.plot()\n",
    "plt.figure()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_beta_eta(sent=[1], layer=0):\n",
    "#     # train_list = np.arange(1,451).tolist()\n",
    "#     z_vals_train, n_vals_train = reg.get_layer_values_and_spikes(layer=layer, win=80, sent_list=sent)\n",
    "#     # print(z_vals_train.shape, n_vals_train.shape)\n",
    "#     beta = np.linalg.solve(z_vals_train.T.dot(z_vals_train), (z_vals_train.T).dot(n_vals_train))\n",
    "#     return beta, n_vals_train, z_vals_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spect_numpy_data = []\n",
    "for spect_list in spect_lists:\n",
    "    spect_numpy = []\n",
    "    for spect in spect_list:\n",
    "        spect_numpy.append(spect[0].detach().numpy())\n",
    "    spect_numpy_data.append(spect_numpy)\n",
    "\n",
    "# len(spect_numpy_data[0])\n",
    "\n",
    "\n",
    "# for n, spect in enumerate(spect_numpy_data):\n",
    "#     np.save('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/partial_input/layer_' + str(n) + '.npy', spect, allow_pickle=True)\n",
    "\n",
    "# spect = feature_extractor(aud, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "# ld.specshow(spect[0].detach().numpy().T, sr=sr, x_axis='time', y_axis='linear')\n",
    "# plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "np.isclose(spect_numpy_data[0][i][:180,:], spect_numpy_data[1][i], rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(spect_numpy_data[0])\n",
    "for i in range(10):\n",
    "    for n, spects in enumerate(spect_numpy_data):\n",
    "        plt.figure()\n",
    "        ld.specshow(spects[i].T, sr=sr, x_axis='time', y_axis='linear')\n",
    "        plt.title(f\"Unit: {i}, sentence: {n}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(layers)):\n",
    "    spects = np.load('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_' + str(i) + '.npy', allow_pickle=True)\n",
    "    print(spects.shape)\n",
    "    for j in range(10):\n",
    "        plt.figure()\n",
    "        ld.specshow(spects[j].T, sr=sr, x_axis='time', y_axis='linear')\n",
    "        plt.colorbar()\n",
    "        plt.title(f\"Layer:{i}, Unit_{i}\")\n",
    "        plt.savefig(f'/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/plots_all_units/layer_{i}_unit_{j}.svg')\n",
    "\n",
    "\n",
    "\n",
    "# spect_numpy_grad_data = []\n",
    "# for spect_list in spect_lists:\n",
    "#     spect_numpy = []\n",
    "#     for spect in spect_list:\n",
    "#         spect_numpy.append(spect.grad.data[0].detach().numpy())\n",
    "#     spect_numpy_grad_data.append(spect_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_0.npy', spect_numpy_data[0], allow_pickle=True)\n",
    "# np.save('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_1.npy', spect_numpy_data[1], allow_pickle=True)\n",
    "\n",
    "# np.save('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_grad_0.npy', spect_numpy_grad_data[0], allow_pickle=True)\n",
    "# np.save('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_grad_1.npy', spect_numpy_grad_data[1], allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "conv_layer_0 = np.load('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_0.npy', allow_pickle=True)\n",
    "conv_layer_1 = np.load('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_1.npy', allow_pickle=True)\n",
    "\n",
    "conv_layer_0_grad = np.load('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_grad_0.npy', allow_pickle=True)\n",
    "conv_layer_1_grad = np.load('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/conv_layer_grad_1.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_0[0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display as ld\n",
    "\n",
    "spect = feature_extractor(aud, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "ld.specshow(spect[0].detach().numpy().T, sr=sr, x_axis='time', y_axis='linear')\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(10):\n",
    "    plt.figure()\n",
    "    ld.specshow(conv_layer_0[i].T, sr=sr, x_axis='time', y_axis='linear')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Unit_{i}\")\n",
    "    plt.savefig(f'/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/plots_all_units/layer0/unit_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display as ld\n",
    "\n",
    "spect = feature_extractor(aud, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "ld.specshow(spect[0].detach().numpy().T, sr=sr, x_axis='time', y_axis='linear')\n",
    "plt.colorbar()\n",
    "\n",
    "for i in range(10):\n",
    "    plt.figure()\n",
    "    ld.specshow(conv_layer_1[i].T, sr=sr, x_axis='time', y_axis='linear')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"Unit_{i}\")\n",
    "    # plt.savefig(f'/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/plots_all_units/layer0/unit_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "for i in range(2):\n",
    "    # plt.figure()\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "\n",
    "    im = ax[0].imshow(conv_layer_1[i].T)\n",
    "    ax[0].set_title(\"Optimal Input\")\n",
    "    cbar = fig.colorbar(im, ax=ax[0])\n",
    "    im2 = ax[1].imshow(conv_layer_1_grad[i].T)\n",
    "    cbar = fig.colorbar(im2, ax=ax[1])\n",
    "    ax[1].set_title(\"Gradient\")\n",
    "    plt.suptitle(f\"Layer 1 Unit_{i}\")\n",
    "    # plt.colorbar()\n",
    "    plt.savefig(f'/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/plots_all_units/layer1/unit_{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld.specshow(conv_layer_0[0].T, sr=sr, x_axis='time', y_axis='linear')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "for i in range(2):\n",
    "    # with open('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/layer_' + str(i), 'w') as f:\n",
    "    np.savez(spect_numpy_data[i], '/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/layer.npz')\n",
    "        # f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,8))\n",
    "    # plt.figure()\n",
    "    im = ax[0].imshow(spect_list[0][i].grad.data[0].numpy().T)\n",
    "    im = ax[1].imshow(spect_list[0][i][0].detach().numpy().T)\n",
    "    # cb_ax = fig.add_axes([0.83, 0.1, 0.02, 0.8])\n",
    "    cbar = fig.colorbar(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.imshow(spect_list[1][i][0].detach().numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, l in enumerate(loss_list[0]):\n",
    "    plt.plot(l, label=s)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Loss across layers\")\n",
    "plt.xlabel(\"Iter\")\n",
    "plt.ylabel(\"loss\")\n",
    "# plt.show()\n",
    "# plt.savefig(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/plots/select_time/loss_plt_last.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(feature_extractor(aud, sampling_rate=16000, return_tensors=\"pt\").input_features[0].T)\n",
    "for n,s in enumerate(spect_grad_data):\n",
    "    plt.figure()\n",
    "    plt.imshow(s.T)\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    # plt.title(\"Gradient\")\n",
    "    plt.title(\"Optimal input last time, layer \" + str(n))\n",
    "    plt.savefig(\"/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/notebooks/plots/select_time/last_layer_\"+str(n)+\".svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_list = []\n",
    "for s in spect_grad_data:\n",
    "    df_list.append(pd.DataFrame(s))\n",
    "pd.concat(df_list, axis=1).to_csv('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/savefile.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/scratch/gilbreth/akamsali/Research/Makin/Auditory_Cortex/savefile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(spect_grad_data.T)\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Gradient\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.abs(spect.detach().numpy())\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import scipy as sp\n",
    "\n",
    "# f, t, sci_spect =sp.signal.spectrogram(aud, fs=16000)\n",
    "# print(\"scipy\",sci_spect.T.shape)\n",
    "# hf_spect = feature_extractor(aud, sampling_rate=16000, return_tensors=\"pt\").input_features.squeeze_(0).detach().numpy().T\n",
    "# print(\"hf\",hf_spect.shape)\n",
    "# librosa_spect = librosa.feature.melspectrogram(aud, sr=16000, n_mels=189)\n",
    "# print(\"ls\",librosa_spect.T.shape)\n",
    "\n",
    "# librosa_spect_dB = librosa.power_to_db(librosa_spect, ref=np.max) \n",
    "# print(\"ls\",librosa_spect_dB.T.shape)\n",
    "\n",
    "# plt.pcolormesh(t, f, 10*np.log10(sci_spect), shading='gouraud')\n",
    "# plt.figure()\n",
    "# plt.specgram(aud, Fs=16000)\n",
    "# plt.figure()\n",
    "# plt.imshow(hf_spect)\n",
    "# plt.figure()\n",
    "# plt.imshow(librosa_spect.T)\n",
    "# plt.figure()\n",
    "# plt.imshow(librosa_spect_dB.T)\n",
    "# audio_from_loss_prop = librosa.griffinlim(s)\n",
    "# audio_from_loss_prop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = aud\n",
    "# S = np.abs(librosa.stft(y))\n",
    "# # Invert using Griffin-Lim\n",
    "# y_inv = librosa.griffinlim(S)\n",
    "# # Invert without estimating phase\n",
    "# y_istft = librosa.istft(S)\n",
    "\n",
    "# # fig, ax = plt.subplots(nrows=3, sharex=True, sharey=True)\n",
    "# # librosa.display.waveshow(y, sr=sr, color='b', ax=ax[0])\n",
    "# plt.plot(y)\n",
    "# plt.title(\"Orig\")\n",
    "# plt.figure()\n",
    "# plt.plot(y_inv)\n",
    "# # plt.plot(audio_from_loss_prop)\n",
    "# # plt.plot(audio_from_loss_prop)\n",
    "# plt.title(\"GriffinLim\")\n",
    "# plt.figure()\n",
    "# plt.plot(y_istft)\n",
    "# plt.title(\"ISTFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Speech2TextForConditionalGeneration, Speech2TextProcessor\n",
    "\n",
    "# model_cg = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor_cg = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aud = neural_data.audio(12)\n",
    "# input_features = processor_cg(aud,padding=True, sampling_rate=16000, return_tensors=\"pt\").input_features\n",
    "\n",
    "# generated_ids = model_cg.generate(inputs=spect.unsqueeze(0))\n",
    "\n",
    "# transcription = processor_cg.batch_decode(generated_ids)[0]\n",
    "# transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spect = torch.tensor(conv_layer_0[0])\n",
    "spect = spect_lists[0][0]\n",
    "spect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gradient_extraction.hook import Hook\n",
    "\n",
    "# hook = Hook(model, layers[3], backward=True)\n",
    "\n",
    "\n",
    "decoder_input_ids = torch.tensor([[1, 1]]) * model.config.decoder_start_token_id\n",
    "generated_ids = model(spect, decoder_input_ids=decoder_input_ids)\n",
    "\n",
    "transcription = processor_cg.batch_decode(generated_ids)[0]\n",
    "transcription\n",
    "\n",
    "# generated_ids[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook.output_f[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from auditory_cortex.dataset import Neural_Data\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# dir = '/depot/jgmakin/data/auditory_cortex/josh_data/data'\n",
    "# # dir = '/Users/akshita/Documents/Research/Makin/data'\n",
    "# subject = '200206'\n",
    "# neural_data = Neural_Data(dir, subject)\n",
    "\n",
    "win = 40\n",
    "sent = 12 \n",
    "\n",
    "edges, psth = neural_data.psth()\n",
    "# plt.bar(edges,psth, width=(0.8*win/1000))\n",
    "# plt.xlim(neural_data.duration(sent))\n",
    "# #plt.xlabel('Time (s)', fontsize=14)\n",
    "# plt.ylabel('Spike Counts', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(edges,psth, width=(0.8*win/1000))\n",
    "# plt.xlim(neural_data.duration(sent))\n",
    "plt.title(\"PSTH\")\n",
    "plt.xlabel('Time (s)', fontsize=14)\n",
    "plt.ylabel('Spike Counts', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ae26810785ba78c37a15c9eb002d2311c93b4a4adb47993511490e08153fac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('research_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
