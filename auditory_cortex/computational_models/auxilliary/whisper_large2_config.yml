use_pca: False
saved_checkpoint: openai/whisper-large-v2

layers:
- layer_name: model.encoder.conv1
  layer_id: 0
  layer_type: conv
  RF: 45 # ms
- layer_name: model.encoder.conv2
  layer_id: 1
  layer_type: conv
  RF: 65 # ms

- layer_name: model.encoder.layers.0.final_layer_norm
  layer_id: 2
  layer_type: transformer
  RF: 0   # RF is irrelevant for transformer layer
- layer_name: model.encoder.layers.1.final_layer_norm
  layer_id: 3
  layer_type: transformer
  RF: 0   # RF is irrelevant for transformer layer
- layer_name: model.encoder.layers.2.final_layer_norm
  layer_id: 4
  layer_type: transformer
  RF: 0   # RF is irrelevant for transformer layer
- layer_name: model.encoder.layers.3.final_layer_norm
  layer_id: 5
  layer_type: transformer
  RF: 0   # RF is irrelevant for transformer layer

# decoder layers
# - layer_name: model.decoder.layers.0.final_layer_norm
#   layer_id: 6
#   layer_type: transformer
#   RF: 0   # RF is irrelevant for transformer layer
# - layer_name: model.decoder.layers.1.final_layer_norm
#   layer_id: 7
#   layer_type: transformer
#   RF: 0   # RF is irrelevant for transformer layer
# - layer_name: model.decoder.layers.2.final_layer_norm
#   layer_id: 8
#   layer_type: transformer
#   RF: 0   # RF is irrelevant for transformer layer
# - layer_name: model.decoder.layers.3.final_layer_norm
#   layer_id: 9
#   layer_type: transformer
#   RF: 0   # RF is irrelevant for transformer layer  
